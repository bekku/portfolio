{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "蒸留実験.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN65yR2tdhwf3w37K3ncT4g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bekku/portfolio/blob/master/CNN%E2%86%922%E5%B1%A4NN%E3%81%B8%E3%81%AE%E8%92%B8%E7%95%99-2020/06/06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYFgde1Lj1WY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O749QmImj2V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_cifar10(batch=128):\n",
        "    train_loader = DataLoader(\n",
        "        datasets.CIFAR10('./data',\n",
        "                         train=True,\n",
        "                         download=True,\n",
        "                         transform=transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize(\n",
        "                                [0.5, 0.5, 0.5],  # RGB 平均\n",
        "                                [0.5, 0.5, 0.5]   # RGB 標準偏差\n",
        "                                )\n",
        "                         ])),\n",
        "        batch_size=batch,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        datasets.CIFAR10('./data',\n",
        "                         train=False,\n",
        "                         download=True,\n",
        "                         transform=transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize(\n",
        "                                 [0.5, 0.5, 0.5],  # RGB 平均\n",
        "                                 [0.5, 0.5, 0.5]  # RGB 標準偏差\n",
        "                             )\n",
        "                         ])),\n",
        "        batch_size=batch,\n",
        "    )\n",
        "\n",
        "    return {'train': train_loader, 'test': test_loader}\n",
        "\n",
        "\n",
        "def load_MNIST(batch=128, intensity=1.0):\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('./data',\n",
        "                       train=True,\n",
        "                       download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Lambda(lambda x: x * intensity)\n",
        "                       ])),\n",
        "        batch_size=batch,\n",
        "        shuffle=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('./data',\n",
        "                       train=False,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Lambda(lambda x: x * intensity)\n",
        "                       ])),\n",
        "        batch_size=batch,\n",
        "        shuffle=True)\n",
        "\n",
        "    return {'train': train_loader, 'test': test_loader}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX9O2G36h8tt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd4b6453-a32b-4d69-c486-bc9226d22e2a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "class MyCNN2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN2, self).__init__()\n",
        "#         self.conv1 = torch.nn.Conv2d(3,  # チャネル入力\n",
        "#                                      6,  # チャンネル出力\n",
        "#                                      5,  # カーネルサイズ\n",
        "#                                      1,  # ストライド (デフォルトは1)\n",
        "#                                      0,  # パディング (デフォルトは0)\n",
        "#                                      )\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 0)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 32, 3)\n",
        "        self.conv3 = torch.nn.Conv2d(32, 64, 3)\n",
        "        self.conv4 = torch.nn.Conv2d(64, 64, 3)\n",
        "        \n",
        "        self.dropout1 = torch.nn.Dropout2d(p=0.25)\n",
        "        self.dropout2 = torch.nn.Dropout2d(p=0.5)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(64 * 5 * 5, 512)  # 入力サイズ, 出力サイズ\n",
        "        self.fc2 = torch.nn.Linear(512, 10)\n",
        "\n",
        "        \n",
        "        \n",
        "# （入力チャネル）×（出力チャネル）が畳み込みフィルタの数になり、これらはネットワークが構築された段階でランダムに初期化されます。\n",
        "\n",
        "    def forward(self, x):\n",
        "        #reluに畳み込み層ぶちこんでて草生える。\n",
        "        x = f.relu(self.conv1(x))\n",
        "        x = f.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        \n",
        "        x = f.relu(self.conv3(x))\n",
        "        x = f.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(-1, 64 * 5 * 5)\n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# class AlexNet(torch.nn.Module):\n",
        " \n",
        "#     def __init__(self, num_classes):\n",
        "#         super(AlexNet, self).__init__()\n",
        "#         self.features = torch.nn.Sequential(\n",
        "#             torch.nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#             torch.nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#             torch.nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#         )\n",
        "#         self.classifier = torch.nn.Sequential(\n",
        "#             torch.nn.Dropout(),\n",
        "#             torch.nn.Linear(256 * 4 * 4, 4096),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.Dropout(),\n",
        "#             torch.nn.Linear(4096, 4096),\n",
        "#             torch.nn.ReLU(inplace=True),\n",
        "#             torch.nn.Linear(4096, num_classes),\n",
        "#         )\n",
        " \n",
        "#     def forward(self, x):\n",
        "#         x = self.features(x)\n",
        "#         x = x.view(x.size(0), 256 * 4 * 4)\n",
        "#         x = self.classifier(x)\n",
        "#         return x\n",
        "   \n",
        "        \n",
        "if __name__ == '__main__':\n",
        "    epoch = 70\n",
        "\n",
        "    loader = load_cifar10()\n",
        "\n",
        "\n",
        "    net: MyCNN2 = MyCNN2()\n",
        "    criterion = torch.nn.CrossEntropyLoss()  # ロスの計算\n",
        "    optimizer = torch.optim.SGD(params=net.parameters(), lr=0.001, momentum=0.9)\n",
        "    \n",
        "    # もしGPUが使えるなら使う\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    net.to(device)\n",
        "\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'test_acc': []\n",
        "    }\n",
        "\n",
        "    for e in range(epoch):\n",
        "        \n",
        "        ################################### 学習 #################################\n",
        "        \n",
        "        net.train()\n",
        "        loss = None\n",
        "        for i, (images, labels) in enumerate(loader['train']):\n",
        "            images = images.to(device)  # to GPU?\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(images)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 90 == 0:\n",
        "                print('Training log: {} epoch ({} / 50000 train. data). Loss: {}'.format(e + 1,\n",
        "                                                                                         (i + 1) * 128,\n",
        "                                                                                         loss.item())\n",
        "                      )\n",
        "\n",
        "\n",
        "        history['train_loss'].append(loss.item())\n",
        "\n",
        "        \n",
        "        \n",
        "        ################################### 推論 #################################\n",
        "        \n",
        "        \n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for i, (images, labels) in enumerate(loader['train']):\n",
        "                images = images.to(device)  # to GPU?\n",
        "                labels = labels.to(device)\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = float(correct / 50000)\n",
        "        print(acc)\n",
        "        history['train_acc'].append(acc)\n",
        "\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for i, (images, labels) in enumerate(loader['test']):\n",
        "                images = images.to(device)  # to GPU?\n",
        "                labels = labels.to(device)\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = float(correct / 10000)\n",
        "        print(acc)\n",
        "        history['test_acc'].append(acc)\n",
        "        \n",
        "    #====== 保存 =======\n",
        "    torch.save(net.state_dict(), 'teacher_model_weight.pth')\n",
        "\n",
        "    # 結果をプロット\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['train_loss'])\n",
        "    plt.title('Training Loss [CIFAR10]')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.savefig('cifar10_loss.png')\n",
        "    \n",
        "    \n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch + 1), history['train_acc'], label='train_acc')\n",
        "    plt.plot(range(1, epoch + 1), history['test_acc'], label='test_acc')\n",
        "    plt.title('Accuracies [CIFAR10]')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig('cifar10_acc.png')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training log: 1 epoch (128 / 50000 train. data). Loss: 2.307032346725464\n",
            "Training log: 1 epoch (11648 / 50000 train. data). Loss: 2.2991673946380615\n",
            "Training log: 1 epoch (23168 / 50000 train. data). Loss: 2.302773952484131\n",
            "Training log: 1 epoch (34688 / 50000 train. data). Loss: 2.3026812076568604\n",
            "Training log: 1 epoch (46208 / 50000 train. data). Loss: 2.2993578910827637\n",
            "0.1192\n",
            "0.1197\n",
            "Training log: 2 epoch (128 / 50000 train. data). Loss: 2.301820993423462\n",
            "Training log: 2 epoch (11648 / 50000 train. data). Loss: 2.301571846008301\n",
            "Training log: 2 epoch (23168 / 50000 train. data). Loss: 2.299187660217285\n",
            "Training log: 2 epoch (34688 / 50000 train. data). Loss: 2.295593023300171\n",
            "Training log: 2 epoch (46208 / 50000 train. data). Loss: 2.2957537174224854\n",
            "0.19484\n",
            "0.1967\n",
            "Training log: 3 epoch (128 / 50000 train. data). Loss: 2.2910361289978027\n",
            "Training log: 3 epoch (11648 / 50000 train. data). Loss: 2.2856059074401855\n",
            "Training log: 3 epoch (23168 / 50000 train. data). Loss: 2.2536089420318604\n",
            "Training log: 3 epoch (34688 / 50000 train. data). Loss: 2.269418716430664\n",
            "Training log: 3 epoch (46208 / 50000 train. data). Loss: 2.1932623386383057\n",
            "0.21702\n",
            "0.2232\n",
            "Training log: 4 epoch (128 / 50000 train. data). Loss: 2.1786131858825684\n",
            "Training log: 4 epoch (11648 / 50000 train. data). Loss: 2.2087388038635254\n",
            "Training log: 4 epoch (23168 / 50000 train. data). Loss: 2.0678279399871826\n",
            "Training log: 4 epoch (34688 / 50000 train. data). Loss: 2.111135959625244\n",
            "Training log: 4 epoch (46208 / 50000 train. data). Loss: 2.1544761657714844\n",
            "0.2572\n",
            "0.2644\n",
            "Training log: 5 epoch (128 / 50000 train. data). Loss: 2.082368850708008\n",
            "Training log: 5 epoch (11648 / 50000 train. data). Loss: 2.061652898788452\n",
            "Training log: 5 epoch (23168 / 50000 train. data). Loss: 2.069495916366577\n",
            "Training log: 5 epoch (34688 / 50000 train. data). Loss: 2.1440980434417725\n",
            "Training log: 5 epoch (46208 / 50000 train. data). Loss: 1.9790656566619873\n",
            "0.27252\n",
            "0.2842\n",
            "Training log: 6 epoch (128 / 50000 train. data). Loss: 1.998020052909851\n",
            "Training log: 6 epoch (11648 / 50000 train. data). Loss: 2.026430368423462\n",
            "Training log: 6 epoch (23168 / 50000 train. data). Loss: 2.1089913845062256\n",
            "Training log: 6 epoch (34688 / 50000 train. data). Loss: 1.9665619134902954\n",
            "Training log: 6 epoch (46208 / 50000 train. data). Loss: 1.9723342657089233\n",
            "0.29138\n",
            "0.3027\n",
            "Training log: 7 epoch (128 / 50000 train. data). Loss: 1.8757131099700928\n",
            "Training log: 7 epoch (11648 / 50000 train. data). Loss: 1.8969910144805908\n",
            "Training log: 7 epoch (23168 / 50000 train. data). Loss: 2.0052330493927\n",
            "Training log: 7 epoch (34688 / 50000 train. data). Loss: 1.9637184143066406\n",
            "Training log: 7 epoch (46208 / 50000 train. data). Loss: 1.9134178161621094\n",
            "0.3095\n",
            "0.3184\n",
            "Training log: 8 epoch (128 / 50000 train. data). Loss: 1.9201117753982544\n",
            "Training log: 8 epoch (11648 / 50000 train. data). Loss: 1.954340934753418\n",
            "Training log: 8 epoch (23168 / 50000 train. data). Loss: 1.9551066160202026\n",
            "Training log: 8 epoch (34688 / 50000 train. data). Loss: 1.9214718341827393\n",
            "Training log: 8 epoch (46208 / 50000 train. data). Loss: 1.9123553037643433\n",
            "0.3198\n",
            "0.3311\n",
            "Training log: 9 epoch (128 / 50000 train. data). Loss: 1.8944226503372192\n",
            "Training log: 9 epoch (11648 / 50000 train. data). Loss: 1.9654288291931152\n",
            "Training log: 9 epoch (23168 / 50000 train. data). Loss: 1.9675079584121704\n",
            "Training log: 9 epoch (34688 / 50000 train. data). Loss: 1.8952277898788452\n",
            "Training log: 9 epoch (46208 / 50000 train. data). Loss: 1.83921217918396\n",
            "0.34844\n",
            "0.3547\n",
            "Training log: 10 epoch (128 / 50000 train. data). Loss: 1.8476834297180176\n",
            "Training log: 10 epoch (11648 / 50000 train. data). Loss: 1.8525605201721191\n",
            "Training log: 10 epoch (23168 / 50000 train. data). Loss: 1.8757821321487427\n",
            "Training log: 10 epoch (34688 / 50000 train. data). Loss: 1.8391013145446777\n",
            "Training log: 10 epoch (46208 / 50000 train. data). Loss: 1.8223291635513306\n",
            "0.36988\n",
            "0.3778\n",
            "Training log: 11 epoch (128 / 50000 train. data). Loss: 1.8730134963989258\n",
            "Training log: 11 epoch (11648 / 50000 train. data). Loss: 1.8451727628707886\n",
            "Training log: 11 epoch (23168 / 50000 train. data). Loss: 1.7528584003448486\n",
            "Training log: 11 epoch (34688 / 50000 train. data). Loss: 1.7940704822540283\n",
            "Training log: 11 epoch (46208 / 50000 train. data). Loss: 1.8588489294052124\n",
            "0.39592\n",
            "0.4012\n",
            "Training log: 12 epoch (128 / 50000 train. data). Loss: 1.7338539361953735\n",
            "Training log: 12 epoch (11648 / 50000 train. data). Loss: 1.7106033563613892\n",
            "Training log: 12 epoch (23168 / 50000 train. data). Loss: 1.7611291408538818\n",
            "Training log: 12 epoch (34688 / 50000 train. data). Loss: 1.7758679389953613\n",
            "Training log: 12 epoch (46208 / 50000 train. data). Loss: 1.7018964290618896\n",
            "0.41636\n",
            "0.4181\n",
            "Training log: 13 epoch (128 / 50000 train. data). Loss: 1.6709883213043213\n",
            "Training log: 13 epoch (11648 / 50000 train. data). Loss: 1.7165257930755615\n",
            "Training log: 13 epoch (23168 / 50000 train. data). Loss: 1.7298858165740967\n",
            "Training log: 13 epoch (34688 / 50000 train. data). Loss: 1.7587599754333496\n",
            "Training log: 13 epoch (46208 / 50000 train. data). Loss: 1.7716965675354004\n",
            "0.42666\n",
            "0.4262\n",
            "Training log: 14 epoch (128 / 50000 train. data). Loss: 1.6139012575149536\n",
            "Training log: 14 epoch (11648 / 50000 train. data). Loss: 1.7540256977081299\n",
            "Training log: 14 epoch (23168 / 50000 train. data). Loss: 1.6329184770584106\n",
            "Training log: 14 epoch (34688 / 50000 train. data). Loss: 1.5914126634597778\n",
            "Training log: 14 epoch (46208 / 50000 train. data). Loss: 1.6346714496612549\n",
            "0.43752\n",
            "0.439\n",
            "Training log: 15 epoch (128 / 50000 train. data). Loss: 1.6294509172439575\n",
            "Training log: 15 epoch (11648 / 50000 train. data). Loss: 1.7638883590698242\n",
            "Training log: 15 epoch (23168 / 50000 train. data). Loss: 1.6807491779327393\n",
            "Training log: 15 epoch (34688 / 50000 train. data). Loss: 1.6484572887420654\n",
            "Training log: 15 epoch (46208 / 50000 train. data). Loss: 1.547453761100769\n",
            "0.45142\n",
            "0.4535\n",
            "Training log: 16 epoch (128 / 50000 train. data). Loss: 1.5671228170394897\n",
            "Training log: 16 epoch (11648 / 50000 train. data). Loss: 1.7175817489624023\n",
            "Training log: 16 epoch (23168 / 50000 train. data). Loss: 1.6464853286743164\n",
            "Training log: 16 epoch (34688 / 50000 train. data). Loss: 1.6789195537567139\n",
            "Training log: 16 epoch (46208 / 50000 train. data). Loss: 1.6382414102554321\n",
            "0.46282\n",
            "0.4622\n",
            "Training log: 17 epoch (128 / 50000 train. data). Loss: 1.5947307348251343\n",
            "Training log: 17 epoch (11648 / 50000 train. data). Loss: 1.6190201044082642\n",
            "Training log: 17 epoch (23168 / 50000 train. data). Loss: 1.5090032815933228\n",
            "Training log: 17 epoch (34688 / 50000 train. data). Loss: 1.7533622980117798\n",
            "Training log: 17 epoch (46208 / 50000 train. data). Loss: 1.5470073223114014\n",
            "0.47036\n",
            "0.4711\n",
            "Training log: 18 epoch (128 / 50000 train. data). Loss: 1.5188957452774048\n",
            "Training log: 18 epoch (11648 / 50000 train. data). Loss: 1.6910961866378784\n",
            "Training log: 18 epoch (23168 / 50000 train. data). Loss: 1.4863331317901611\n",
            "Training log: 18 epoch (34688 / 50000 train. data). Loss: 1.563551902770996\n",
            "Training log: 18 epoch (46208 / 50000 train. data). Loss: 1.4748473167419434\n",
            "0.47888\n",
            "0.477\n",
            "Training log: 19 epoch (128 / 50000 train. data). Loss: 1.5353124141693115\n",
            "Training log: 19 epoch (11648 / 50000 train. data). Loss: 1.5325100421905518\n",
            "Training log: 19 epoch (23168 / 50000 train. data). Loss: 1.514621615409851\n",
            "Training log: 19 epoch (34688 / 50000 train. data). Loss: 1.359143853187561\n",
            "Training log: 19 epoch (46208 / 50000 train. data). Loss: 1.604814887046814\n",
            "0.48468\n",
            "0.4798\n",
            "Training log: 20 epoch (128 / 50000 train. data). Loss: 1.6799129247665405\n",
            "Training log: 20 epoch (11648 / 50000 train. data). Loss: 1.677854299545288\n",
            "Training log: 20 epoch (23168 / 50000 train. data). Loss: 1.5694559812545776\n",
            "Training log: 20 epoch (34688 / 50000 train. data). Loss: 1.3893648386001587\n",
            "Training log: 20 epoch (46208 / 50000 train. data). Loss: 1.4765734672546387\n",
            "0.49682\n",
            "0.4936\n",
            "Training log: 21 epoch (128 / 50000 train. data). Loss: 1.6302435398101807\n",
            "Training log: 21 epoch (11648 / 50000 train. data). Loss: 1.599886417388916\n",
            "Training log: 21 epoch (23168 / 50000 train. data). Loss: 1.4436860084533691\n",
            "Training log: 21 epoch (34688 / 50000 train. data). Loss: 1.5583997964859009\n",
            "Training log: 21 epoch (46208 / 50000 train. data). Loss: 1.4594719409942627\n",
            "0.5027\n",
            "0.498\n",
            "Training log: 22 epoch (128 / 50000 train. data). Loss: 1.5351316928863525\n",
            "Training log: 22 epoch (11648 / 50000 train. data). Loss: 1.6333487033843994\n",
            "Training log: 22 epoch (23168 / 50000 train. data). Loss: 1.3975549936294556\n",
            "Training log: 22 epoch (34688 / 50000 train. data). Loss: 1.441247820854187\n",
            "Training log: 22 epoch (46208 / 50000 train. data). Loss: 1.4761383533477783\n",
            "0.51208\n",
            "0.503\n",
            "Training log: 23 epoch (128 / 50000 train. data). Loss: 1.4986335039138794\n",
            "Training log: 23 epoch (11648 / 50000 train. data). Loss: 1.515145182609558\n",
            "Training log: 23 epoch (23168 / 50000 train. data). Loss: 1.3162447214126587\n",
            "Training log: 23 epoch (34688 / 50000 train. data). Loss: 1.5387487411499023\n",
            "Training log: 23 epoch (46208 / 50000 train. data). Loss: 1.4633349180221558\n",
            "0.5173\n",
            "0.5095\n",
            "Training log: 24 epoch (128 / 50000 train. data). Loss: 1.3930892944335938\n",
            "Training log: 24 epoch (11648 / 50000 train. data). Loss: 1.4482007026672363\n",
            "Training log: 24 epoch (23168 / 50000 train. data). Loss: 1.4043588638305664\n",
            "Training log: 24 epoch (34688 / 50000 train. data). Loss: 1.386422038078308\n",
            "Training log: 24 epoch (46208 / 50000 train. data). Loss: 1.494024395942688\n",
            "0.52598\n",
            "0.5173\n",
            "Training log: 25 epoch (128 / 50000 train. data). Loss: 1.5959120988845825\n",
            "Training log: 25 epoch (11648 / 50000 train. data). Loss: 1.4206171035766602\n",
            "Training log: 25 epoch (23168 / 50000 train. data). Loss: 1.2843483686447144\n",
            "Training log: 25 epoch (34688 / 50000 train. data). Loss: 1.529748797416687\n",
            "Training log: 25 epoch (46208 / 50000 train. data). Loss: 1.229194164276123\n",
            "0.53532\n",
            "0.5248\n",
            "Training log: 26 epoch (128 / 50000 train. data). Loss: 1.456127643585205\n",
            "Training log: 26 epoch (11648 / 50000 train. data). Loss: 1.3728317022323608\n",
            "Training log: 26 epoch (23168 / 50000 train. data). Loss: 1.348583459854126\n",
            "Training log: 26 epoch (34688 / 50000 train. data). Loss: 1.3818963766098022\n",
            "Training log: 26 epoch (46208 / 50000 train. data). Loss: 1.4009453058242798\n",
            "0.54094\n",
            "0.5273\n",
            "Training log: 27 epoch (128 / 50000 train. data). Loss: 1.547791600227356\n",
            "Training log: 27 epoch (11648 / 50000 train. data). Loss: 1.5345686674118042\n",
            "Training log: 27 epoch (23168 / 50000 train. data). Loss: 1.4923838376998901\n",
            "Training log: 27 epoch (34688 / 50000 train. data). Loss: 1.4315071105957031\n",
            "Training log: 27 epoch (46208 / 50000 train. data). Loss: 1.267747402191162\n",
            "0.54618\n",
            "0.5346\n",
            "Training log: 28 epoch (128 / 50000 train. data). Loss: 1.4282095432281494\n",
            "Training log: 28 epoch (11648 / 50000 train. data). Loss: 1.4606622457504272\n",
            "Training log: 28 epoch (23168 / 50000 train. data). Loss: 1.4553251266479492\n",
            "Training log: 28 epoch (34688 / 50000 train. data). Loss: 1.4791648387908936\n",
            "Training log: 28 epoch (46208 / 50000 train. data). Loss: 1.3309650421142578\n",
            "0.5495\n",
            "0.535\n",
            "Training log: 29 epoch (128 / 50000 train. data). Loss: 1.2607065439224243\n",
            "Training log: 29 epoch (11648 / 50000 train. data). Loss: 1.43681001663208\n",
            "Training log: 29 epoch (23168 / 50000 train. data). Loss: 1.5485663414001465\n",
            "Training log: 29 epoch (34688 / 50000 train. data). Loss: 1.535422921180725\n",
            "Training log: 29 epoch (46208 / 50000 train. data). Loss: 1.473272681236267\n",
            "0.559\n",
            "0.5453\n",
            "Training log: 30 epoch (128 / 50000 train. data). Loss: 1.3859460353851318\n",
            "Training log: 30 epoch (11648 / 50000 train. data). Loss: 1.4548919200897217\n",
            "Training log: 30 epoch (23168 / 50000 train. data). Loss: 1.327604055404663\n",
            "Training log: 30 epoch (34688 / 50000 train. data). Loss: 1.4019954204559326\n",
            "Training log: 30 epoch (46208 / 50000 train. data). Loss: 1.406053900718689\n",
            "0.5654\n",
            "0.5514\n",
            "Training log: 31 epoch (128 / 50000 train. data). Loss: 1.4074028730392456\n",
            "Training log: 31 epoch (11648 / 50000 train. data). Loss: 1.2339036464691162\n",
            "Training log: 31 epoch (23168 / 50000 train. data). Loss: 1.3422030210494995\n",
            "Training log: 31 epoch (34688 / 50000 train. data). Loss: 1.2677420377731323\n",
            "Training log: 31 epoch (46208 / 50000 train. data). Loss: 1.4676436185836792\n",
            "0.56606\n",
            "0.551\n",
            "Training log: 32 epoch (128 / 50000 train. data). Loss: 1.2413378953933716\n",
            "Training log: 32 epoch (11648 / 50000 train. data). Loss: 1.3653873205184937\n",
            "Training log: 32 epoch (23168 / 50000 train. data). Loss: 1.4554452896118164\n",
            "Training log: 32 epoch (34688 / 50000 train. data). Loss: 1.3080192804336548\n",
            "Training log: 32 epoch (46208 / 50000 train. data). Loss: 1.3587950468063354\n",
            "0.5723\n",
            "0.5559\n",
            "Training log: 33 epoch (128 / 50000 train. data). Loss: 1.4154285192489624\n",
            "Training log: 33 epoch (11648 / 50000 train. data). Loss: 1.2106504440307617\n",
            "Training log: 33 epoch (23168 / 50000 train. data). Loss: 1.2505111694335938\n",
            "Training log: 33 epoch (34688 / 50000 train. data). Loss: 1.1953203678131104\n",
            "Training log: 33 epoch (46208 / 50000 train. data). Loss: 1.3308508396148682\n",
            "0.58206\n",
            "0.5659\n",
            "Training log: 34 epoch (128 / 50000 train. data). Loss: 1.424276351928711\n",
            "Training log: 34 epoch (11648 / 50000 train. data). Loss: 1.1751248836517334\n",
            "Training log: 34 epoch (23168 / 50000 train. data). Loss: 1.3411507606506348\n",
            "Training log: 34 epoch (34688 / 50000 train. data). Loss: 1.490323781967163\n",
            "Training log: 34 epoch (46208 / 50000 train. data). Loss: 1.352510929107666\n",
            "0.58788\n",
            "0.5699\n",
            "Training log: 35 epoch (128 / 50000 train. data). Loss: 1.2456258535385132\n",
            "Training log: 35 epoch (11648 / 50000 train. data). Loss: 1.2689520120620728\n",
            "Training log: 35 epoch (23168 / 50000 train. data). Loss: 1.3717577457427979\n",
            "Training log: 35 epoch (34688 / 50000 train. data). Loss: 1.288933515548706\n",
            "Training log: 35 epoch (46208 / 50000 train. data). Loss: 1.228088617324829\n",
            "0.59308\n",
            "0.5715\n",
            "Training log: 36 epoch (128 / 50000 train. data). Loss: 1.2370597124099731\n",
            "Training log: 36 epoch (11648 / 50000 train. data). Loss: 1.299531102180481\n",
            "Training log: 36 epoch (23168 / 50000 train. data). Loss: 1.5753577947616577\n",
            "Training log: 36 epoch (34688 / 50000 train. data). Loss: 1.2194844484329224\n",
            "Training log: 36 epoch (46208 / 50000 train. data). Loss: 1.3589575290679932\n",
            "0.599\n",
            "0.5761\n",
            "Training log: 37 epoch (128 / 50000 train. data). Loss: 1.1773409843444824\n",
            "Training log: 37 epoch (11648 / 50000 train. data). Loss: 1.2071541547775269\n",
            "Training log: 37 epoch (23168 / 50000 train. data). Loss: 1.175726294517517\n",
            "Training log: 37 epoch (34688 / 50000 train. data). Loss: 1.3556989431381226\n",
            "Training log: 37 epoch (46208 / 50000 train. data). Loss: 1.3107398748397827\n",
            "0.60016\n",
            "0.5792\n",
            "Training log: 38 epoch (128 / 50000 train. data). Loss: 1.150227665901184\n",
            "Training log: 38 epoch (11648 / 50000 train. data). Loss: 1.385871410369873\n",
            "Training log: 38 epoch (23168 / 50000 train. data). Loss: 1.3916515111923218\n",
            "Training log: 38 epoch (34688 / 50000 train. data). Loss: 1.3752070665359497\n",
            "Training log: 38 epoch (46208 / 50000 train. data). Loss: 1.204229474067688\n",
            "0.60818\n",
            "0.5887\n",
            "Training log: 39 epoch (128 / 50000 train. data). Loss: 1.4166362285614014\n",
            "Training log: 39 epoch (11648 / 50000 train. data). Loss: 1.2210166454315186\n",
            "Training log: 39 epoch (23168 / 50000 train. data). Loss: 1.1708333492279053\n",
            "Training log: 39 epoch (34688 / 50000 train. data). Loss: 1.3010811805725098\n",
            "Training log: 39 epoch (46208 / 50000 train. data). Loss: 1.1836135387420654\n",
            "0.61536\n",
            "0.5924\n",
            "Training log: 40 epoch (128 / 50000 train. data). Loss: 1.4178932905197144\n",
            "Training log: 40 epoch (11648 / 50000 train. data). Loss: 1.229436993598938\n",
            "Training log: 40 epoch (23168 / 50000 train. data). Loss: 1.3254929780960083\n",
            "Training log: 40 epoch (34688 / 50000 train. data). Loss: 1.2033333778381348\n",
            "Training log: 40 epoch (46208 / 50000 train. data). Loss: 1.3684275150299072\n",
            "0.6202\n",
            "0.5951\n",
            "Training log: 41 epoch (128 / 50000 train. data). Loss: 1.3363721370697021\n",
            "Training log: 41 epoch (11648 / 50000 train. data). Loss: 1.3545153141021729\n",
            "Training log: 41 epoch (23168 / 50000 train. data). Loss: 1.3213067054748535\n",
            "Training log: 41 epoch (34688 / 50000 train. data). Loss: 1.2055552005767822\n",
            "Training log: 41 epoch (46208 / 50000 train. data). Loss: 1.1801997423171997\n",
            "0.6274\n",
            "0.5994\n",
            "Training log: 42 epoch (128 / 50000 train. data). Loss: 1.2446088790893555\n",
            "Training log: 42 epoch (11648 / 50000 train. data). Loss: 1.1552263498306274\n",
            "Training log: 42 epoch (23168 / 50000 train. data). Loss: 1.1327670812606812\n",
            "Training log: 42 epoch (34688 / 50000 train. data). Loss: 1.269913673400879\n",
            "Training log: 42 epoch (46208 / 50000 train. data). Loss: 1.1408286094665527\n",
            "0.62674\n",
            "0.5997\n",
            "Training log: 43 epoch (128 / 50000 train. data). Loss: 1.1957873106002808\n",
            "Training log: 43 epoch (11648 / 50000 train. data). Loss: 1.197080373764038\n",
            "Training log: 43 epoch (23168 / 50000 train. data). Loss: 1.2005634307861328\n",
            "Training log: 43 epoch (34688 / 50000 train. data). Loss: 1.264542818069458\n",
            "Training log: 43 epoch (46208 / 50000 train. data). Loss: 1.300805926322937\n",
            "0.63476\n",
            "0.607\n",
            "Training log: 44 epoch (128 / 50000 train. data). Loss: 1.1977317333221436\n",
            "Training log: 44 epoch (11648 / 50000 train. data). Loss: 1.2203658819198608\n",
            "Training log: 44 epoch (23168 / 50000 train. data). Loss: 1.1666605472564697\n",
            "Training log: 44 epoch (34688 / 50000 train. data). Loss: 1.2585924863815308\n",
            "Training log: 44 epoch (46208 / 50000 train. data). Loss: 1.4260649681091309\n",
            "0.63824\n",
            "0.6103\n",
            "Training log: 45 epoch (128 / 50000 train. data). Loss: 1.253082036972046\n",
            "Training log: 45 epoch (11648 / 50000 train. data). Loss: 1.2343436479568481\n",
            "Training log: 45 epoch (23168 / 50000 train. data). Loss: 1.2413827180862427\n",
            "Training log: 45 epoch (34688 / 50000 train. data). Loss: 1.1835167407989502\n",
            "Training log: 45 epoch (46208 / 50000 train. data). Loss: 1.211219072341919\n",
            "0.64246\n",
            "0.6152\n",
            "Training log: 46 epoch (128 / 50000 train. data). Loss: 1.1502364873886108\n",
            "Training log: 46 epoch (11648 / 50000 train. data). Loss: 1.1855589151382446\n",
            "Training log: 46 epoch (23168 / 50000 train. data). Loss: 1.256744384765625\n",
            "Training log: 46 epoch (34688 / 50000 train. data). Loss: 1.2678769826889038\n",
            "Training log: 46 epoch (46208 / 50000 train. data). Loss: 1.162773609161377\n",
            "0.64858\n",
            "0.616\n",
            "Training log: 47 epoch (128 / 50000 train. data). Loss: 1.0398919582366943\n",
            "Training log: 47 epoch (11648 / 50000 train. data). Loss: 1.1956759691238403\n",
            "Training log: 47 epoch (23168 / 50000 train. data). Loss: 1.0180648565292358\n",
            "Training log: 47 epoch (34688 / 50000 train. data). Loss: 1.0753947496414185\n",
            "Training log: 47 epoch (46208 / 50000 train. data). Loss: 1.2074154615402222\n",
            "0.64916\n",
            "0.6202\n",
            "Training log: 48 epoch (128 / 50000 train. data). Loss: 1.155386209487915\n",
            "Training log: 48 epoch (11648 / 50000 train. data). Loss: 1.1924688816070557\n",
            "Training log: 48 epoch (23168 / 50000 train. data). Loss: 1.2076945304870605\n",
            "Training log: 48 epoch (34688 / 50000 train. data). Loss: 1.1910220384597778\n",
            "Training log: 48 epoch (46208 / 50000 train. data). Loss: 1.1255154609680176\n",
            "0.65964\n",
            "0.6258\n",
            "Training log: 49 epoch (128 / 50000 train. data). Loss: 1.0552456378936768\n",
            "Training log: 49 epoch (11648 / 50000 train. data). Loss: 1.1851025819778442\n",
            "Training log: 49 epoch (23168 / 50000 train. data). Loss: 1.2034454345703125\n",
            "Training log: 49 epoch (34688 / 50000 train. data). Loss: 0.9872526526451111\n",
            "Training log: 49 epoch (46208 / 50000 train. data). Loss: 1.0653042793273926\n",
            "0.66224\n",
            "0.6242\n",
            "Training log: 50 epoch (128 / 50000 train. data). Loss: 1.061982274055481\n",
            "Training log: 50 epoch (11648 / 50000 train. data). Loss: 1.2412118911743164\n",
            "Training log: 50 epoch (23168 / 50000 train. data). Loss: 1.1446032524108887\n",
            "Training log: 50 epoch (34688 / 50000 train. data). Loss: 1.2077497243881226\n",
            "Training log: 50 epoch (46208 / 50000 train. data). Loss: 1.0361734628677368\n",
            "0.66634\n",
            "0.6317\n",
            "Training log: 51 epoch (128 / 50000 train. data). Loss: 1.1823935508728027\n",
            "Training log: 51 epoch (11648 / 50000 train. data). Loss: 1.1918995380401611\n",
            "Training log: 51 epoch (23168 / 50000 train. data). Loss: 1.0467183589935303\n",
            "Training log: 51 epoch (34688 / 50000 train. data). Loss: 1.1504288911819458\n",
            "Training log: 51 epoch (46208 / 50000 train. data). Loss: 0.9926280975341797\n",
            "0.66808\n",
            "0.6324\n",
            "Training log: 52 epoch (128 / 50000 train. data). Loss: 1.176400065422058\n",
            "Training log: 52 epoch (11648 / 50000 train. data). Loss: 1.2473595142364502\n",
            "Training log: 52 epoch (23168 / 50000 train. data). Loss: 1.1631237268447876\n",
            "Training log: 52 epoch (34688 / 50000 train. data). Loss: 1.0788910388946533\n",
            "Training log: 52 epoch (46208 / 50000 train. data). Loss: 0.9977837800979614\n",
            "0.67088\n",
            "0.6347\n",
            "Training log: 53 epoch (128 / 50000 train. data). Loss: 1.1555603742599487\n",
            "Training log: 53 epoch (11648 / 50000 train. data). Loss: 1.1802617311477661\n",
            "Training log: 53 epoch (23168 / 50000 train. data). Loss: 1.1277214288711548\n",
            "Training log: 53 epoch (34688 / 50000 train. data). Loss: 1.0779403448104858\n",
            "Training log: 53 epoch (46208 / 50000 train. data). Loss: 1.1822896003723145\n",
            "0.67452\n",
            "0.6376\n",
            "Training log: 54 epoch (128 / 50000 train. data). Loss: 1.1579495668411255\n",
            "Training log: 54 epoch (11648 / 50000 train. data). Loss: 0.9860425591468811\n",
            "Training log: 54 epoch (23168 / 50000 train. data). Loss: 1.0895825624465942\n",
            "Training log: 54 epoch (34688 / 50000 train. data). Loss: 1.1218786239624023\n",
            "Training log: 54 epoch (46208 / 50000 train. data). Loss: 1.1287990808486938\n",
            "0.67832\n",
            "0.6392\n",
            "Training log: 55 epoch (128 / 50000 train. data). Loss: 1.3791905641555786\n",
            "Training log: 55 epoch (11648 / 50000 train. data). Loss: 1.020389437675476\n",
            "Training log: 55 epoch (23168 / 50000 train. data). Loss: 1.1521327495574951\n",
            "Training log: 55 epoch (34688 / 50000 train. data). Loss: 1.0065404176712036\n",
            "Training log: 55 epoch (46208 / 50000 train. data). Loss: 1.097292423248291\n",
            "0.6891\n",
            "0.644\n",
            "Training log: 56 epoch (128 / 50000 train. data). Loss: 0.945276141166687\n",
            "Training log: 56 epoch (11648 / 50000 train. data). Loss: 1.140378475189209\n",
            "Training log: 56 epoch (23168 / 50000 train. data). Loss: 1.0616828203201294\n",
            "Training log: 56 epoch (34688 / 50000 train. data). Loss: 1.2523179054260254\n",
            "Training log: 56 epoch (46208 / 50000 train. data). Loss: 1.1833208799362183\n",
            "0.68886\n",
            "0.6462\n",
            "Training log: 57 epoch (128 / 50000 train. data). Loss: 1.07787024974823\n",
            "Training log: 57 epoch (11648 / 50000 train. data). Loss: 1.1258093118667603\n",
            "Training log: 57 epoch (23168 / 50000 train. data). Loss: 1.2079341411590576\n",
            "Training log: 57 epoch (34688 / 50000 train. data). Loss: 1.180979609489441\n",
            "Training log: 57 epoch (46208 / 50000 train. data). Loss: 1.0942606925964355\n",
            "0.6936\n",
            "0.6471\n",
            "Training log: 58 epoch (128 / 50000 train. data). Loss: 1.1240651607513428\n",
            "Training log: 58 epoch (11648 / 50000 train. data). Loss: 1.013003945350647\n",
            "Training log: 58 epoch (23168 / 50000 train. data). Loss: 1.1579700708389282\n",
            "Training log: 58 epoch (34688 / 50000 train. data). Loss: 1.1463744640350342\n",
            "Training log: 58 epoch (46208 / 50000 train. data). Loss: 1.1179687976837158\n",
            "0.69998\n",
            "0.6508\n",
            "Training log: 59 epoch (128 / 50000 train. data). Loss: 1.0625901222229004\n",
            "Training log: 59 epoch (11648 / 50000 train. data). Loss: 1.0384454727172852\n",
            "Training log: 59 epoch (23168 / 50000 train. data). Loss: 1.0867886543273926\n",
            "Training log: 59 epoch (34688 / 50000 train. data). Loss: 1.2091712951660156\n",
            "Training log: 59 epoch (46208 / 50000 train. data). Loss: 1.2043293714523315\n",
            "0.70446\n",
            "0.6579\n",
            "Training log: 60 epoch (128 / 50000 train. data). Loss: 1.1562886238098145\n",
            "Training log: 60 epoch (11648 / 50000 train. data). Loss: 1.0133841037750244\n",
            "Training log: 60 epoch (23168 / 50000 train. data). Loss: 0.999489426612854\n",
            "Training log: 60 epoch (34688 / 50000 train. data). Loss: 1.0254873037338257\n",
            "Training log: 60 epoch (46208 / 50000 train. data). Loss: 0.9937169551849365\n",
            "0.70878\n",
            "0.6608\n",
            "Training log: 61 epoch (128 / 50000 train. data). Loss: 1.1038914918899536\n",
            "Training log: 61 epoch (11648 / 50000 train. data). Loss: 0.9588972926139832\n",
            "Training log: 61 epoch (23168 / 50000 train. data). Loss: 1.045039415359497\n",
            "Training log: 61 epoch (34688 / 50000 train. data). Loss: 1.1585134267807007\n",
            "Training log: 61 epoch (46208 / 50000 train. data). Loss: 1.0221856832504272\n",
            "0.70666\n",
            "0.6567\n",
            "Training log: 62 epoch (128 / 50000 train. data). Loss: 1.0026265382766724\n",
            "Training log: 62 epoch (11648 / 50000 train. data). Loss: 1.1589030027389526\n",
            "Training log: 62 epoch (23168 / 50000 train. data). Loss: 1.0413016080856323\n",
            "Training log: 62 epoch (34688 / 50000 train. data). Loss: 0.9649248719215393\n",
            "Training log: 62 epoch (46208 / 50000 train. data). Loss: 1.3003075122833252\n",
            "0.7185\n",
            "0.6682\n",
            "Training log: 63 epoch (128 / 50000 train. data). Loss: 1.1295726299285889\n",
            "Training log: 63 epoch (11648 / 50000 train. data). Loss: 0.9589438438415527\n",
            "Training log: 63 epoch (23168 / 50000 train. data). Loss: 1.0298267602920532\n",
            "Training log: 63 epoch (34688 / 50000 train. data). Loss: 1.0533933639526367\n",
            "Training log: 63 epoch (46208 / 50000 train. data). Loss: 1.0829999446868896\n",
            "0.71648\n",
            "0.6643\n",
            "Training log: 64 epoch (128 / 50000 train. data). Loss: 0.8817187547683716\n",
            "Training log: 64 epoch (11648 / 50000 train. data). Loss: 1.0666084289550781\n",
            "Training log: 64 epoch (23168 / 50000 train. data). Loss: 0.9810082316398621\n",
            "Training log: 64 epoch (34688 / 50000 train. data). Loss: 1.043058156967163\n",
            "Training log: 64 epoch (46208 / 50000 train. data). Loss: 1.0683619976043701\n",
            "0.72174\n",
            "0.6675\n",
            "Training log: 65 epoch (128 / 50000 train. data). Loss: 1.033495545387268\n",
            "Training log: 65 epoch (11648 / 50000 train. data). Loss: 1.0722802877426147\n",
            "Training log: 65 epoch (23168 / 50000 train. data). Loss: 0.887493908405304\n",
            "Training log: 65 epoch (34688 / 50000 train. data). Loss: 1.0879466533660889\n",
            "Training log: 65 epoch (46208 / 50000 train. data). Loss: 1.0989140272140503\n",
            "0.72924\n",
            "0.6733\n",
            "Training log: 66 epoch (128 / 50000 train. data). Loss: 0.9332708716392517\n",
            "Training log: 66 epoch (11648 / 50000 train. data). Loss: 0.7339572906494141\n",
            "Training log: 66 epoch (23168 / 50000 train. data). Loss: 1.0514963865280151\n",
            "Training log: 66 epoch (34688 / 50000 train. data). Loss: 1.0414806604385376\n",
            "Training log: 66 epoch (46208 / 50000 train. data). Loss: 0.9735241532325745\n",
            "0.73552\n",
            "0.6767\n",
            "Training log: 67 epoch (128 / 50000 train. data). Loss: 0.952201783657074\n",
            "Training log: 67 epoch (11648 / 50000 train. data). Loss: 0.9986919164657593\n",
            "Training log: 67 epoch (23168 / 50000 train. data). Loss: 1.1808918714523315\n",
            "Training log: 67 epoch (34688 / 50000 train. data). Loss: 0.9905290603637695\n",
            "Training log: 67 epoch (46208 / 50000 train. data). Loss: 0.9769866466522217\n",
            "0.73436\n",
            "0.6763\n",
            "Training log: 68 epoch (128 / 50000 train. data). Loss: 1.0867689847946167\n",
            "Training log: 68 epoch (11648 / 50000 train. data). Loss: 0.9310974478721619\n",
            "Training log: 68 epoch (23168 / 50000 train. data). Loss: 0.9811720848083496\n",
            "Training log: 68 epoch (34688 / 50000 train. data). Loss: 1.0395785570144653\n",
            "Training log: 68 epoch (46208 / 50000 train. data). Loss: 1.1373084783554077\n",
            "0.73922\n",
            "0.6758\n",
            "Training log: 69 epoch (128 / 50000 train. data). Loss: 1.0472147464752197\n",
            "Training log: 69 epoch (11648 / 50000 train. data). Loss: 0.9488027095794678\n",
            "Training log: 69 epoch (23168 / 50000 train. data). Loss: 0.9289976954460144\n",
            "Training log: 69 epoch (34688 / 50000 train. data). Loss: 1.0220688581466675\n",
            "Training log: 69 epoch (46208 / 50000 train. data). Loss: 1.039355993270874\n",
            "0.74134\n",
            "0.6794\n",
            "Training log: 70 epoch (128 / 50000 train. data). Loss: 1.1573867797851562\n",
            "Training log: 70 epoch (11648 / 50000 train. data). Loss: 0.8310562968254089\n",
            "Training log: 70 epoch (23168 / 50000 train. data). Loss: 1.108656883239746\n",
            "Training log: 70 epoch (34688 / 50000 train. data). Loss: 0.953209400177002\n",
            "Training log: 70 epoch (46208 / 50000 train. data). Loss: 0.8305366039276123\n",
            "0.74814\n",
            "0.6854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRNwqhbbYlK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####ドロップアウトを除いた推論用モデル#######\n",
        "\n",
        "\n",
        "class MyCNN3(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyCNN3, self).__init__()\n",
        "#         self.conv1 = torch.nn.Conv2d(3,  # チャネル入力\n",
        "#                                      6,  # チャンネル出力\n",
        "#                                      5,  # カーネルサイズ\n",
        "#                                      1,  # ストライド (デフォルトは1)\n",
        "#                                      0,  # パディング (デフォルトは0)\n",
        "#                                      )\n",
        "        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 0)\n",
        "        self.conv2 = torch.nn.Conv2d(32, 32, 3)\n",
        "        self.conv3 = torch.nn.Conv2d(32, 64, 3)\n",
        "        self.conv4 = torch.nn.Conv2d(64, 64, 3)\n",
        "        \n",
        "        self.dropout1 = torch.nn.Dropout2d(p=0.25)\n",
        "        self.dropout2 = torch.nn.Dropout2d(p=0.5)\n",
        "\n",
        "        self.pool = torch.nn.MaxPool2d(2, 2)  # カーネルサイズ, ストライド\n",
        "\n",
        "        self.fc1 = torch.nn.Linear(64 * 5 * 5, 512)  # 入力サイズ, 出力サイズ\n",
        "        self.fc2 = torch.nn.Linear(512, 10)\n",
        "\n",
        "        \n",
        "        \n",
        "# （入力チャネル）×（出力チャネル）が畳み込みフィルタの数になり、これらはネットワークが構築された段階でランダムに初期化されます。\n",
        "\n",
        "    def forward(self, x):\n",
        "        #reluに畳み込み層ぶちこんでて草生える。\n",
        "        x = f.relu(self.conv1(x))\n",
        "        x = f.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = f.relu(self.conv3(x))\n",
        "        x = f.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 64 * 5 * 5)\n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0qL0mccB9u0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUtDB1RnjF0V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89b09c1d-6750-40b2-aa0e-636943a669a6"
      },
      "source": [
        "torch.cuda.is_available() "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te3GphvYrKA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distillation_loss(Mini_model,Max_model):\n",
        "    #学習済みの大きなモデルのsoftmaxを通す前のLogitsをMax_modelの引数とする。\n",
        "    #学習中の小さなモデルのsoftmaxを通す前のlogitsをMini_modelの引数とする。\n",
        "    #ans=f.mse_loss(Mini_model,Max_model)\n",
        "    ans=f.mse_loss(Mini_model,Max_model)\n",
        "    return ans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyJKr24QwQzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2d569598-f2d2-4c1e-eab0-894b29a1d25b"
      },
      "source": [
        "# ====== 保存 =======\n",
        "# torch.save(net.state_dict(), 'teacher_model_weight.pth')\n",
        "\n",
        "\n",
        "Tnet: MyCNN3 = MyCNN3()\n",
        "    \n",
        "# 保存したモデルのパラメータを読み込む\n",
        "param = torch.load('teacher_model_weight.pth')\n",
        "\n",
        "# 保存したモデルにパラメータを当てはめる\n",
        "Tnet.load_state_dict(param)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyKyCQIvCIYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOhCXuDaYzzk",
        "colab_type": "text"
      },
      "source": [
        "**通常NN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YlGQDvtwRH5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14ecfad7-46f6-4306-f7cb-d982f9a860d1"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MyNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "#         self.fc1 = torch.nn.Linear(32 * 32 * 3, 10)\n",
        "        self.fc1 = torch.nn.Linear(32 * 32 * 3, 1024)\n",
        "        self.fc2 = torch.nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         x = torch.sigmoid(x)\n",
        "#         x = self.fc2(x)\n",
        "        \n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        #画像ということもあり、シグモイドよりもRELUの方が精度高い\n",
        "        \n",
        "        return f.log_softmax(x, dim=1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 学習回数\n",
        "    epoch = 50\n",
        "\n",
        "    # 学習結果の保存用\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'test_loss': [],\n",
        "        'test_acc': [],\n",
        "    }\n",
        "\n",
        "    # ネットワークを構築\n",
        "    net: torch.nn.Module = MyNet()\n",
        "\n",
        "    # MNISTのデータローダーを取得\n",
        "    loaders = load_cifar10()\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    net.to(device)\n",
        "\n",
        "    for e in range(epoch):\n",
        "\n",
        "        \"\"\" Training Part\"\"\"\n",
        "        loss = None\n",
        "        # 学習開始 (再開)\n",
        "        net.train(True)  # 引数は省略可能\n",
        "        for i, (data, target) in enumerate(loaders['train']):\n",
        "            data = data.to(device)  # to GPU?\n",
        "            target = target.to(device)\n",
        "#             max_model_outputs = Tnet(data)\n",
        "            data = data.view(-1, 32 * 32 * 3)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(data)\n",
        "            loss = f.nll_loss(output, target)\n",
        "#             loss = distillation_loss(output, max_model_outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 90 == 0:\n",
        "                print('Training log: {} epoch ({} / 50000 train. data). Loss: {}'.format(e+1,\n",
        "                                                                                         (i+1)*128,\n",
        "                                                                                         loss.item())\n",
        "                      )\n",
        "        history['train_loss'].append(loss)\n",
        "        \n",
        "        \"\"\" Test Part \"\"\"\n",
        "        # 学習のストップ\n",
        "        net.eval()  # または net.train(False) でも良い\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in loaders['test']:\n",
        "                data = data.to(device)  # to GPU?\n",
        "                target = target.to(device)\n",
        "                data = data.view(-1, 32 * 32 * 3)\n",
        "                output = net(data)\n",
        "                test_loss += f.nll_loss(output, target, reduction='sum').item()\n",
        "                #テスト部分のロスは全て足して、最後に平均を取ることで、その学習(epoch)でのロスとしています。\n",
        "                \n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                #softmaxの確率出力の中で一番大きいニューロンのインデックスを取得\n",
        "                \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                #eqっていうのは、同じ値だとTrueをとる。\n",
        "\n",
        "        test_loss /= 10000\n",
        "\n",
        "        print('Test loss (avg): {}, Accuracy: {}'.format(test_loss,\n",
        "                                                         correct / 10000))\n",
        "\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(correct / 10000)\n",
        "        \n",
        "    #====== 保存 =======\n",
        "    torch.save(net.state_dict(), 'weight_NN_gc.pth')\n",
        "    \n",
        "\n",
        "    # 結果の出力と描画\n",
        "    print(history)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['train_loss'], label='train_loss')\n",
        "    plt.plot(range(1, epoch+1), history['test_loss'], label='test_loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss.png')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['test_acc'])\n",
        "    plt.title('test accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.savefig('test_acc.png')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Training log: 1 epoch (128 / 50000 train. data). Loss: 2.3179731369018555\n",
            "Training log: 1 epoch (11648 / 50000 train. data). Loss: 1.7048763036727905\n",
            "Training log: 1 epoch (23168 / 50000 train. data). Loss: 1.6387486457824707\n",
            "Training log: 1 epoch (34688 / 50000 train. data). Loss: 1.6086976528167725\n",
            "Training log: 1 epoch (46208 / 50000 train. data). Loss: 1.4022159576416016\n",
            "Test loss (avg): 1.4967425300598145, Accuracy: 0.4789\n",
            "Training log: 2 epoch (128 / 50000 train. data). Loss: 1.415174961090088\n",
            "Training log: 2 epoch (11648 / 50000 train. data). Loss: 1.520485281944275\n",
            "Training log: 2 epoch (23168 / 50000 train. data). Loss: 1.4905726909637451\n",
            "Training log: 2 epoch (34688 / 50000 train. data). Loss: 1.3259505033493042\n",
            "Training log: 2 epoch (46208 / 50000 train. data). Loss: 1.5202486515045166\n",
            "Test loss (avg): 1.494954673576355, Accuracy: 0.4859\n",
            "Training log: 3 epoch (128 / 50000 train. data). Loss: 1.5528229475021362\n",
            "Training log: 3 epoch (11648 / 50000 train. data). Loss: 1.3024159669876099\n",
            "Training log: 3 epoch (23168 / 50000 train. data). Loss: 1.5901103019714355\n",
            "Training log: 3 epoch (34688 / 50000 train. data). Loss: 1.3256076574325562\n",
            "Training log: 3 epoch (46208 / 50000 train. data). Loss: 1.215895652770996\n",
            "Test loss (avg): 1.52002114944458, Accuracy: 0.4867\n",
            "Training log: 4 epoch (128 / 50000 train. data). Loss: 1.400227665901184\n",
            "Training log: 4 epoch (11648 / 50000 train. data). Loss: 1.3075941801071167\n",
            "Training log: 4 epoch (23168 / 50000 train. data). Loss: 1.253798484802246\n",
            "Training log: 4 epoch (34688 / 50000 train. data). Loss: 1.477699875831604\n",
            "Training log: 4 epoch (46208 / 50000 train. data). Loss: 1.4059216976165771\n",
            "Test loss (avg): 1.487633968925476, Accuracy: 0.4933\n",
            "Training log: 5 epoch (128 / 50000 train. data). Loss: 1.2226983308792114\n",
            "Training log: 5 epoch (11648 / 50000 train. data). Loss: 1.1233636140823364\n",
            "Training log: 5 epoch (23168 / 50000 train. data). Loss: 1.242437481880188\n",
            "Training log: 5 epoch (34688 / 50000 train. data). Loss: 1.2063732147216797\n",
            "Training log: 5 epoch (46208 / 50000 train. data). Loss: 1.3544917106628418\n",
            "Test loss (avg): 1.4586064998626709, Accuracy: 0.5105\n",
            "Training log: 6 epoch (128 / 50000 train. data). Loss: 0.9616371393203735\n",
            "Training log: 6 epoch (11648 / 50000 train. data). Loss: 1.2077879905700684\n",
            "Training log: 6 epoch (23168 / 50000 train. data). Loss: 1.1504706144332886\n",
            "Training log: 6 epoch (34688 / 50000 train. data). Loss: 1.1980334520339966\n",
            "Training log: 6 epoch (46208 / 50000 train. data). Loss: 1.1682571172714233\n",
            "Test loss (avg): 1.4643627628326417, Accuracy: 0.5162\n",
            "Training log: 7 epoch (128 / 50000 train. data). Loss: 1.0500909090042114\n",
            "Training log: 7 epoch (11648 / 50000 train. data). Loss: 1.251208782196045\n",
            "Training log: 7 epoch (23168 / 50000 train. data). Loss: 1.0379968881607056\n",
            "Training log: 7 epoch (34688 / 50000 train. data). Loss: 0.9727730751037598\n",
            "Training log: 7 epoch (46208 / 50000 train. data). Loss: 1.1795179843902588\n",
            "Test loss (avg): 1.543122174835205, Accuracy: 0.511\n",
            "Training log: 8 epoch (128 / 50000 train. data). Loss: 0.859147310256958\n",
            "Training log: 8 epoch (11648 / 50000 train. data). Loss: 0.8444657921791077\n",
            "Training log: 8 epoch (23168 / 50000 train. data). Loss: 1.0045139789581299\n",
            "Training log: 8 epoch (34688 / 50000 train. data). Loss: 0.9202561974525452\n",
            "Training log: 8 epoch (46208 / 50000 train. data). Loss: 1.265339732170105\n",
            "Test loss (avg): 1.5966974420547486, Accuracy: 0.5157\n",
            "Training log: 9 epoch (128 / 50000 train. data). Loss: 0.9391369819641113\n",
            "Training log: 9 epoch (11648 / 50000 train. data). Loss: 0.7936195135116577\n",
            "Training log: 9 epoch (23168 / 50000 train. data). Loss: 0.9070597887039185\n",
            "Training log: 9 epoch (34688 / 50000 train. data). Loss: 1.118190884590149\n",
            "Training log: 9 epoch (46208 / 50000 train. data). Loss: 1.0728504657745361\n",
            "Test loss (avg): 1.589669041633606, Accuracy: 0.529\n",
            "Training log: 10 epoch (128 / 50000 train. data). Loss: 0.8569878339767456\n",
            "Training log: 10 epoch (11648 / 50000 train. data). Loss: 1.0170866250991821\n",
            "Training log: 10 epoch (23168 / 50000 train. data). Loss: 0.8848006725311279\n",
            "Training log: 10 epoch (34688 / 50000 train. data). Loss: 0.7877496480941772\n",
            "Training log: 10 epoch (46208 / 50000 train. data). Loss: 0.9348485469818115\n",
            "Test loss (avg): 1.6125461267471313, Accuracy: 0.5265\n",
            "Training log: 11 epoch (128 / 50000 train. data). Loss: 0.6971928477287292\n",
            "Training log: 11 epoch (11648 / 50000 train. data). Loss: 1.0367672443389893\n",
            "Training log: 11 epoch (23168 / 50000 train. data). Loss: 1.065427541732788\n",
            "Training log: 11 epoch (34688 / 50000 train. data). Loss: 0.7624468207359314\n",
            "Training log: 11 epoch (46208 / 50000 train. data). Loss: 0.8803132176399231\n",
            "Test loss (avg): 1.670376086616516, Accuracy: 0.5276\n",
            "Training log: 12 epoch (128 / 50000 train. data). Loss: 0.7225211262702942\n",
            "Training log: 12 epoch (11648 / 50000 train. data). Loss: 0.709904670715332\n",
            "Training log: 12 epoch (23168 / 50000 train. data). Loss: 0.795342206954956\n",
            "Training log: 12 epoch (34688 / 50000 train. data). Loss: 0.7793587446212769\n",
            "Training log: 12 epoch (46208 / 50000 train. data). Loss: 0.7237948179244995\n",
            "Test loss (avg): 1.6643767154693603, Accuracy: 0.5275\n",
            "Training log: 13 epoch (128 / 50000 train. data). Loss: 0.5114187002182007\n",
            "Training log: 13 epoch (11648 / 50000 train. data). Loss: 0.7789896726608276\n",
            "Training log: 13 epoch (23168 / 50000 train. data). Loss: 0.6444446444511414\n",
            "Training log: 13 epoch (34688 / 50000 train. data). Loss: 0.7696049213409424\n",
            "Training log: 13 epoch (46208 / 50000 train. data). Loss: 0.7480359673500061\n",
            "Test loss (avg): 1.727976321220398, Accuracy: 0.5281\n",
            "Training log: 14 epoch (128 / 50000 train. data). Loss: 0.8503275513648987\n",
            "Training log: 14 epoch (11648 / 50000 train. data). Loss: 0.8164860606193542\n",
            "Training log: 14 epoch (23168 / 50000 train. data). Loss: 0.7441316246986389\n",
            "Training log: 14 epoch (34688 / 50000 train. data). Loss: 0.6686185002326965\n",
            "Training log: 14 epoch (46208 / 50000 train. data). Loss: 0.9134266376495361\n",
            "Test loss (avg): 1.821005372619629, Accuracy: 0.525\n",
            "Training log: 15 epoch (128 / 50000 train. data). Loss: 0.7220277786254883\n",
            "Training log: 15 epoch (11648 / 50000 train. data). Loss: 0.7141536474227905\n",
            "Training log: 15 epoch (23168 / 50000 train. data). Loss: 0.692602276802063\n",
            "Training log: 15 epoch (34688 / 50000 train. data). Loss: 0.6091498136520386\n",
            "Training log: 15 epoch (46208 / 50000 train. data). Loss: 0.7570341229438782\n",
            "Test loss (avg): 1.9174661277770997, Accuracy: 0.5222\n",
            "Training log: 16 epoch (128 / 50000 train. data). Loss: 0.5040677189826965\n",
            "Training log: 16 epoch (11648 / 50000 train. data). Loss: 0.5349526405334473\n",
            "Training log: 16 epoch (23168 / 50000 train. data). Loss: 0.7470442652702332\n",
            "Training log: 16 epoch (34688 / 50000 train. data). Loss: 0.6514595150947571\n",
            "Training log: 16 epoch (46208 / 50000 train. data). Loss: 0.7702215909957886\n",
            "Test loss (avg): 1.844106360435486, Accuracy: 0.5373\n",
            "Training log: 17 epoch (128 / 50000 train. data). Loss: 0.610126256942749\n",
            "Training log: 17 epoch (11648 / 50000 train. data). Loss: 0.5498141646385193\n",
            "Training log: 17 epoch (23168 / 50000 train. data). Loss: 0.7100662589073181\n",
            "Training log: 17 epoch (34688 / 50000 train. data). Loss: 0.5346568822860718\n",
            "Training log: 17 epoch (46208 / 50000 train. data). Loss: 0.7331094741821289\n",
            "Test loss (avg): 1.9456965267181396, Accuracy: 0.5279\n",
            "Training log: 18 epoch (128 / 50000 train. data). Loss: 0.5603135824203491\n",
            "Training log: 18 epoch (11648 / 50000 train. data). Loss: 0.5184721946716309\n",
            "Training log: 18 epoch (23168 / 50000 train. data). Loss: 0.5362765789031982\n",
            "Training log: 18 epoch (34688 / 50000 train. data). Loss: 0.6625481843948364\n",
            "Training log: 18 epoch (46208 / 50000 train. data). Loss: 0.6446136832237244\n",
            "Test loss (avg): 2.074491424560547, Accuracy: 0.5223\n",
            "Training log: 19 epoch (128 / 50000 train. data). Loss: 0.42523449659347534\n",
            "Training log: 19 epoch (11648 / 50000 train. data). Loss: 0.6117449998855591\n",
            "Training log: 19 epoch (23168 / 50000 train. data). Loss: 0.6283575892448425\n",
            "Training log: 19 epoch (34688 / 50000 train. data). Loss: 0.6349324584007263\n",
            "Training log: 19 epoch (46208 / 50000 train. data). Loss: 0.6726952195167542\n",
            "Test loss (avg): 2.153384369850159, Accuracy: 0.5273\n",
            "Training log: 20 epoch (128 / 50000 train. data). Loss: 0.5466231107711792\n",
            "Training log: 20 epoch (11648 / 50000 train. data). Loss: 0.39402687549591064\n",
            "Training log: 20 epoch (23168 / 50000 train. data). Loss: 0.5785353779792786\n",
            "Training log: 20 epoch (34688 / 50000 train. data). Loss: 0.7300468683242798\n",
            "Training log: 20 epoch (46208 / 50000 train. data). Loss: 0.48381930589675903\n",
            "Test loss (avg): 2.3008037441253664, Accuracy: 0.512\n",
            "Training log: 21 epoch (128 / 50000 train. data). Loss: 0.624865710735321\n",
            "Training log: 21 epoch (11648 / 50000 train. data). Loss: 0.5132553577423096\n",
            "Training log: 21 epoch (23168 / 50000 train. data). Loss: 0.41045570373535156\n",
            "Training log: 21 epoch (34688 / 50000 train. data). Loss: 0.5224570631980896\n",
            "Training log: 21 epoch (46208 / 50000 train. data). Loss: 0.5532987117767334\n",
            "Test loss (avg): 2.2452392990112306, Accuracy: 0.5207\n",
            "Training log: 22 epoch (128 / 50000 train. data). Loss: 0.3944261968135834\n",
            "Training log: 22 epoch (11648 / 50000 train. data). Loss: 0.44358718395233154\n",
            "Training log: 22 epoch (23168 / 50000 train. data). Loss: 0.5567395091056824\n",
            "Training log: 22 epoch (34688 / 50000 train. data). Loss: 0.5027748942375183\n",
            "Training log: 22 epoch (46208 / 50000 train. data). Loss: 0.6911040544509888\n",
            "Test loss (avg): 2.3221752815246584, Accuracy: 0.5234\n",
            "Training log: 23 epoch (128 / 50000 train. data). Loss: 0.3899185359477997\n",
            "Training log: 23 epoch (11648 / 50000 train. data). Loss: 0.4378075897693634\n",
            "Training log: 23 epoch (23168 / 50000 train. data). Loss: 0.3860890865325928\n",
            "Training log: 23 epoch (34688 / 50000 train. data). Loss: 0.5530292391777039\n",
            "Training log: 23 epoch (46208 / 50000 train. data). Loss: 0.446500301361084\n",
            "Test loss (avg): 2.3902541542053224, Accuracy: 0.5218\n",
            "Training log: 24 epoch (128 / 50000 train. data). Loss: 0.302639365196228\n",
            "Training log: 24 epoch (11648 / 50000 train. data). Loss: 0.49656322598457336\n",
            "Training log: 24 epoch (23168 / 50000 train. data). Loss: 0.3498590886592865\n",
            "Training log: 24 epoch (34688 / 50000 train. data). Loss: 0.5152163505554199\n",
            "Training log: 24 epoch (46208 / 50000 train. data). Loss: 0.4709119498729706\n",
            "Test loss (avg): 2.591886728477478, Accuracy: 0.5126\n",
            "Training log: 25 epoch (128 / 50000 train. data). Loss: 0.3973814845085144\n",
            "Training log: 25 epoch (11648 / 50000 train. data). Loss: 0.35332027077674866\n",
            "Training log: 25 epoch (23168 / 50000 train. data). Loss: 0.4783104360103607\n",
            "Training log: 25 epoch (34688 / 50000 train. data). Loss: 0.5113376379013062\n",
            "Training log: 25 epoch (46208 / 50000 train. data). Loss: 0.4194410741329193\n",
            "Test loss (avg): 2.5056385971069335, Accuracy: 0.5238\n",
            "Training log: 26 epoch (128 / 50000 train. data). Loss: 0.42065849900245667\n",
            "Training log: 26 epoch (11648 / 50000 train. data). Loss: 0.41692209243774414\n",
            "Training log: 26 epoch (23168 / 50000 train. data). Loss: 0.3303060233592987\n",
            "Training log: 26 epoch (34688 / 50000 train. data). Loss: 0.5862616300582886\n",
            "Training log: 26 epoch (46208 / 50000 train. data). Loss: 0.5112091898918152\n",
            "Test loss (avg): 2.5129575189590456, Accuracy: 0.5315\n",
            "Training log: 27 epoch (128 / 50000 train. data). Loss: 0.2902557849884033\n",
            "Training log: 27 epoch (11648 / 50000 train. data). Loss: 0.23488710820674896\n",
            "Training log: 27 epoch (23168 / 50000 train. data). Loss: 0.32501688599586487\n",
            "Training log: 27 epoch (34688 / 50000 train. data). Loss: 0.5135481953620911\n",
            "Training log: 27 epoch (46208 / 50000 train. data). Loss: 0.4191941022872925\n",
            "Test loss (avg): 2.6543737482070924, Accuracy: 0.5181\n",
            "Training log: 28 epoch (128 / 50000 train. data). Loss: 0.5579960346221924\n",
            "Training log: 28 epoch (11648 / 50000 train. data). Loss: 0.2008579969406128\n",
            "Training log: 28 epoch (23168 / 50000 train. data). Loss: 0.44924724102020264\n",
            "Training log: 28 epoch (34688 / 50000 train. data). Loss: 0.5121275186538696\n",
            "Training log: 28 epoch (46208 / 50000 train. data). Loss: 0.4001871943473816\n",
            "Test loss (avg): 2.7327394512176513, Accuracy: 0.5225\n",
            "Training log: 29 epoch (128 / 50000 train. data). Loss: 0.48402631282806396\n",
            "Training log: 29 epoch (11648 / 50000 train. data). Loss: 0.3462682366371155\n",
            "Training log: 29 epoch (23168 / 50000 train. data). Loss: 0.2636831998825073\n",
            "Training log: 29 epoch (34688 / 50000 train. data). Loss: 0.3958054780960083\n",
            "Training log: 29 epoch (46208 / 50000 train. data). Loss: 0.4702124297618866\n",
            "Test loss (avg): 2.86014708366394, Accuracy: 0.5186\n",
            "Training log: 30 epoch (128 / 50000 train. data). Loss: 0.18980088829994202\n",
            "Training log: 30 epoch (11648 / 50000 train. data). Loss: 0.4621036648750305\n",
            "Training log: 30 epoch (23168 / 50000 train. data). Loss: 0.41868120431900024\n",
            "Training log: 30 epoch (34688 / 50000 train. data). Loss: 0.35225430130958557\n",
            "Training log: 30 epoch (46208 / 50000 train. data). Loss: 0.3401746153831482\n",
            "Test loss (avg): 3.032406069946289, Accuracy: 0.5107\n",
            "Training log: 31 epoch (128 / 50000 train. data). Loss: 0.4095729887485504\n",
            "Training log: 31 epoch (11648 / 50000 train. data). Loss: 0.3214806616306305\n",
            "Training log: 31 epoch (23168 / 50000 train. data). Loss: 0.21034453809261322\n",
            "Training log: 31 epoch (34688 / 50000 train. data). Loss: 0.2497553825378418\n",
            "Training log: 31 epoch (46208 / 50000 train. data). Loss: 0.2729038596153259\n",
            "Test loss (avg): 2.934801036834717, Accuracy: 0.5331\n",
            "Training log: 32 epoch (128 / 50000 train. data). Loss: 0.41047754883766174\n",
            "Training log: 32 epoch (11648 / 50000 train. data). Loss: 0.21705262362957\n",
            "Training log: 32 epoch (23168 / 50000 train. data). Loss: 0.46745026111602783\n",
            "Training log: 32 epoch (34688 / 50000 train. data). Loss: 0.26459041237831116\n",
            "Training log: 32 epoch (46208 / 50000 train. data). Loss: 0.5474300980567932\n",
            "Test loss (avg): 3.3544767219543457, Accuracy: 0.5087\n",
            "Training log: 33 epoch (128 / 50000 train. data). Loss: 0.42261338233947754\n",
            "Training log: 33 epoch (11648 / 50000 train. data). Loss: 0.18625035881996155\n",
            "Training log: 33 epoch (23168 / 50000 train. data). Loss: 0.3157590627670288\n",
            "Training log: 33 epoch (34688 / 50000 train. data). Loss: 0.20925380289554596\n",
            "Training log: 33 epoch (46208 / 50000 train. data). Loss: 0.29358673095703125\n",
            "Test loss (avg): 3.1268466884613035, Accuracy: 0.5269\n",
            "Training log: 34 epoch (128 / 50000 train. data). Loss: 0.2574000656604767\n",
            "Training log: 34 epoch (11648 / 50000 train. data). Loss: 0.4634629786014557\n",
            "Training log: 34 epoch (23168 / 50000 train. data). Loss: 0.22573372721672058\n",
            "Training log: 34 epoch (34688 / 50000 train. data). Loss: 0.2548878490924835\n",
            "Training log: 34 epoch (46208 / 50000 train. data). Loss: 0.6821597814559937\n",
            "Test loss (avg): 3.161347608566284, Accuracy: 0.5182\n",
            "Training log: 35 epoch (128 / 50000 train. data). Loss: 0.477588951587677\n",
            "Training log: 35 epoch (11648 / 50000 train. data). Loss: 0.2345017045736313\n",
            "Training log: 35 epoch (23168 / 50000 train. data). Loss: 0.4042528569698334\n",
            "Training log: 35 epoch (34688 / 50000 train. data). Loss: 0.2876720726490021\n",
            "Training log: 35 epoch (46208 / 50000 train. data). Loss: 0.5049435496330261\n",
            "Test loss (avg): 3.184263037109375, Accuracy: 0.5167\n",
            "Training log: 36 epoch (128 / 50000 train. data). Loss: 0.18675845861434937\n",
            "Training log: 36 epoch (11648 / 50000 train. data). Loss: 0.24949350953102112\n",
            "Training log: 36 epoch (23168 / 50000 train. data). Loss: 0.19161295890808105\n",
            "Training log: 36 epoch (34688 / 50000 train. data). Loss: 0.1969742476940155\n",
            "Training log: 36 epoch (46208 / 50000 train. data). Loss: 0.31075847148895264\n",
            "Test loss (avg): 3.2766682273864745, Accuracy: 0.5252\n",
            "Training log: 37 epoch (128 / 50000 train. data). Loss: 0.25730422139167786\n",
            "Training log: 37 epoch (11648 / 50000 train. data). Loss: 0.2882348895072937\n",
            "Training log: 37 epoch (23168 / 50000 train. data). Loss: 0.23586325347423553\n",
            "Training log: 37 epoch (34688 / 50000 train. data). Loss: 0.26180174946784973\n",
            "Training log: 37 epoch (46208 / 50000 train. data). Loss: 0.28508004546165466\n",
            "Test loss (avg): 3.5585545211791993, Accuracy: 0.517\n",
            "Training log: 38 epoch (128 / 50000 train. data). Loss: 0.36110109090805054\n",
            "Training log: 38 epoch (11648 / 50000 train. data). Loss: 0.28599604964256287\n",
            "Training log: 38 epoch (23168 / 50000 train. data). Loss: 0.25666001439094543\n",
            "Training log: 38 epoch (34688 / 50000 train. data). Loss: 0.2731231153011322\n",
            "Training log: 38 epoch (46208 / 50000 train. data). Loss: 0.3146917223930359\n",
            "Test loss (avg): 3.438968158340454, Accuracy: 0.5204\n",
            "Training log: 39 epoch (128 / 50000 train. data). Loss: 0.3599874973297119\n",
            "Training log: 39 epoch (11648 / 50000 train. data). Loss: 0.1199212297797203\n",
            "Training log: 39 epoch (23168 / 50000 train. data). Loss: 0.16325540840625763\n",
            "Training log: 39 epoch (34688 / 50000 train. data). Loss: 0.13280722498893738\n",
            "Training log: 39 epoch (46208 / 50000 train. data). Loss: 0.10973423719406128\n",
            "Test loss (avg): 3.4763642585754395, Accuracy: 0.5167\n",
            "Training log: 40 epoch (128 / 50000 train. data). Loss: 0.22292864322662354\n",
            "Training log: 40 epoch (11648 / 50000 train. data). Loss: 0.2816005349159241\n",
            "Training log: 40 epoch (23168 / 50000 train. data). Loss: 0.2528141736984253\n",
            "Training log: 40 epoch (34688 / 50000 train. data). Loss: 0.32487577199935913\n",
            "Training log: 40 epoch (46208 / 50000 train. data). Loss: 0.34808260202407837\n",
            "Test loss (avg): 3.4614085847854614, Accuracy: 0.5318\n",
            "Training log: 41 epoch (128 / 50000 train. data). Loss: 0.2499249428510666\n",
            "Training log: 41 epoch (11648 / 50000 train. data). Loss: 0.11939430236816406\n",
            "Training log: 41 epoch (23168 / 50000 train. data). Loss: 0.41392019391059875\n",
            "Training log: 41 epoch (34688 / 50000 train. data). Loss: 0.2667926549911499\n",
            "Training log: 41 epoch (46208 / 50000 train. data). Loss: 0.6288001537322998\n",
            "Test loss (avg): 3.6039711036682127, Accuracy: 0.5204\n",
            "Training log: 42 epoch (128 / 50000 train. data). Loss: 0.22485941648483276\n",
            "Training log: 42 epoch (11648 / 50000 train. data). Loss: 0.5149792432785034\n",
            "Training log: 42 epoch (23168 / 50000 train. data). Loss: 0.2766464948654175\n",
            "Training log: 42 epoch (34688 / 50000 train. data). Loss: 0.28937119245529175\n",
            "Training log: 42 epoch (46208 / 50000 train. data). Loss: 0.33607351779937744\n",
            "Test loss (avg): 3.765281262207031, Accuracy: 0.5097\n",
            "Training log: 43 epoch (128 / 50000 train. data). Loss: 0.23453126847743988\n",
            "Training log: 43 epoch (11648 / 50000 train. data). Loss: 0.3057509660720825\n",
            "Training log: 43 epoch (23168 / 50000 train. data). Loss: 0.20569032430648804\n",
            "Training log: 43 epoch (34688 / 50000 train. data). Loss: 0.5320048928260803\n",
            "Training log: 43 epoch (46208 / 50000 train. data). Loss: 0.3331907093524933\n",
            "Test loss (avg): 3.5360368930816652, Accuracy: 0.5282\n",
            "Training log: 44 epoch (128 / 50000 train. data). Loss: 0.11248619854450226\n",
            "Training log: 44 epoch (11648 / 50000 train. data). Loss: 0.09023518860340118\n",
            "Training log: 44 epoch (23168 / 50000 train. data). Loss: 0.29822975397109985\n",
            "Training log: 44 epoch (34688 / 50000 train. data). Loss: 0.1221826821565628\n",
            "Training log: 44 epoch (46208 / 50000 train. data). Loss: 0.3514986038208008\n",
            "Test loss (avg): 3.9164428718566895, Accuracy: 0.5126\n",
            "Training log: 45 epoch (128 / 50000 train. data). Loss: 0.28339719772338867\n",
            "Training log: 45 epoch (11648 / 50000 train. data). Loss: 0.20414191484451294\n",
            "Training log: 45 epoch (23168 / 50000 train. data). Loss: 0.13513997197151184\n",
            "Training log: 45 epoch (34688 / 50000 train. data). Loss: 0.20949006080627441\n",
            "Training log: 45 epoch (46208 / 50000 train. data). Loss: 0.21618178486824036\n",
            "Test loss (avg): 3.7895565204620363, Accuracy: 0.5272\n",
            "Training log: 46 epoch (128 / 50000 train. data). Loss: 0.18559019267559052\n",
            "Training log: 46 epoch (11648 / 50000 train. data). Loss: 0.4914276599884033\n",
            "Training log: 46 epoch (23168 / 50000 train. data). Loss: 0.33867260813713074\n",
            "Training log: 46 epoch (34688 / 50000 train. data). Loss: 0.25182315707206726\n",
            "Training log: 46 epoch (46208 / 50000 train. data). Loss: 0.17031534016132355\n",
            "Test loss (avg): 3.8665988357543943, Accuracy: 0.5198\n",
            "Training log: 47 epoch (128 / 50000 train. data). Loss: 0.1594715118408203\n",
            "Training log: 47 epoch (11648 / 50000 train. data). Loss: 0.25920701026916504\n",
            "Training log: 47 epoch (23168 / 50000 train. data). Loss: 0.08570413291454315\n",
            "Training log: 47 epoch (34688 / 50000 train. data). Loss: 0.15498539805412292\n",
            "Training log: 47 epoch (46208 / 50000 train. data). Loss: 0.41172167658805847\n",
            "Test loss (avg): 4.113865311431884, Accuracy: 0.523\n",
            "Training log: 48 epoch (128 / 50000 train. data). Loss: 0.4655446410179138\n",
            "Training log: 48 epoch (11648 / 50000 train. data). Loss: 0.2629392743110657\n",
            "Training log: 48 epoch (23168 / 50000 train. data). Loss: 0.2495461404323578\n",
            "Training log: 48 epoch (34688 / 50000 train. data). Loss: 0.5435217618942261\n",
            "Training log: 48 epoch (46208 / 50000 train. data). Loss: 0.36795249581336975\n",
            "Test loss (avg): 3.913687112045288, Accuracy: 0.5306\n",
            "Training log: 49 epoch (128 / 50000 train. data). Loss: 0.15905514359474182\n",
            "Training log: 49 epoch (11648 / 50000 train. data). Loss: 0.5013923048973083\n",
            "Training log: 49 epoch (23168 / 50000 train. data). Loss: 0.2852335572242737\n",
            "Training log: 49 epoch (34688 / 50000 train. data). Loss: 0.39682909846305847\n",
            "Training log: 49 epoch (46208 / 50000 train. data). Loss: 0.1210685670375824\n",
            "Test loss (avg): 4.070755319976807, Accuracy: 0.5257\n",
            "Training log: 50 epoch (128 / 50000 train. data). Loss: 0.184312641620636\n",
            "Training log: 50 epoch (11648 / 50000 train. data). Loss: 0.3302912712097168\n",
            "Training log: 50 epoch (23168 / 50000 train. data). Loss: 0.15993079543113708\n",
            "Training log: 50 epoch (34688 / 50000 train. data). Loss: 0.41327106952667236\n",
            "Training log: 50 epoch (46208 / 50000 train. data). Loss: 0.48189422488212585\n",
            "Test loss (avg): 4.178868721008301, Accuracy: 0.5251\n",
            "{'train_loss': [tensor(1.4677, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.6810, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.2591, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.3572, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.2779, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.1970, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.8684, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.9638, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.9045, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.9641, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6962, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.9546, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.0140, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.8490, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4520, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5739, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5223, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6097, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3920, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4294, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7859, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6228, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5864, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4319, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5578, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2569, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2815, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2974, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4738, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2998, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5561, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2527, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3827, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3274, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2977, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3716, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2710, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2921, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4080, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3258, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3182, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2262, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.2615, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.1570, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.3286, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.1901, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.0816, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.1770, device='cuda:0', grad_fn=<NllLossBackward>)], 'test_loss': [1.4967425300598145, 1.494954673576355, 1.52002114944458, 1.487633968925476, 1.4586064998626709, 1.4643627628326417, 1.543122174835205, 1.5966974420547486, 1.589669041633606, 1.6125461267471313, 1.670376086616516, 1.6643767154693603, 1.727976321220398, 1.821005372619629, 1.9174661277770997, 1.844106360435486, 1.9456965267181396, 2.074491424560547, 2.153384369850159, 2.3008037441253664, 2.2452392990112306, 2.3221752815246584, 2.3902541542053224, 2.591886728477478, 2.5056385971069335, 2.5129575189590456, 2.6543737482070924, 2.7327394512176513, 2.86014708366394, 3.032406069946289, 2.934801036834717, 3.3544767219543457, 3.1268466884613035, 3.161347608566284, 3.184263037109375, 3.2766682273864745, 3.5585545211791993, 3.438968158340454, 3.4763642585754395, 3.4614085847854614, 3.6039711036682127, 3.765281262207031, 3.5360368930816652, 3.9164428718566895, 3.7895565204620363, 3.8665988357543943, 4.113865311431884, 3.913687112045288, 4.070755319976807, 4.178868721008301], 'test_acc': [0.4789, 0.4859, 0.4867, 0.4933, 0.5105, 0.5162, 0.511, 0.5157, 0.529, 0.5265, 0.5276, 0.5275, 0.5281, 0.525, 0.5222, 0.5373, 0.5279, 0.5223, 0.5273, 0.512, 0.5207, 0.5234, 0.5218, 0.5126, 0.5238, 0.5315, 0.5181, 0.5225, 0.5186, 0.5107, 0.5331, 0.5087, 0.5269, 0.5182, 0.5167, 0.5252, 0.517, 0.5204, 0.5167, 0.5318, 0.5204, 0.5097, 0.5282, 0.5126, 0.5272, 0.5198, 0.523, 0.5306, 0.5257, 0.5251]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVK8mIXTwRNU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "352ca70b-0931-4605-9be5-46e74418e15e"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MyNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "#        self.fc1 = torch.nn.Linear(32 * 32 * 3, 10)\n",
        "        self.fc1 = torch.nn.Linear(32 * 32 * 3, 1024)\n",
        "        self.fc2 = torch.nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         x = torch.sigmoid(x)\n",
        "#         x = self.fc2(x)\n",
        "        \n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 学習回数\n",
        "    epoch = 50\n",
        "\n",
        "    # 学習結果の保存用\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'test_loss': [],\n",
        "        'test_acc': [],\n",
        "    }\n",
        "\n",
        "    # ネットワークを構築\n",
        "    net: torch.nn.Module = MyNet()\n",
        "\n",
        "    # MNISTのデータローダーを取得\n",
        "    loaders = load_cifar10()\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)\n",
        "\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    net.to(device)\n",
        "    Tnet.to(device)\n",
        "\n",
        "    for e in range(epoch):\n",
        "\n",
        "        \"\"\" Training Part\"\"\"\n",
        "        loss = None\n",
        "        # 学習開始 (再開)\n",
        "        net.train(True)  # 引数は省略可能\n",
        "        for i, (data, target) in enumerate(loaders['train']):\n",
        "            \n",
        "            data = data.to(device)  # to GPU?\n",
        "            target = target.to(device)\n",
        "            max_model_outputs = Tnet(data)\n",
        "\n",
        "            data = data.view(-1, 32 * 32 * 3)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = net(data)\n",
        "#             loss = f.nll_loss(output, target)\n",
        "            loss = distillation_loss(output,max_model_outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "#             optimizer.zero_grad()\n",
        "#             output = net(data)\n",
        "#             loss = f.nll_loss(f.log_softmax(output, dim=1), target)\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "            \n",
        "\n",
        "            if i % 90 == 0:\n",
        "                print('Training log: {} epoch ({} / 50000 train. data). Loss: {}'.format(e+1,\n",
        "                                                                                         (i+1)*128,\n",
        "                                                                                         loss.item())\n",
        "                      )\n",
        "        history['train_loss'].append(loss)\n",
        "        \n",
        "        \"\"\" Test Part \"\"\"\n",
        "        # 学習のストップ\n",
        "        net.eval()  # または net.train(False) でも良い\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in loaders['test']:\n",
        "                data = data.to(device)  # to GPU?\n",
        "                target = target.to(device)\n",
        "                data = data.view(-1, 32 * 32 * 3)\n",
        "                output = net(data)\n",
        "                test_loss += f.nll_loss(f.log_softmax(output, dim=1), target, reduction='sum').item()\n",
        "                #テスト部分のロスは全て足して、最後に平均を取ることで、その学習(epoch)でのロスとしています。\n",
        "                \n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                #softmaxの確率出力の中で一番大きいニューロンのインデックスを取得\n",
        "                \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                #eqっていうのは、同じ値だとTrueをとる。\n",
        "\n",
        "        test_loss /= 10000\n",
        "\n",
        "        print('Test loss (avg): {}, Accuracy: {}'.format(test_loss,\n",
        "                                                         correct / 10000))\n",
        "\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(correct / 10000)\n",
        "    \n",
        "    #====== 保存 =======\n",
        "    torch.save(net.state_dict(), 'weight_distillationNN_gc.pth')\n",
        "\n",
        "    # 結果の出力と描画\n",
        "    print(history)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['train_loss'], label='train_loss')\n",
        "    plt.plot(range(1, epoch+1), history['test_loss'], label='test_loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss.png')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['test_acc'])\n",
        "    plt.title('test accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.savefig('test_acc.png')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training log: 3 epoch (23168 / 50000 train. data). Loss: 1.7005014419555664\n",
            "Training log: 3 epoch (34688 / 50000 train. data). Loss: 1.6652530431747437\n",
            "Training log: 3 epoch (46208 / 50000 train. data). Loss: 1.6148232221603394\n",
            "Test loss (avg): 1.38559228515625, Accuracy: 0.5052\n",
            "Training log: 4 epoch (128 / 50000 train. data). Loss: 1.7805817127227783\n",
            "Training log: 4 epoch (11648 / 50000 train. data). Loss: 1.7336387634277344\n",
            "Training log: 4 epoch (23168 / 50000 train. data). Loss: 1.5354456901550293\n",
            "Training log: 4 epoch (34688 / 50000 train. data). Loss: 1.5611542463302612\n",
            "Training log: 4 epoch (46208 / 50000 train. data). Loss: 1.660578966140747\n",
            "Test loss (avg): 1.3411638435363769, Accuracy: 0.5264\n",
            "Training log: 5 epoch (128 / 50000 train. data). Loss: 1.4069949388504028\n",
            "Training log: 5 epoch (11648 / 50000 train. data). Loss: 1.283648133277893\n",
            "Training log: 5 epoch (23168 / 50000 train. data). Loss: 1.5089713335037231\n",
            "Training log: 5 epoch (34688 / 50000 train. data). Loss: 1.1645339727401733\n",
            "Training log: 5 epoch (46208 / 50000 train. data). Loss: 1.4503536224365234\n",
            "Test loss (avg): 1.3339218517303466, Accuracy: 0.5274\n",
            "Training log: 6 epoch (128 / 50000 train. data). Loss: 1.2043159008026123\n",
            "Training log: 6 epoch (11648 / 50000 train. data). Loss: 1.4231688976287842\n",
            "Training log: 6 epoch (23168 / 50000 train. data). Loss: 1.3249868154525757\n",
            "Training log: 6 epoch (34688 / 50000 train. data). Loss: 1.4492000341415405\n",
            "Training log: 6 epoch (46208 / 50000 train. data). Loss: 1.435586929321289\n",
            "Test loss (avg): 1.3183014419555663, Accuracy: 0.5333\n",
            "Training log: 7 epoch (128 / 50000 train. data). Loss: 1.111462950706482\n",
            "Training log: 7 epoch (11648 / 50000 train. data). Loss: 1.2426561117172241\n",
            "Training log: 7 epoch (23168 / 50000 train. data). Loss: 1.1016393899917603\n",
            "Training log: 7 epoch (34688 / 50000 train. data). Loss: 1.230502963066101\n",
            "Training log: 7 epoch (46208 / 50000 train. data). Loss: 1.1470392942428589\n",
            "Test loss (avg): 1.3039298942565918, Accuracy: 0.5334\n",
            "Training log: 8 epoch (128 / 50000 train. data). Loss: 1.1134365797042847\n",
            "Training log: 8 epoch (11648 / 50000 train. data). Loss: 1.1356133222579956\n",
            "Training log: 8 epoch (23168 / 50000 train. data). Loss: 1.0021860599517822\n",
            "Training log: 8 epoch (34688 / 50000 train. data). Loss: 1.155527949333191\n",
            "Training log: 8 epoch (46208 / 50000 train. data). Loss: 1.1119375228881836\n",
            "Test loss (avg): 1.291631165122986, Accuracy: 0.5357\n",
            "Training log: 9 epoch (128 / 50000 train. data). Loss: 1.0459460020065308\n",
            "Training log: 9 epoch (11648 / 50000 train. data). Loss: 0.9641467928886414\n",
            "Training log: 9 epoch (23168 / 50000 train. data). Loss: 1.1325905323028564\n",
            "Training log: 9 epoch (34688 / 50000 train. data). Loss: 1.130860686302185\n",
            "Training log: 9 epoch (46208 / 50000 train. data). Loss: 1.1679744720458984\n",
            "Test loss (avg): 1.292490205001831, Accuracy: 0.5387\n",
            "Training log: 10 epoch (128 / 50000 train. data). Loss: 1.0000635385513306\n",
            "Training log: 10 epoch (11648 / 50000 train. data). Loss: 1.0598715543746948\n",
            "Training log: 10 epoch (23168 / 50000 train. data). Loss: 1.0078792572021484\n",
            "Training log: 10 epoch (34688 / 50000 train. data). Loss: 1.0174206495285034\n",
            "Training log: 10 epoch (46208 / 50000 train. data). Loss: 1.068068265914917\n",
            "Test loss (avg): 1.2674290071487426, Accuracy: 0.5485\n",
            "Training log: 11 epoch (128 / 50000 train. data). Loss: 0.936137318611145\n",
            "Training log: 11 epoch (11648 / 50000 train. data). Loss: 1.00971257686615\n",
            "Training log: 11 epoch (23168 / 50000 train. data). Loss: 1.0536059141159058\n",
            "Training log: 11 epoch (34688 / 50000 train. data). Loss: 0.8190895318984985\n",
            "Training log: 11 epoch (46208 / 50000 train. data). Loss: 0.9592722058296204\n",
            "Test loss (avg): 1.2669351499557495, Accuracy: 0.5459\n",
            "Training log: 12 epoch (128 / 50000 train. data). Loss: 0.8202487826347351\n",
            "Training log: 12 epoch (11648 / 50000 train. data). Loss: 0.9771063923835754\n",
            "Training log: 12 epoch (23168 / 50000 train. data). Loss: 0.9727384448051453\n",
            "Training log: 12 epoch (34688 / 50000 train. data). Loss: 0.9938938021659851\n",
            "Training log: 12 epoch (46208 / 50000 train. data). Loss: 0.9811857342720032\n",
            "Test loss (avg): 1.2822225231170654, Accuracy: 0.5472\n",
            "Training log: 13 epoch (128 / 50000 train. data). Loss: 0.9584542512893677\n",
            "Training log: 13 epoch (11648 / 50000 train. data). Loss: 0.8408164381980896\n",
            "Training log: 13 epoch (23168 / 50000 train. data). Loss: 0.8065519332885742\n",
            "Training log: 13 epoch (34688 / 50000 train. data). Loss: 1.0131090879440308\n",
            "Training log: 13 epoch (46208 / 50000 train. data). Loss: 0.9423120617866516\n",
            "Test loss (avg): 1.289782674407959, Accuracy: 0.5399\n",
            "Training log: 14 epoch (128 / 50000 train. data). Loss: 1.0027841329574585\n",
            "Training log: 14 epoch (11648 / 50000 train. data). Loss: 0.9354177713394165\n",
            "Training log: 14 epoch (23168 / 50000 train. data). Loss: 0.7742663621902466\n",
            "Training log: 14 epoch (34688 / 50000 train. data). Loss: 1.0795296430587769\n",
            "Training log: 14 epoch (46208 / 50000 train. data). Loss: 0.925379753112793\n",
            "Test loss (avg): 1.2791069835662843, Accuracy: 0.5421\n",
            "Training log: 15 epoch (128 / 50000 train. data). Loss: 0.9617681503295898\n",
            "Training log: 15 epoch (11648 / 50000 train. data). Loss: 0.8242782950401306\n",
            "Training log: 15 epoch (23168 / 50000 train. data). Loss: 0.817896842956543\n",
            "Training log: 15 epoch (34688 / 50000 train. data). Loss: 0.8366815447807312\n",
            "Training log: 15 epoch (46208 / 50000 train. data). Loss: 0.8349453210830688\n",
            "Test loss (avg): 1.2570140636444092, Accuracy: 0.5489\n",
            "Training log: 16 epoch (128 / 50000 train. data). Loss: 0.8698908090591431\n",
            "Training log: 16 epoch (11648 / 50000 train. data). Loss: 0.7849946022033691\n",
            "Training log: 16 epoch (23168 / 50000 train. data). Loss: 0.8211860060691833\n",
            "Training log: 16 epoch (34688 / 50000 train. data). Loss: 0.8114200830459595\n",
            "Training log: 16 epoch (46208 / 50000 train. data). Loss: 1.0456955432891846\n",
            "Test loss (avg): 1.2716633466720582, Accuracy: 0.5413\n",
            "Training log: 17 epoch (128 / 50000 train. data). Loss: 0.7713451981544495\n",
            "Training log: 17 epoch (11648 / 50000 train. data). Loss: 0.8907319903373718\n",
            "Training log: 17 epoch (23168 / 50000 train. data). Loss: 1.058251976966858\n",
            "Training log: 17 epoch (34688 / 50000 train. data). Loss: 0.7784491777420044\n",
            "Training log: 17 epoch (46208 / 50000 train. data). Loss: 0.7870106101036072\n",
            "Test loss (avg): 1.2570649709701538, Accuracy: 0.5514\n",
            "Training log: 18 epoch (128 / 50000 train. data). Loss: 0.6907334923744202\n",
            "Training log: 18 epoch (11648 / 50000 train. data). Loss: 0.6985813975334167\n",
            "Training log: 18 epoch (23168 / 50000 train. data). Loss: 0.7918407320976257\n",
            "Training log: 18 epoch (34688 / 50000 train. data). Loss: 0.7256379723548889\n",
            "Training log: 18 epoch (46208 / 50000 train. data). Loss: 0.7697295546531677\n",
            "Test loss (avg): 1.2561631534576416, Accuracy: 0.5504\n",
            "Training log: 19 epoch (128 / 50000 train. data). Loss: 0.7999266386032104\n",
            "Training log: 19 epoch (11648 / 50000 train. data). Loss: 0.7147925496101379\n",
            "Training log: 19 epoch (23168 / 50000 train. data). Loss: 0.8356807827949524\n",
            "Training log: 19 epoch (34688 / 50000 train. data). Loss: 0.7434629797935486\n",
            "Training log: 19 epoch (46208 / 50000 train. data). Loss: 0.7307361960411072\n",
            "Test loss (avg): 1.259212942314148, Accuracy: 0.554\n",
            "Training log: 20 epoch (128 / 50000 train. data). Loss: 0.7057458758354187\n",
            "Training log: 20 epoch (11648 / 50000 train. data). Loss: 0.687592625617981\n",
            "Training log: 20 epoch (23168 / 50000 train. data). Loss: 0.8375797271728516\n",
            "Training log: 20 epoch (34688 / 50000 train. data). Loss: 0.7884732484817505\n",
            "Training log: 20 epoch (46208 / 50000 train. data). Loss: 0.7615228891372681\n",
            "Test loss (avg): 1.249174845123291, Accuracy: 0.5542\n",
            "Training log: 21 epoch (128 / 50000 train. data). Loss: 0.7220178842544556\n",
            "Training log: 21 epoch (11648 / 50000 train. data). Loss: 0.6052691340446472\n",
            "Training log: 21 epoch (23168 / 50000 train. data). Loss: 0.6491919755935669\n",
            "Training log: 21 epoch (34688 / 50000 train. data). Loss: 0.6814696788787842\n",
            "Training log: 21 epoch (46208 / 50000 train. data). Loss: 0.7186174392700195\n",
            "Test loss (avg): 1.2444658613204955, Accuracy: 0.5573\n",
            "Training log: 22 epoch (128 / 50000 train. data). Loss: 0.6165528297424316\n",
            "Training log: 22 epoch (11648 / 50000 train. data). Loss: 0.5874382257461548\n",
            "Training log: 22 epoch (23168 / 50000 train. data). Loss: 0.6291465163230896\n",
            "Training log: 22 epoch (34688 / 50000 train. data). Loss: 0.70843505859375\n",
            "Training log: 22 epoch (46208 / 50000 train. data). Loss: 0.7170782685279846\n",
            "Test loss (avg): 1.255006164932251, Accuracy: 0.554\n",
            "Training log: 23 epoch (128 / 50000 train. data). Loss: 0.636094868183136\n",
            "Training log: 23 epoch (11648 / 50000 train. data). Loss: 0.5712215304374695\n",
            "Training log: 23 epoch (23168 / 50000 train. data). Loss: 0.5859079360961914\n",
            "Training log: 23 epoch (34688 / 50000 train. data). Loss: 0.6922874450683594\n",
            "Training log: 23 epoch (46208 / 50000 train. data). Loss: 0.7401493191719055\n",
            "Test loss (avg): 1.2539868574142456, Accuracy: 0.5534\n",
            "Training log: 24 epoch (128 / 50000 train. data). Loss: 0.5998477339744568\n",
            "Training log: 24 epoch (11648 / 50000 train. data). Loss: 0.6192144751548767\n",
            "Training log: 24 epoch (23168 / 50000 train. data). Loss: 0.6645769476890564\n",
            "Training log: 24 epoch (34688 / 50000 train. data). Loss: 0.6991206407546997\n",
            "Training log: 24 epoch (46208 / 50000 train. data). Loss: 0.8457586169242859\n",
            "Test loss (avg): 1.2521565399169923, Accuracy: 0.5516\n",
            "Training log: 25 epoch (128 / 50000 train. data). Loss: 0.6347044110298157\n",
            "Training log: 25 epoch (11648 / 50000 train. data). Loss: 0.559399425983429\n",
            "Training log: 25 epoch (23168 / 50000 train. data). Loss: 0.7184100151062012\n",
            "Training log: 25 epoch (34688 / 50000 train. data). Loss: 0.6038162112236023\n",
            "Training log: 25 epoch (46208 / 50000 train. data). Loss: 0.6685876250267029\n",
            "Test loss (avg): 1.235616516304016, Accuracy: 0.5597\n",
            "Training log: 26 epoch (128 / 50000 train. data). Loss: 0.5632414817810059\n",
            "Training log: 26 epoch (11648 / 50000 train. data). Loss: 0.5099512934684753\n",
            "Training log: 26 epoch (23168 / 50000 train. data). Loss: 0.7153972387313843\n",
            "Training log: 26 epoch (34688 / 50000 train. data). Loss: 0.5980765223503113\n",
            "Training log: 26 epoch (46208 / 50000 train. data). Loss: 0.6632653474807739\n",
            "Test loss (avg): 1.2300179723739624, Accuracy: 0.5586\n",
            "Training log: 27 epoch (128 / 50000 train. data). Loss: 0.4958338737487793\n",
            "Training log: 27 epoch (11648 / 50000 train. data). Loss: 0.6040000319480896\n",
            "Training log: 27 epoch (23168 / 50000 train. data). Loss: 0.5905047655105591\n",
            "Training log: 27 epoch (34688 / 50000 train. data). Loss: 0.5802225470542908\n",
            "Training log: 27 epoch (46208 / 50000 train. data). Loss: 0.5690719485282898\n",
            "Test loss (avg): 1.2268740367889404, Accuracy: 0.5662\n",
            "Training log: 28 epoch (128 / 50000 train. data). Loss: 0.5455288290977478\n",
            "Training log: 28 epoch (11648 / 50000 train. data). Loss: 0.602296769618988\n",
            "Training log: 28 epoch (23168 / 50000 train. data). Loss: 0.5163050889968872\n",
            "Training log: 28 epoch (34688 / 50000 train. data). Loss: 0.5891170501708984\n",
            "Training log: 28 epoch (46208 / 50000 train. data). Loss: 0.6965989470481873\n",
            "Test loss (avg): 1.2396562105178832, Accuracy: 0.5624\n",
            "Training log: 29 epoch (128 / 50000 train. data). Loss: 0.5536750555038452\n",
            "Training log: 29 epoch (11648 / 50000 train. data). Loss: 0.6032814979553223\n",
            "Training log: 29 epoch (23168 / 50000 train. data). Loss: 0.4935820698738098\n",
            "Training log: 29 epoch (34688 / 50000 train. data). Loss: 0.6758170127868652\n",
            "Training log: 29 epoch (46208 / 50000 train. data). Loss: 0.5349651575088501\n",
            "Test loss (avg): 1.2213183864593506, Accuracy: 0.5645\n",
            "Training log: 30 epoch (128 / 50000 train. data). Loss: 0.4277288615703583\n",
            "Training log: 30 epoch (11648 / 50000 train. data). Loss: 0.6399983763694763\n",
            "Training log: 30 epoch (23168 / 50000 train. data). Loss: 0.5803430676460266\n",
            "Training log: 30 epoch (34688 / 50000 train. data). Loss: 0.545756995677948\n",
            "Training log: 30 epoch (46208 / 50000 train. data). Loss: 0.5885675549507141\n",
            "Test loss (avg): 1.2248061115264892, Accuracy: 0.5655\n",
            "Training log: 31 epoch (128 / 50000 train. data). Loss: 0.5130392909049988\n",
            "Training log: 31 epoch (11648 / 50000 train. data). Loss: 0.5439713597297668\n",
            "Training log: 31 epoch (23168 / 50000 train. data). Loss: 0.6071643829345703\n",
            "Training log: 31 epoch (34688 / 50000 train. data). Loss: 0.5858861207962036\n",
            "Training log: 31 epoch (46208 / 50000 train. data). Loss: 0.5481873750686646\n",
            "Test loss (avg): 1.234661092567444, Accuracy: 0.555\n",
            "Training log: 32 epoch (128 / 50000 train. data). Loss: 0.5118058323860168\n",
            "Training log: 32 epoch (11648 / 50000 train. data). Loss: 0.5026269555091858\n",
            "Training log: 32 epoch (23168 / 50000 train. data). Loss: 0.5201810598373413\n",
            "Training log: 32 epoch (34688 / 50000 train. data). Loss: 0.6067332625389099\n",
            "Training log: 32 epoch (46208 / 50000 train. data). Loss: 0.5426570773124695\n",
            "Test loss (avg): 1.2431990047454835, Accuracy: 0.5589\n",
            "Training log: 33 epoch (128 / 50000 train. data). Loss: 0.460566908121109\n",
            "Training log: 33 epoch (11648 / 50000 train. data). Loss: 0.5174049735069275\n",
            "Training log: 33 epoch (23168 / 50000 train. data). Loss: 0.6567343473434448\n",
            "Training log: 33 epoch (34688 / 50000 train. data). Loss: 0.5029605031013489\n",
            "Training log: 33 epoch (46208 / 50000 train. data). Loss: 0.6392435431480408\n",
            "Test loss (avg): 1.237124481010437, Accuracy: 0.5555\n",
            "Training log: 34 epoch (128 / 50000 train. data). Loss: 0.5112383961677551\n",
            "Training log: 34 epoch (11648 / 50000 train. data). Loss: 0.5741342306137085\n",
            "Training log: 34 epoch (23168 / 50000 train. data). Loss: 0.4754929542541504\n",
            "Training log: 34 epoch (34688 / 50000 train. data). Loss: 0.4902682900428772\n",
            "Training log: 34 epoch (46208 / 50000 train. data). Loss: 0.44876718521118164\n",
            "Test loss (avg): 1.2390705808639526, Accuracy: 0.5573\n",
            "Training log: 35 epoch (128 / 50000 train. data). Loss: 0.4729740619659424\n",
            "Training log: 35 epoch (11648 / 50000 train. data). Loss: 0.4640088975429535\n",
            "Training log: 35 epoch (23168 / 50000 train. data). Loss: 0.5105604529380798\n",
            "Training log: 35 epoch (34688 / 50000 train. data). Loss: 0.5099584460258484\n",
            "Training log: 35 epoch (46208 / 50000 train. data). Loss: 0.4391578733921051\n",
            "Test loss (avg): 1.2324632743835449, Accuracy: 0.561\n",
            "Training log: 36 epoch (128 / 50000 train. data). Loss: 0.47479429841041565\n",
            "Training log: 36 epoch (11648 / 50000 train. data). Loss: 0.43575960397720337\n",
            "Training log: 36 epoch (23168 / 50000 train. data). Loss: 0.4610430896282196\n",
            "Training log: 36 epoch (34688 / 50000 train. data). Loss: 0.5011534094810486\n",
            "Training log: 36 epoch (46208 / 50000 train. data). Loss: 0.4775664508342743\n",
            "Test loss (avg): 1.222352642250061, Accuracy: 0.5676\n",
            "Training log: 37 epoch (128 / 50000 train. data). Loss: 0.43016624450683594\n",
            "Training log: 37 epoch (11648 / 50000 train. data). Loss: 0.48160943388938904\n",
            "Training log: 37 epoch (23168 / 50000 train. data). Loss: 0.4073038101196289\n",
            "Training log: 37 epoch (34688 / 50000 train. data). Loss: 0.46673551201820374\n",
            "Training log: 37 epoch (46208 / 50000 train. data). Loss: 0.5358237028121948\n",
            "Test loss (avg): 1.2353675191879272, Accuracy: 0.5607\n",
            "Training log: 38 epoch (128 / 50000 train. data). Loss: 0.4484716057777405\n",
            "Training log: 38 epoch (11648 / 50000 train. data). Loss: 0.5232237577438354\n",
            "Training log: 38 epoch (23168 / 50000 train. data). Loss: 0.4430140554904938\n",
            "Training log: 38 epoch (34688 / 50000 train. data). Loss: 0.5601038932800293\n",
            "Training log: 38 epoch (46208 / 50000 train. data). Loss: 0.5101048350334167\n",
            "Test loss (avg): 1.2224511852264404, Accuracy: 0.5666\n",
            "Training log: 39 epoch (128 / 50000 train. data). Loss: 0.420702189207077\n",
            "Training log: 39 epoch (11648 / 50000 train. data). Loss: 0.4236762523651123\n",
            "Training log: 39 epoch (23168 / 50000 train. data). Loss: 0.43634119629859924\n",
            "Training log: 39 epoch (34688 / 50000 train. data). Loss: 0.459261417388916\n",
            "Training log: 39 epoch (46208 / 50000 train. data). Loss: 0.5524781346321106\n",
            "Test loss (avg): 1.22891812210083, Accuracy: 0.5665\n",
            "Training log: 40 epoch (128 / 50000 train. data). Loss: 0.4881289601325989\n",
            "Training log: 40 epoch (11648 / 50000 train. data). Loss: 0.4016488492488861\n",
            "Training log: 40 epoch (23168 / 50000 train. data). Loss: 0.44538089632987976\n",
            "Training log: 40 epoch (34688 / 50000 train. data). Loss: 0.43983545899391174\n",
            "Training log: 40 epoch (46208 / 50000 train. data). Loss: 0.5086153149604797\n",
            "Test loss (avg): 1.2302306303024293, Accuracy: 0.5652\n",
            "Training log: 41 epoch (128 / 50000 train. data). Loss: 0.43629932403564453\n",
            "Training log: 41 epoch (11648 / 50000 train. data). Loss: 0.3822577893733978\n",
            "Training log: 41 epoch (23168 / 50000 train. data). Loss: 0.4416584074497223\n",
            "Training log: 41 epoch (34688 / 50000 train. data). Loss: 0.4760912358760834\n",
            "Training log: 41 epoch (46208 / 50000 train. data). Loss: 0.4617653787136078\n",
            "Test loss (avg): 1.2257481903076173, Accuracy: 0.5624\n",
            "Training log: 42 epoch (128 / 50000 train. data). Loss: 0.442967027425766\n",
            "Training log: 42 epoch (11648 / 50000 train. data). Loss: 0.34542688727378845\n",
            "Training log: 42 epoch (23168 / 50000 train. data). Loss: 0.4374978244304657\n",
            "Training log: 42 epoch (34688 / 50000 train. data). Loss: 0.4046667218208313\n",
            "Training log: 42 epoch (46208 / 50000 train. data). Loss: 0.45231157541275024\n",
            "Test loss (avg): 1.2300862297058106, Accuracy: 0.563\n",
            "Training log: 43 epoch (128 / 50000 train. data). Loss: 0.4160219132900238\n",
            "Training log: 43 epoch (11648 / 50000 train. data). Loss: 0.4196627140045166\n",
            "Training log: 43 epoch (23168 / 50000 train. data). Loss: 0.4453328549861908\n",
            "Training log: 43 epoch (34688 / 50000 train. data). Loss: 0.4109829068183899\n",
            "Training log: 43 epoch (46208 / 50000 train. data). Loss: 0.4170478880405426\n",
            "Test loss (avg): 1.2356676725387574, Accuracy: 0.559\n",
            "Training log: 44 epoch (128 / 50000 train. data). Loss: 0.3887365758419037\n",
            "Training log: 44 epoch (11648 / 50000 train. data). Loss: 0.3666265904903412\n",
            "Training log: 44 epoch (23168 / 50000 train. data). Loss: 0.37830281257629395\n",
            "Training log: 44 epoch (34688 / 50000 train. data). Loss: 0.593559205532074\n",
            "Training log: 44 epoch (46208 / 50000 train. data). Loss: 0.45784425735473633\n",
            "Test loss (avg): 1.2289868793487548, Accuracy: 0.5647\n",
            "Training log: 45 epoch (128 / 50000 train. data). Loss: 0.34823301434516907\n",
            "Training log: 45 epoch (11648 / 50000 train. data). Loss: 0.37067991495132446\n",
            "Training log: 45 epoch (23168 / 50000 train. data). Loss: 0.5753830075263977\n",
            "Training log: 45 epoch (34688 / 50000 train. data). Loss: 0.3957254886627197\n",
            "Training log: 45 epoch (46208 / 50000 train. data). Loss: 0.40675926208496094\n",
            "Test loss (avg): 1.2469956838607787, Accuracy: 0.5562\n",
            "Training log: 46 epoch (128 / 50000 train. data). Loss: 0.44684821367263794\n",
            "Training log: 46 epoch (11648 / 50000 train. data). Loss: 0.35389968752861023\n",
            "Training log: 46 epoch (23168 / 50000 train. data). Loss: 0.39674997329711914\n",
            "Training log: 46 epoch (34688 / 50000 train. data). Loss: 0.44136449694633484\n",
            "Training log: 46 epoch (46208 / 50000 train. data). Loss: 0.3988471031188965\n",
            "Test loss (avg): 1.2340815395355225, Accuracy: 0.5573\n",
            "Training log: 47 epoch (128 / 50000 train. data). Loss: 0.36777934432029724\n",
            "Training log: 47 epoch (11648 / 50000 train. data). Loss: 0.4252355694770813\n",
            "Training log: 47 epoch (23168 / 50000 train. data). Loss: 0.3697342276573181\n",
            "Training log: 47 epoch (34688 / 50000 train. data). Loss: 0.42633768916130066\n",
            "Training log: 47 epoch (46208 / 50000 train. data). Loss: 0.4223065972328186\n",
            "Test loss (avg): 1.2337452495574952, Accuracy: 0.5617\n",
            "Training log: 48 epoch (128 / 50000 train. data). Loss: 0.402170866727829\n",
            "Training log: 48 epoch (11648 / 50000 train. data). Loss: 0.5782194137573242\n",
            "Training log: 48 epoch (23168 / 50000 train. data). Loss: 0.4442909359931946\n",
            "Training log: 48 epoch (34688 / 50000 train. data). Loss: 0.4151268005371094\n",
            "Training log: 48 epoch (46208 / 50000 train. data). Loss: 0.4255952835083008\n",
            "Test loss (avg): 1.217726072883606, Accuracy: 0.5661\n",
            "Training log: 49 epoch (128 / 50000 train. data). Loss: 0.37635985016822815\n",
            "Training log: 49 epoch (11648 / 50000 train. data). Loss: 0.40397724509239197\n",
            "Training log: 49 epoch (23168 / 50000 train. data). Loss: 0.38639137148857117\n",
            "Training log: 49 epoch (34688 / 50000 train. data). Loss: 0.3664720058441162\n",
            "Training log: 49 epoch (46208 / 50000 train. data). Loss: 0.34079059958457947\n",
            "Test loss (avg): 1.233884352493286, Accuracy: 0.563\n",
            "Training log: 50 epoch (128 / 50000 train. data). Loss: 0.3161064088344574\n",
            "Training log: 50 epoch (11648 / 50000 train. data). Loss: 0.318796843290329\n",
            "Training log: 50 epoch (23168 / 50000 train. data). Loss: 0.404806911945343\n",
            "Training log: 50 epoch (34688 / 50000 train. data). Loss: 0.4329231381416321\n",
            "Training log: 50 epoch (46208 / 50000 train. data). Loss: 0.35644403100013733\n",
            "Test loss (avg): 1.2364396900177002, Accuracy: 0.5603\n",
            "{'train_loss': [tensor(2.0804, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.8756, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.5179, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.6570, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.6124, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.3263, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.2633, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.1606, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.0650, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.9358, device='cuda:0', grad_fn=<MeanBackward0>), tensor(1.0395, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.8351, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.9565, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.9028, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.8411, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5435, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4719, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4985, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5147, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5020, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5271, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4833, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4760, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.3921, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.3750, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4522, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4019, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4017, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.3733, device='cuda:0', grad_fn=<MeanBackward0>), tensor(0.4471, device='cuda:0', grad_fn=<MeanBackward0>)], 'test_loss': [1.4645259103775023, 1.3920973655700684, 1.38559228515625, 1.3411638435363769, 1.3339218517303466, 1.3183014419555663, 1.3039298942565918, 1.291631165122986, 1.292490205001831, 1.2674290071487426, 1.2669351499557495, 1.2822225231170654, 1.289782674407959, 1.2791069835662843, 1.2570140636444092, 1.2716633466720582, 1.2570649709701538, 1.2561631534576416, 1.259212942314148, 1.249174845123291, 1.2444658613204955, 1.255006164932251, 1.2539868574142456, 1.2521565399169923, 1.235616516304016, 1.2300179723739624, 1.2268740367889404, 1.2396562105178832, 1.2213183864593506, 1.2248061115264892, 1.234661092567444, 1.2431990047454835, 1.237124481010437, 1.2390705808639526, 1.2324632743835449, 1.222352642250061, 1.2353675191879272, 1.2224511852264404, 1.22891812210083, 1.2302306303024293, 1.2257481903076173, 1.2300862297058106, 1.2356676725387574, 1.2289868793487548, 1.2469956838607787, 1.2340815395355225, 1.2337452495574952, 1.217726072883606, 1.233884352493286, 1.2364396900177002], 'test_acc': [0.4741, 0.5024, 0.5052, 0.5264, 0.5274, 0.5333, 0.5334, 0.5357, 0.5387, 0.5485, 0.5459, 0.5472, 0.5399, 0.5421, 0.5489, 0.5413, 0.5514, 0.5504, 0.554, 0.5542, 0.5573, 0.554, 0.5534, 0.5516, 0.5597, 0.5586, 0.5662, 0.5624, 0.5645, 0.5655, 0.555, 0.5589, 0.5555, 0.5573, 0.561, 0.5676, 0.5607, 0.5666, 0.5665, 0.5652, 0.5624, 0.563, 0.559, 0.5647, 0.5562, 0.5573, 0.5617, 0.5661, 0.563, 0.5603]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTWK4Nn1wRVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b347978-959c-4782-d86f-523ebf75cdbc"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class MyNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "#        self.fc1 = torch.nn.Linear(32 * 32 * 3, 10)\n",
        "        self.fc1 = torch.nn.Linear(32 * 32 * 3, 1024)\n",
        "        self.fc2 = torch.nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         x = torch.sigmoid(x)\n",
        "#         x = self.fc2(x)\n",
        "        \n",
        "        x = f.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 学習回数\n",
        "    epoch = 50\n",
        "\n",
        "    # 学習結果の保存用\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'test_loss': [],\n",
        "        'test_acc': [],\n",
        "    }\n",
        "\n",
        "    # ネットワークを構築\n",
        "    net: torch.nn.Module = MyNet()\n",
        "\n",
        "    # MNISTのデータローダーを取得\n",
        "    loaders = load_cifar10()\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)\n",
        "\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    net.to(device)\n",
        "    Tnet.to(device)\n",
        "\n",
        "    for e in range(epoch):\n",
        "\n",
        "        \"\"\" Training Part\"\"\"\n",
        "        loss = None\n",
        "        # 学習開始 (再開)\n",
        "        net.train(True)  # 引数は省略可能\n",
        "        for i, (data, target) in enumerate(loaders['train']):\n",
        "            data = data.to(device)  # to GPU?\n",
        "            target = target.to(device)\n",
        "            Tnet.to(device)\n",
        "            max_model_outputs = Tnet(data)\n",
        "            data = data.view(-1, 32 * 32 * 3)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = net(data)\n",
        "#             loss = f.nll_loss(output, target)\n",
        "            loss = distillation_loss(output,max_model_outputs)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            output = net(data)\n",
        "            loss = f.nll_loss(f.log_softmax(output, dim=1), target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "\n",
        "            if i % 90 == 0:\n",
        "                print('Training log: {} epoch ({} / 50000 train. data). Loss: {}'.format(e+1,\n",
        "                                                                                         (i+1)*128,\n",
        "                                                                                         loss.item())\n",
        "                      )\n",
        "        history['train_loss'].append(loss)\n",
        "        \n",
        "        \"\"\" Test Part \"\"\"\n",
        "        # 学習のストップ\n",
        "        net.eval()  # または net.train(False) でも良い\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in loaders['test']:\n",
        "                data = data.to(device)  # to GPU?\n",
        "                target = target.to(device)\n",
        "                data = data.view(-1, 32 * 32 * 3)\n",
        "                output = net(data)\n",
        "                test_loss += f.nll_loss(f.log_softmax(output, dim=1), target, reduction='sum').item()\n",
        "                #テスト部分のロスは全て足して、最後に平均を取ることで、その学習(epoch)でのロスとしています。\n",
        "                \n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                #softmaxの確率出力の中で一番大きいニューロンのインデックスを取得\n",
        "                \n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "                #eqっていうのは、同じ値だとTrueをとる。\n",
        "\n",
        "        test_loss /= 10000\n",
        "\n",
        "        print('Test loss (avg): {}, Accuracy: {}'.format(test_loss,\n",
        "                                                         correct / 10000))\n",
        "\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(correct / 10000)\n",
        "    \n",
        "    #====== 保存 =======\n",
        "    torch.save(net.state_dict(), 'weight_distillationNN2_gc.pth')\n",
        "\n",
        "    # 結果の出力と描画\n",
        "    print(history)\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['train_loss'], label='train_loss')\n",
        "    plt.plot(range(1, epoch+1), history['test_loss'], label='test_loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss.png')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['test_acc'])\n",
        "    plt.title('test accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.savefig('test_acc.png')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training log: 4 epoch (34688 / 50000 train. data). Loss: 1.2597301006317139\n",
            "Training log: 4 epoch (46208 / 50000 train. data). Loss: 1.280426025390625\n",
            "Test loss (avg): 1.3359144353866577, Accuracy: 0.5262\n",
            "Training log: 5 epoch (128 / 50000 train. data). Loss: 1.0619409084320068\n",
            "Training log: 5 epoch (11648 / 50000 train. data). Loss: 1.0885905027389526\n",
            "Training log: 5 epoch (23168 / 50000 train. data). Loss: 1.0088083744049072\n",
            "Training log: 5 epoch (34688 / 50000 train. data). Loss: 1.2269073724746704\n",
            "Training log: 5 epoch (46208 / 50000 train. data). Loss: 1.275286316871643\n",
            "Test loss (avg): 1.2947766540527343, Accuracy: 0.5408\n",
            "Training log: 6 epoch (128 / 50000 train. data). Loss: 1.297997236251831\n",
            "Training log: 6 epoch (11648 / 50000 train. data). Loss: 1.2189624309539795\n",
            "Training log: 6 epoch (23168 / 50000 train. data). Loss: 1.1380897760391235\n",
            "Training log: 6 epoch (34688 / 50000 train. data). Loss: 1.1141806840896606\n",
            "Training log: 6 epoch (46208 / 50000 train. data). Loss: 1.0553473234176636\n",
            "Test loss (avg): 1.3276174215316772, Accuracy: 0.5291\n",
            "Training log: 7 epoch (128 / 50000 train. data). Loss: 0.9562618732452393\n",
            "Training log: 7 epoch (11648 / 50000 train. data). Loss: 1.122475028038025\n",
            "Training log: 7 epoch (23168 / 50000 train. data). Loss: 0.9841474294662476\n",
            "Training log: 7 epoch (34688 / 50000 train. data). Loss: 1.1023554801940918\n",
            "Training log: 7 epoch (46208 / 50000 train. data). Loss: 1.1851692199707031\n",
            "Test loss (avg): 1.2817119678497315, Accuracy: 0.5424\n",
            "Training log: 8 epoch (128 / 50000 train. data). Loss: 1.1497180461883545\n",
            "Training log: 8 epoch (11648 / 50000 train. data). Loss: 0.877407968044281\n",
            "Training log: 8 epoch (23168 / 50000 train. data). Loss: 0.8808689713478088\n",
            "Training log: 8 epoch (34688 / 50000 train. data). Loss: 0.8976154923439026\n",
            "Training log: 8 epoch (46208 / 50000 train. data). Loss: 1.0932586193084717\n",
            "Test loss (avg): 1.2741982719421387, Accuracy: 0.5479\n",
            "Training log: 9 epoch (128 / 50000 train. data). Loss: 0.9975789189338684\n",
            "Training log: 9 epoch (11648 / 50000 train. data). Loss: 1.0988116264343262\n",
            "Training log: 9 epoch (23168 / 50000 train. data). Loss: 1.057705283164978\n",
            "Training log: 9 epoch (34688 / 50000 train. data). Loss: 0.8460656404495239\n",
            "Training log: 9 epoch (46208 / 50000 train. data). Loss: 1.026970386505127\n",
            "Test loss (avg): 1.263942109298706, Accuracy: 0.5553\n",
            "Training log: 10 epoch (128 / 50000 train. data). Loss: 0.973101794719696\n",
            "Training log: 10 epoch (11648 / 50000 train. data). Loss: 0.8541725873947144\n",
            "Training log: 10 epoch (23168 / 50000 train. data). Loss: 1.0550869703292847\n",
            "Training log: 10 epoch (34688 / 50000 train. data). Loss: 0.8034859299659729\n",
            "Training log: 10 epoch (46208 / 50000 train. data). Loss: 1.1047602891921997\n",
            "Test loss (avg): 1.2535454780578614, Accuracy: 0.5527\n",
            "Training log: 11 epoch (128 / 50000 train. data). Loss: 1.0210504531860352\n",
            "Training log: 11 epoch (11648 / 50000 train. data). Loss: 0.9945392608642578\n",
            "Training log: 11 epoch (23168 / 50000 train. data). Loss: 0.9410807490348816\n",
            "Training log: 11 epoch (34688 / 50000 train. data). Loss: 0.9463117122650146\n",
            "Training log: 11 epoch (46208 / 50000 train. data). Loss: 0.9135669469833374\n",
            "Test loss (avg): 1.236247985458374, Accuracy: 0.5638\n",
            "Training log: 12 epoch (128 / 50000 train. data). Loss: 0.8768175840377808\n",
            "Training log: 12 epoch (11648 / 50000 train. data). Loss: 0.9896612763404846\n",
            "Training log: 12 epoch (23168 / 50000 train. data). Loss: 0.8384464979171753\n",
            "Training log: 12 epoch (34688 / 50000 train. data). Loss: 0.8810411691665649\n",
            "Training log: 12 epoch (46208 / 50000 train. data). Loss: 0.8801655769348145\n",
            "Test loss (avg): 1.23187216796875, Accuracy: 0.5697\n",
            "Training log: 13 epoch (128 / 50000 train. data). Loss: 0.8445488214492798\n",
            "Training log: 13 epoch (11648 / 50000 train. data). Loss: 0.9537612199783325\n",
            "Training log: 13 epoch (23168 / 50000 train. data). Loss: 0.7947772145271301\n",
            "Training log: 13 epoch (34688 / 50000 train. data). Loss: 1.031329870223999\n",
            "Training log: 13 epoch (46208 / 50000 train. data). Loss: 0.8545918464660645\n",
            "Test loss (avg): 1.2868680683135987, Accuracy: 0.5471\n",
            "Training log: 14 epoch (128 / 50000 train. data). Loss: 0.8195335268974304\n",
            "Training log: 14 epoch (11648 / 50000 train. data). Loss: 0.9253455996513367\n",
            "Training log: 14 epoch (23168 / 50000 train. data). Loss: 1.0185621976852417\n",
            "Training log: 14 epoch (34688 / 50000 train. data). Loss: 0.8178753852844238\n",
            "Training log: 14 epoch (46208 / 50000 train. data). Loss: 0.8852826952934265\n",
            "Test loss (avg): 1.281037692642212, Accuracy: 0.5479\n",
            "Training log: 15 epoch (128 / 50000 train. data). Loss: 0.9125052690505981\n",
            "Training log: 15 epoch (11648 / 50000 train. data). Loss: 0.9002354145050049\n",
            "Training log: 15 epoch (23168 / 50000 train. data). Loss: 0.8015491962432861\n",
            "Training log: 15 epoch (34688 / 50000 train. data). Loss: 0.7549795508384705\n",
            "Training log: 15 epoch (46208 / 50000 train. data). Loss: 0.8767396807670593\n",
            "Test loss (avg): 1.2306186254501343, Accuracy: 0.5733\n",
            "Training log: 16 epoch (128 / 50000 train. data). Loss: 0.7961320281028748\n",
            "Training log: 16 epoch (11648 / 50000 train. data). Loss: 0.7952377796173096\n",
            "Training log: 16 epoch (23168 / 50000 train. data). Loss: 1.0117688179016113\n",
            "Training log: 16 epoch (34688 / 50000 train. data). Loss: 0.9650906324386597\n",
            "Training log: 16 epoch (46208 / 50000 train. data). Loss: 0.8988253474235535\n",
            "Test loss (avg): 1.2260435438156128, Accuracy: 0.5696\n",
            "Training log: 17 epoch (128 / 50000 train. data). Loss: 0.7844728231430054\n",
            "Training log: 17 epoch (11648 / 50000 train. data). Loss: 0.8058947324752808\n",
            "Training log: 17 epoch (23168 / 50000 train. data). Loss: 0.8794392347335815\n",
            "Training log: 17 epoch (34688 / 50000 train. data). Loss: 0.8171283602714539\n",
            "Training log: 17 epoch (46208 / 50000 train. data). Loss: 0.8491906523704529\n",
            "Test loss (avg): 1.2261659616470337, Accuracy: 0.5711\n",
            "Training log: 18 epoch (128 / 50000 train. data). Loss: 0.8745430111885071\n",
            "Training log: 18 epoch (11648 / 50000 train. data). Loss: 0.8253409266471863\n",
            "Training log: 18 epoch (23168 / 50000 train. data). Loss: 0.7388087511062622\n",
            "Training log: 18 epoch (34688 / 50000 train. data). Loss: 0.8594857454299927\n",
            "Training log: 18 epoch (46208 / 50000 train. data). Loss: 0.7858704924583435\n",
            "Test loss (avg): 1.2374664180755615, Accuracy: 0.5642\n",
            "Training log: 19 epoch (128 / 50000 train. data). Loss: 0.7420477271080017\n",
            "Training log: 19 epoch (11648 / 50000 train. data). Loss: 0.6440498232841492\n",
            "Training log: 19 epoch (23168 / 50000 train. data). Loss: 0.7117161154747009\n",
            "Training log: 19 epoch (34688 / 50000 train. data). Loss: 0.7934349775314331\n",
            "Training log: 19 epoch (46208 / 50000 train. data). Loss: 0.7717443108558655\n",
            "Test loss (avg): 1.2410057731628419, Accuracy: 0.5689\n",
            "Training log: 20 epoch (128 / 50000 train. data). Loss: 0.8494659066200256\n",
            "Training log: 20 epoch (11648 / 50000 train. data). Loss: 0.7033536434173584\n",
            "Training log: 20 epoch (23168 / 50000 train. data). Loss: 0.7406079769134521\n",
            "Training log: 20 epoch (34688 / 50000 train. data). Loss: 0.8158491849899292\n",
            "Training log: 20 epoch (46208 / 50000 train. data). Loss: 0.8608707785606384\n",
            "Test loss (avg): 1.2386948205947876, Accuracy: 0.5643\n",
            "Training log: 21 epoch (128 / 50000 train. data). Loss: 0.7104057669639587\n",
            "Training log: 21 epoch (11648 / 50000 train. data). Loss: 0.7629597783088684\n",
            "Training log: 21 epoch (23168 / 50000 train. data). Loss: 0.8370721936225891\n",
            "Training log: 21 epoch (34688 / 50000 train. data). Loss: 0.7338331937789917\n",
            "Training log: 21 epoch (46208 / 50000 train. data). Loss: 0.7034711837768555\n",
            "Test loss (avg): 1.2198005718231202, Accuracy: 0.5733\n",
            "Training log: 22 epoch (128 / 50000 train. data). Loss: 0.7356172204017639\n",
            "Training log: 22 epoch (11648 / 50000 train. data). Loss: 0.6991249322891235\n",
            "Training log: 22 epoch (23168 / 50000 train. data). Loss: 0.7399754524230957\n",
            "Training log: 22 epoch (34688 / 50000 train. data). Loss: 0.6685224771499634\n",
            "Training log: 22 epoch (46208 / 50000 train. data). Loss: 0.6621214747428894\n",
            "Test loss (avg): 1.231540828895569, Accuracy: 0.5682\n",
            "Training log: 23 epoch (128 / 50000 train. data). Loss: 0.668752133846283\n",
            "Training log: 23 epoch (11648 / 50000 train. data). Loss: 0.7126996517181396\n",
            "Training log: 23 epoch (23168 / 50000 train. data). Loss: 0.6900787949562073\n",
            "Training log: 23 epoch (34688 / 50000 train. data). Loss: 0.6361222267150879\n",
            "Training log: 23 epoch (46208 / 50000 train. data). Loss: 0.5523114800453186\n",
            "Test loss (avg): 1.2271001113891602, Accuracy: 0.573\n",
            "Training log: 24 epoch (128 / 50000 train. data). Loss: 0.7040532231330872\n",
            "Training log: 24 epoch (11648 / 50000 train. data). Loss: 0.7337325215339661\n",
            "Training log: 24 epoch (23168 / 50000 train. data). Loss: 0.693550169467926\n",
            "Training log: 24 epoch (34688 / 50000 train. data). Loss: 0.795621395111084\n",
            "Training log: 24 epoch (46208 / 50000 train. data). Loss: 0.6972767114639282\n",
            "Test loss (avg): 1.2284250942230224, Accuracy: 0.5746\n",
            "Training log: 25 epoch (128 / 50000 train. data). Loss: 0.7485321760177612\n",
            "Training log: 25 epoch (11648 / 50000 train. data). Loss: 0.7050130367279053\n",
            "Training log: 25 epoch (23168 / 50000 train. data). Loss: 0.8116898536682129\n",
            "Training log: 25 epoch (34688 / 50000 train. data). Loss: 0.7323731184005737\n",
            "Training log: 25 epoch (46208 / 50000 train. data). Loss: 0.6961451768875122\n",
            "Test loss (avg): 1.2166278415679932, Accuracy: 0.5772\n",
            "Training log: 26 epoch (128 / 50000 train. data). Loss: 0.6525518298149109\n",
            "Training log: 26 epoch (11648 / 50000 train. data). Loss: 0.597230851650238\n",
            "Training log: 26 epoch (23168 / 50000 train. data). Loss: 0.6289202570915222\n",
            "Training log: 26 epoch (34688 / 50000 train. data). Loss: 0.6526111364364624\n",
            "Training log: 26 epoch (46208 / 50000 train. data). Loss: 0.7147120833396912\n",
            "Test loss (avg): 1.208886937713623, Accuracy: 0.5765\n",
            "Training log: 27 epoch (128 / 50000 train. data). Loss: 0.6486563086509705\n",
            "Training log: 27 epoch (11648 / 50000 train. data). Loss: 0.5583428740501404\n",
            "Training log: 27 epoch (23168 / 50000 train. data). Loss: 0.627362072467804\n",
            "Training log: 27 epoch (34688 / 50000 train. data). Loss: 0.651464581489563\n",
            "Training log: 27 epoch (46208 / 50000 train. data). Loss: 0.5516942739486694\n",
            "Test loss (avg): 1.2371057067871094, Accuracy: 0.5675\n",
            "Training log: 28 epoch (128 / 50000 train. data). Loss: 0.5801421403884888\n",
            "Training log: 28 epoch (11648 / 50000 train. data). Loss: 0.6472916007041931\n",
            "Training log: 28 epoch (23168 / 50000 train. data). Loss: 0.58027583360672\n",
            "Training log: 28 epoch (34688 / 50000 train. data). Loss: 0.7097466588020325\n",
            "Training log: 28 epoch (46208 / 50000 train. data). Loss: 0.6387146711349487\n",
            "Test loss (avg): 1.2290953378677367, Accuracy: 0.5746\n",
            "Training log: 29 epoch (128 / 50000 train. data). Loss: 0.6259481310844421\n",
            "Training log: 29 epoch (11648 / 50000 train. data). Loss: 0.6262790560722351\n",
            "Training log: 29 epoch (23168 / 50000 train. data). Loss: 0.7172350287437439\n",
            "Training log: 29 epoch (34688 / 50000 train. data). Loss: 0.612630307674408\n",
            "Training log: 29 epoch (46208 / 50000 train. data). Loss: 0.6483185291290283\n",
            "Test loss (avg): 1.2161757972717284, Accuracy: 0.5767\n",
            "Training log: 30 epoch (128 / 50000 train. data). Loss: 0.6309594511985779\n",
            "Training log: 30 epoch (11648 / 50000 train. data). Loss: 0.603313684463501\n",
            "Training log: 30 epoch (23168 / 50000 train. data). Loss: 0.6170289516448975\n",
            "Training log: 30 epoch (34688 / 50000 train. data). Loss: 0.690808892250061\n",
            "Training log: 30 epoch (46208 / 50000 train. data). Loss: 0.657921314239502\n",
            "Test loss (avg): 1.2063782625198365, Accuracy: 0.5824\n",
            "Training log: 31 epoch (128 / 50000 train. data). Loss: 0.5086254477500916\n",
            "Training log: 31 epoch (11648 / 50000 train. data). Loss: 0.47376152873039246\n",
            "Training log: 31 epoch (23168 / 50000 train. data). Loss: 0.5414651036262512\n",
            "Training log: 31 epoch (34688 / 50000 train. data). Loss: 0.6629981994628906\n",
            "Training log: 31 epoch (46208 / 50000 train. data). Loss: 0.5679857134819031\n",
            "Test loss (avg): 1.2534608219146728, Accuracy: 0.5633\n",
            "Training log: 32 epoch (128 / 50000 train. data). Loss: 0.5988979935646057\n",
            "Training log: 32 epoch (11648 / 50000 train. data). Loss: 0.7395350933074951\n",
            "Training log: 32 epoch (23168 / 50000 train. data). Loss: 0.6107449531555176\n",
            "Training log: 32 epoch (34688 / 50000 train. data). Loss: 0.6484165787696838\n",
            "Training log: 32 epoch (46208 / 50000 train. data). Loss: 0.6522612571716309\n",
            "Test loss (avg): 1.2140039735794068, Accuracy: 0.5801\n",
            "Training log: 33 epoch (128 / 50000 train. data). Loss: 0.6613025069236755\n",
            "Training log: 33 epoch (11648 / 50000 train. data). Loss: 0.5831204056739807\n",
            "Training log: 33 epoch (23168 / 50000 train. data). Loss: 0.5233744382858276\n",
            "Training log: 33 epoch (34688 / 50000 train. data). Loss: 0.607731819152832\n",
            "Training log: 33 epoch (46208 / 50000 train. data). Loss: 0.6106740236282349\n",
            "Test loss (avg): 1.2173433544158936, Accuracy: 0.5745\n",
            "Training log: 34 epoch (128 / 50000 train. data). Loss: 0.6753665804862976\n",
            "Training log: 34 epoch (11648 / 50000 train. data). Loss: 0.6336027979850769\n",
            "Training log: 34 epoch (23168 / 50000 train. data). Loss: 0.7162333726882935\n",
            "Training log: 34 epoch (34688 / 50000 train. data). Loss: 0.6077956557273865\n",
            "Training log: 34 epoch (46208 / 50000 train. data). Loss: 0.6135703921318054\n",
            "Test loss (avg): 1.2263287170410155, Accuracy: 0.5719\n",
            "Training log: 35 epoch (128 / 50000 train. data). Loss: 0.6265954971313477\n",
            "Training log: 35 epoch (11648 / 50000 train. data). Loss: 0.6443681120872498\n",
            "Training log: 35 epoch (23168 / 50000 train. data). Loss: 0.5227177739143372\n",
            "Training log: 35 epoch (34688 / 50000 train. data). Loss: 0.5699179172515869\n",
            "Training log: 35 epoch (46208 / 50000 train. data). Loss: 0.6291919946670532\n",
            "Test loss (avg): 1.2244816535949707, Accuracy: 0.5715\n",
            "Training log: 36 epoch (128 / 50000 train. data). Loss: 0.5525556206703186\n",
            "Training log: 36 epoch (11648 / 50000 train. data). Loss: 0.6767276525497437\n",
            "Training log: 36 epoch (23168 / 50000 train. data). Loss: 0.5235614776611328\n",
            "Training log: 36 epoch (34688 / 50000 train. data). Loss: 0.5832957625389099\n",
            "Training log: 36 epoch (46208 / 50000 train. data). Loss: 0.6352740526199341\n",
            "Test loss (avg): 1.2198938207626342, Accuracy: 0.5763\n",
            "Training log: 37 epoch (128 / 50000 train. data). Loss: 0.6699829697608948\n",
            "Training log: 37 epoch (11648 / 50000 train. data). Loss: 0.606799840927124\n",
            "Training log: 37 epoch (23168 / 50000 train. data). Loss: 0.51694256067276\n",
            "Training log: 37 epoch (34688 / 50000 train. data). Loss: 0.5273742079734802\n",
            "Training log: 37 epoch (46208 / 50000 train. data). Loss: 0.5915849804878235\n",
            "Test loss (avg): 1.2293135736465455, Accuracy: 0.5776\n",
            "Training log: 38 epoch (128 / 50000 train. data). Loss: 0.5570821166038513\n",
            "Training log: 38 epoch (11648 / 50000 train. data). Loss: 0.4751243591308594\n",
            "Training log: 38 epoch (23168 / 50000 train. data). Loss: 0.5606623291969299\n",
            "Training log: 38 epoch (34688 / 50000 train. data). Loss: 0.5647035241127014\n",
            "Training log: 38 epoch (46208 / 50000 train. data). Loss: 0.5699010491371155\n",
            "Test loss (avg): 1.2164749420166017, Accuracy: 0.58\n",
            "Training log: 39 epoch (128 / 50000 train. data). Loss: 0.520379900932312\n",
            "Training log: 39 epoch (11648 / 50000 train. data). Loss: 0.5566766262054443\n",
            "Training log: 39 epoch (23168 / 50000 train. data). Loss: 0.5159477591514587\n",
            "Training log: 39 epoch (34688 / 50000 train. data). Loss: 0.5057436227798462\n",
            "Training log: 39 epoch (46208 / 50000 train. data). Loss: 0.5938065648078918\n",
            "Test loss (avg): 1.2182609930038453, Accuracy: 0.5748\n",
            "Training log: 40 epoch (128 / 50000 train. data). Loss: 0.5814204216003418\n",
            "Training log: 40 epoch (11648 / 50000 train. data). Loss: 0.5992719531059265\n",
            "Training log: 40 epoch (23168 / 50000 train. data). Loss: 0.5375850796699524\n",
            "Training log: 40 epoch (34688 / 50000 train. data). Loss: 0.6110805869102478\n",
            "Training log: 40 epoch (46208 / 50000 train. data). Loss: 0.6445285677909851\n",
            "Test loss (avg): 1.2327147571563721, Accuracy: 0.5737\n",
            "Training log: 41 epoch (128 / 50000 train. data). Loss: 0.5621320605278015\n",
            "Training log: 41 epoch (11648 / 50000 train. data). Loss: 0.5758057236671448\n",
            "Training log: 41 epoch (23168 / 50000 train. data). Loss: 0.6122660636901855\n",
            "Training log: 41 epoch (34688 / 50000 train. data). Loss: 0.6250694394111633\n",
            "Training log: 41 epoch (46208 / 50000 train. data). Loss: 0.5794875621795654\n",
            "Test loss (avg): 1.229011639213562, Accuracy: 0.5696\n",
            "Training log: 42 epoch (128 / 50000 train. data). Loss: 0.5960077047348022\n",
            "Training log: 42 epoch (11648 / 50000 train. data). Loss: 0.4297713339328766\n",
            "Training log: 42 epoch (23168 / 50000 train. data). Loss: 0.5201800465583801\n",
            "Training log: 42 epoch (34688 / 50000 train. data). Loss: 0.5537549257278442\n",
            "Training log: 42 epoch (46208 / 50000 train. data). Loss: 0.676405668258667\n",
            "Test loss (avg): 1.2053549438476563, Accuracy: 0.5784\n",
            "Training log: 43 epoch (128 / 50000 train. data). Loss: 0.5799992084503174\n",
            "Training log: 43 epoch (11648 / 50000 train. data). Loss: 0.4672498106956482\n",
            "Training log: 43 epoch (23168 / 50000 train. data). Loss: 0.5489518642425537\n",
            "Training log: 43 epoch (34688 / 50000 train. data). Loss: 0.5548571348190308\n",
            "Training log: 43 epoch (46208 / 50000 train. data). Loss: 0.6075656414031982\n",
            "Test loss (avg): 1.2056834760665893, Accuracy: 0.5813\n",
            "Training log: 44 epoch (128 / 50000 train. data). Loss: 0.45355337858200073\n",
            "Training log: 44 epoch (11648 / 50000 train. data). Loss: 0.5479432940483093\n",
            "Training log: 44 epoch (23168 / 50000 train. data). Loss: 0.46198946237564087\n",
            "Training log: 44 epoch (34688 / 50000 train. data). Loss: 0.5197768807411194\n",
            "Training log: 44 epoch (46208 / 50000 train. data). Loss: 0.5780232548713684\n",
            "Test loss (avg): 1.205617963218689, Accuracy: 0.5795\n",
            "Training log: 45 epoch (128 / 50000 train. data). Loss: 0.5200287103652954\n",
            "Training log: 45 epoch (11648 / 50000 train. data). Loss: 0.5132057070732117\n",
            "Training log: 45 epoch (23168 / 50000 train. data). Loss: 0.5947781205177307\n",
            "Training log: 45 epoch (34688 / 50000 train. data). Loss: 0.5885273218154907\n",
            "Training log: 45 epoch (46208 / 50000 train. data). Loss: 0.53518146276474\n",
            "Test loss (avg): 1.2092563535690308, Accuracy: 0.5828\n",
            "Training log: 46 epoch (128 / 50000 train. data). Loss: 0.44515499472618103\n",
            "Training log: 46 epoch (11648 / 50000 train. data). Loss: 0.5396121144294739\n",
            "Training log: 46 epoch (23168 / 50000 train. data). Loss: 0.47415730357170105\n",
            "Training log: 46 epoch (34688 / 50000 train. data). Loss: 0.4776604175567627\n",
            "Training log: 46 epoch (46208 / 50000 train. data). Loss: 0.5953309535980225\n",
            "Test loss (avg): 1.2102314725875853, Accuracy: 0.5856\n",
            "Training log: 47 epoch (128 / 50000 train. data). Loss: 0.4761795699596405\n",
            "Training log: 47 epoch (11648 / 50000 train. data). Loss: 0.5431355237960815\n",
            "Training log: 47 epoch (23168 / 50000 train. data). Loss: 0.5699513554573059\n",
            "Training log: 47 epoch (34688 / 50000 train. data). Loss: 0.4935477375984192\n",
            "Training log: 47 epoch (46208 / 50000 train. data). Loss: 0.5901802778244019\n",
            "Test loss (avg): 1.2197114040374757, Accuracy: 0.5695\n",
            "Training log: 48 epoch (128 / 50000 train. data). Loss: 0.43304237723350525\n",
            "Training log: 48 epoch (11648 / 50000 train. data). Loss: 0.4752840995788574\n",
            "Training log: 48 epoch (23168 / 50000 train. data). Loss: 0.5278397798538208\n",
            "Training log: 48 epoch (34688 / 50000 train. data). Loss: 0.4971534311771393\n",
            "Training log: 48 epoch (46208 / 50000 train. data). Loss: 0.4924980401992798\n",
            "Test loss (avg): 1.2166140953063964, Accuracy: 0.5733\n",
            "Training log: 49 epoch (128 / 50000 train. data). Loss: 0.46908068656921387\n",
            "Training log: 49 epoch (11648 / 50000 train. data). Loss: 0.5045266151428223\n",
            "Training log: 49 epoch (23168 / 50000 train. data). Loss: 0.5232334136962891\n",
            "Training log: 49 epoch (34688 / 50000 train. data). Loss: 0.5269320607185364\n",
            "Training log: 49 epoch (46208 / 50000 train. data). Loss: 0.48776358366012573\n",
            "Test loss (avg): 1.202564539527893, Accuracy: 0.5808\n",
            "Training log: 50 epoch (128 / 50000 train. data). Loss: 0.5626120567321777\n",
            "Training log: 50 epoch (11648 / 50000 train. data). Loss: 0.512758195400238\n",
            "Training log: 50 epoch (23168 / 50000 train. data). Loss: 0.616077721118927\n",
            "Training log: 50 epoch (34688 / 50000 train. data). Loss: 0.4286856949329376\n",
            "Training log: 50 epoch (46208 / 50000 train. data). Loss: 0.47496965527534485\n",
            "Test loss (avg): 1.2183129814147948, Accuracy: 0.5747\n",
            "{'train_loss': [tensor(1.4804, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.3561, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.1355, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.2077, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.2549, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.1937, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.3000, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.0505, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.9120, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.2218, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.9696, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.0617, device='cuda:0', grad_fn=<NllLossBackward>), tensor(1.0602, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.8681, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7084, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7984, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7374, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7369, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.8937, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7640, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6858, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6355, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7541, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.8137, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7015, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6232, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5389, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5279, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6793, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6812, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6702, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5847, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4786, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6118, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6066, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.7032, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6428, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6216, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6121, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6767, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5927, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6465, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5079, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5511, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4488, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.6342, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5058, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.4841, device='cuda:0', grad_fn=<NllLossBackward>), tensor(0.5444, device='cuda:0', grad_fn=<NllLossBackward>)], 'test_loss': [1.4591257236480712, 1.4146602325439452, 1.3510259180068969, 1.3359144353866577, 1.2947766540527343, 1.3276174215316772, 1.2817119678497315, 1.2741982719421387, 1.263942109298706, 1.2535454780578614, 1.236247985458374, 1.23187216796875, 1.2868680683135987, 1.281037692642212, 1.2306186254501343, 1.2260435438156128, 1.2261659616470337, 1.2374664180755615, 1.2410057731628419, 1.2386948205947876, 1.2198005718231202, 1.231540828895569, 1.2271001113891602, 1.2284250942230224, 1.2166278415679932, 1.208886937713623, 1.2371057067871094, 1.2290953378677367, 1.2161757972717284, 1.2063782625198365, 1.2534608219146728, 1.2140039735794068, 1.2173433544158936, 1.2263287170410155, 1.2244816535949707, 1.2198938207626342, 1.2293135736465455, 1.2164749420166017, 1.2182609930038453, 1.2327147571563721, 1.229011639213562, 1.2053549438476563, 1.2056834760665893, 1.205617963218689, 1.2092563535690308, 1.2102314725875853, 1.2197114040374757, 1.2166140953063964, 1.202564539527893, 1.2183129814147948], 'test_acc': [0.4801, 0.4996, 0.5156, 0.5262, 0.5408, 0.5291, 0.5424, 0.5479, 0.5553, 0.5527, 0.5638, 0.5697, 0.5471, 0.5479, 0.5733, 0.5696, 0.5711, 0.5642, 0.5689, 0.5643, 0.5733, 0.5682, 0.573, 0.5746, 0.5772, 0.5765, 0.5675, 0.5746, 0.5767, 0.5824, 0.5633, 0.5801, 0.5745, 0.5719, 0.5715, 0.5763, 0.5776, 0.58, 0.5748, 0.5737, 0.5696, 0.5784, 0.5813, 0.5795, 0.5828, 0.5856, 0.5695, 0.5733, 0.5808, 0.5747]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEWCAYAAABollyxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU1d3H8c8vOyQhISQESAJh3wNCxA0FrQtu4FKt1arYWm3V2t3q09b2sbt2edqqbV2r1lZcKyqKqIiioASEQICwhCUJkITsC9l/zx9zE0OYJJN1kpnf+/XKy5m7novJd86ce+45oqoYY4zxXQHeLoAxxpjeZUFvjDE+zoLeGGN8nAW9Mcb4OAt6Y4zxcRb0xhjj4yzojTHGx1nQm35FRPaLyLk9cJylIrK2J8pkzEBnQW+Ml4hIoLfLYPyDBb3pN0TkGWA08JqIVIjIXc7yU0XkYxEpEZEtIrKwxT5LRSRLRMpFZJ+IXCciU4G/A6c5xylp43w3icgOZ98sEbm11folIrJZRMpEZK+ILHKWx4jIkyJySESKReS/LcqyttUxVEQmOK//KSJ/E5EVIlIJnC0iF4vIZ845skXk5632n9/i2rOdc5wsInktPyhE5AoR2dLFf3rj61TVfuyn3/wA+4FzW7xPAAqBi3BVTM5z3scB4UAZMNnZdiQw3Xm9FFjbwbkuBsYDAiwAqoA5zrp5QKlzvgCnHFOcdW8Ay4ChQDCwoK1zAgpMcF7/0znmGc4xw4CFwEznfQqQB1zmbD8GKAe+7JxnGDDbWbcduLDFeV4Bvu/t/3/20z9/rEZv+ruvACtUdYWqNqrqKiANV/ADNAIzRGSQqh5W1QxPD6yqb6jqXnVZA7wNnOms/hrwhKqucs6bq6o7RWQkcCHwDVUtVtU6Z19PvaqqHznHrFbV91V1q/M+HfgPrg8dgGuBd1T1P855ClV1s7PuKeffBhGJAS4A/t2Jchg/YkFv+rsxwFVO00WJ0wwzHxipqpXAl4BvAIdF5A0RmeLpgUXkQhFZLyJFznEvAmKd1UnAXje7JQFFqlrcxevJblWGU0RktYgUiEgprmvpqAwA/wIuFZFw4GrgQ1U93MUyGR9nQW/6m9bDqWYDz6hqdIufcFX9LYCqrlTV83A12+wEHm3jOMcRkVDgJeD3QLyqRgMrcDXjNJ13vJtds4EYEYl2s64SGNziHCM8uL5/A8uBJFWNwnVvoaMyoKq5wDrgCuB64Bl32xkDFvSm/8kDxrV431RzvUBEAkUkTEQWikiiiMQ7N0zDgRqgAldTTtNxEkUkpI3zhAChQAFQLyIXAue3WP84cJOIfEFEAkQkQUSmOLXmN4GHRWSoiASLyFnOPluA6SIyW0TCgJ97cL2RuL4hVIvIPFzNNU2eBc4VkatFJEhEhonI7BbrnwbuwtXG/7IH5zJ+yoLe9De/AX7iNNP8QFWzgSXA/+AK5Wzgh7h+dwOA7wGHgCJcbdvfdI7zHpABHBGRo61PoqrlwJ3A80AxroBd3mL9p8BNwJ9w3UBdg6sZCVw16Dpc3yDyge84++wC7gPeAXYDnvTjvw24T0TKgXud8jSV4SCu5qTvO9e3GZjVYt9XnDK9oqpVHpzL+ClRtYlHjBmoRGQvcKuqvuPtspj+y2r0xgxQInIlrjb/97xdFtO/BXm7AMaYzhOR94FpwPWq2tjB5sbPWdONMcb4OGu6McYYH9fvmm5iY2M1OTnZ28UwxpgBZePGjUdVNc7dun4X9MnJyaSlpXm7GMYYM6CIyIG21lnTjTHG+DgLemOM8XEW9MYY4+Ms6I0xxsdZ0BtjjI+zoDfGGB9nQW+MMT7Ogt4YYzqQeaSc9zPzvV2MLrOgN8aYdry59TBLHlrL159Oo7quwdvF6RILemOMcUNVeWj1Hr757CYiQoOpa1B2Hin3drG6xILeGGNaqalv4AcvpPPAykyWzB7F87eeCkB6TomXS9Y1/W6sG2OM8aaiylq+8cxGPt1fxHfPncSdX5gAQGxECOk5pV4uXddY0BtjjGNPfgVfe2oDh0ur+cuXT2LxrFHN62YmRA3YGr013RjTT63YepgDhZXeLobf2H6ojKv+/jGVNfU8d8upx4U8QEpiNHvyK6isqfdSCbvOgt6YfmjjgSJue3YTf3t/r7eL4he2HyrjusfWExYcyEvfPJ05o4eesM2spCgaFbblDrzmGwt6Y/qZxkbl58u3A5CZNzB7efQHNfUNvLgxh4Lymna3yzhUyrWPrWdQcCDLbjmNMcPC3W43MyEagK2+GvQiskhEMkVkj4jc7Wb9UhEpEJHNzs/NLdbdLyIZIrJDRP4iItKTF2CMr3lxYw5bc0sZHTOYXUfKaWy0eZ07q6Sqlusf/5QfvLCFBQ+s5k+rdrltctmWW8q1j35CeEgQz91yGqOHDW7zmHGRoYyKCmNLN2/Ivrn1MHvy+/YDvMOgF5FA4CHgQlyzzn9ZRKa52XSZqs52fh5z9j0dOANIAWYAJwMLeqrwxviasuo67l+5k9QxQ7l1wTgqaxvILTnm0b619Y0UVrRfe/UH2UVVXPm3j9l8sISfXzqNhZPj+PO7u1nwwGqeWbefuoZGwBXy1z32CRGhQTx3y6nthnyTlMTobt2QPVhYxW3/3sSd/9ncpx/gntTo5wF7VDVLVWuB54AlHh5fgTAgBAgFgoG8rhTUGH/w13d3U1hZy88unc6UEUMA1+P3nnj4/T0seOB9Dnn4wdDbGhpdDxyl/nIVG/YX9ck503NKuPzhjykor+GZr81j6Rljefi6ubxy2+mMi4vgp69mcP6fPuCJtfuOC/mkmI5DHiAlKYoDhVWUVtV1qXxPfrwPVdh+uIxXt+R26Rhd4UnQJwDZLd7nOMtau1JE0kXkRRFJAlDVdcBq4LDzs1JVd7TeUURuEZE0EUkrKCjo9EUY4wv2FlTw5Ef7uXpuEjMTo5gUHwF43k6ftr+Yipp6frXihD+xPnektJqvPPYJD6zMpLy6nh+9lN7rwwe8uyOPL/1jPaFBAbx82+mcMm5Y87qTRg9l2S2n8viNqQQHCve9vr3TIQ+Q4rTTp+d2vlZfVl3H8xuyWTJ7FDMTovj9yl19NqRCT92MfQ1IVtUUYBXwFICITACmAom4PhzOEZEzW++sqo+oaqqqpsbFuZ3E3Bif94vXtzMoOJAfLpoMQGRYMAnRgzyq0asqW3NLiQgN4o30w3y892hvF7dNq7bnceGfP2BLTgn3fzGFR29IJaugkodX7+m1c/5r/QG+/nQaE4ZH8MrtpzNheOQJ24gIX5gaz5vfPot/XD+Xl287vVMhDzAzMQqgSw9OPb8hm8raBm6eP467L5xCbskxnlnX5nzePcqToM8Fklq8T3SWNVPVQlVtahx8DJjrvL4cWK+qFapaAbwJnNa9Ihvje97bmcf7mQV8+9yJxEaENi+fPCKSXR7U6HOKj1F6rI7vnDuRxKGD+PnyjOa26L5SXdfAva9u4+tPpzEqehCvf2s+V6cmcdakOC4/KYG/rdnr0bV01uvph/jJf7excPJwnrvlVIZHhrW7fWCAcMH0EcQPaX87d6IGBTM2Npwt2Z2r0dc3NPLkR/uZNzaGmYlRnDEhlrMmxfHg6j1dbgbqDE+CfgMwUUTGikgIcA2wvOUGIjKyxdvFQNN3x4PAAhEJEpFgXDdivf+90ph+pLa+kV+8voNxceHccFrycesmj4hkb0FFh6Hd1Lc7NTmGey+Zxq68ij6rLTY2Kh/uLmDJgx/x9LoD3Dx/LC87beJNfnLxVCJCg/jRS+k09PBNyKfXHSB52GAeuX4u4aG9/7B/SmJUp7tYrszII7fkGF+bP7Z52d2LplBWXcfDa3rvm06TDoNeVeuBO4CVuEL6eVXNEJH7RGSxs9mdThfKLcCdwFJn+YvAXmArsAXYoqqv9fA1GNMr8suq+e6yzXz/+S08s24/6Tkl1Nb3fC35yY/2se9oJfdeMo2QoOP/JCfHR1LXoOw72v4TstsOlRIYIEwZEcl50+I5a1Icf1q1q8M+5N1xuPQYf313N2c9sJrrH/+Uoqpa/nnTyfzkkmmEBgUet+2wiFDuvXQanx0s4V/re+4D6EBhJZ/uK+Kq1CSCAvvmsaCZCVEcLq0mv7za430eX5vF6JjBnDs1vnnZtFFDuHx2Ak9+tL/Xb6B79PGnqiuAFa2W3dvi9T3APW72awBu7WYZjelzn+4r4vZ/b6K8uo6I0CBe2pQDQEhgANNGDWF2UjTXnTKaifEntgV3xurMfP763h7OmTKchZOHn7B+knP8zCPlza/d2ZpbxsThEYQFuwL2Z5dOY9H/fcD9b+3kgatmdauMLdU3NPLeznye25DN+5n5NCqcMWEYdy2awgXT408I+JYum53AK58d4v63dnLetHhGRQ/qdnle2piDCFx+krv+Ib1jVpJzQza7lHOnddz889nBYjYdLOFnl04jMOD4x4i+d/4kXk8/zB9X7eL3Pfj/qTV7MtaYFlSVJ9bu49pH1xMeEsh/bz+DDT8+l4/uPoeHr5vDTWckExoUwHMbDnLbs5tQ7VozREF5DXf+5zNuenID8UNC+d/F091uN354OIEB0u4NWVUlI7eUmQlRn+8XF8FX54/lhY05bDpY3KUyujvP159O45ZnNrItt5RvLhzPmh8u5NmbXePCtBfy4LoZ+qvLZtCocO+r27r8b9eksVF5aVMu8yfE9siHhqemjxpCgEC6h803j6/dR2RoEFelJp2wLnHoYG48fQwvbcph55Gyni5qMwt6YxxVtfV8Z9lm7nt9OwsnD2f5t+YzZcQQRISE6EFcNHMk91w0lWW3nsZPL5nG7vwKtuV27o9TVXl+Qzbn/nENb207wnfOnciKb5/ZZu+P0KBAxsaGt9vF8nBpNYWVtcxoEfQA3zpnIvFDQvnZqxk90i7+zPoDrM4s4K5Fk/n47nP44QVT2hwuoC1JMYP53nmTeGdHPiu2HulWedZlFZJbcowvzk3s1nE6a3BIEBOHR3r04FRuyTHe3HaEL58ymog27h/cfvYEIkOD+N2bO3u6qM0s6I0B9h+t5IqHP2b5lkP84PxJPHL9XIaEBbe5/SUzRxESFNDcpOOJrIIKvvzoeu56KZ1J8RGs+PZ8vnPupA5rwpNHRLZbo2+6Eds66CNCg/ifi6ayNbeU59Oy3e3qsb0FFfx6xQ4WTIrjmwvGd6s9/KYzkpmZEMXPlmd0qp27tRc35hAZFsQF00d0+RhdlZIYRXpOaYffSp7+eD8AN56e3OY20YNDuO3sCazOLOi1brEW9MavlR6r46/v7ubSv67lSFk1/7xpHnecM5GAgPaHZIoaHMx5U+NZvuWQR90YP8kqZNGfPyTjUBm/vnwmy245zW1fb3cmx0dysKiKqlr3w+Nuyy0lQGDayCEnrFs8axTzkmO4/62d7O/ghm5b6hsa+d7zWwgLDuT+L6bQ3eGqggID+M0VMympquX037zHDU98yrINBymurPX4GGXVdby57TCXzhrVfF+iL6UkRVNUWUtOcds3UStr6vn3pwdZNGMECR00LS09PZmRUWH89s2d3W7ScseC3vilwooaHli5k/m/fY8/rNrFyWNjeO2O+SyY5PkDe1fMSaCospb3Mzt+mvsPq3YxLDyEd7+3gGtPGd3hB0lLk0e4PhB251W4Xb/tUBkThkcwKOTEwBMRfnn5DBS49MG1vLO98yOQPLR6L1uyS/jlZTO61PfcnRkJUbx+53y+duZY9h2t4EcvbSX1V+9w/eOf8NynBymvbr9v+Yr0w1TXNXJVHzfbNElxvj21183yhbRsyqvrj+tS2Zaw4EB+dfkM7rpgSrc/SN2xoDcdUlWWbzlESZXnNa6+8ElWIbs7+QBOXlk1v3h9O/N/t5qH39/LmZNief1b83li6cmdfkryrElxDAsP4eUOmm82Hijm031F3HzmOIZ3ISgnt+h5487W3FJmjIpyuw5cPXdeu2M+Y4YN5uan0/jD25ket9mn55Tw1/d2s3jWKC5JGdXxDp0wZcQQ7rlwKh/88Gxeu2M+Xz9zHAcKq7j75a186R/rOVbb9vAAL2zMYXxcOLOdHjB9bcrISIIDhS1ttNM3NCpPfryfk0ZHux3b3p1zpsQzf2JsTxazmQW96dC+o5Xc+Z/PuPHJDW02H/S1Y7UNfO2pNJY+uYEKD2f8eXPrYc783Wr++fF+LpwxglXfPYuHr5t7Qtu2p4IDA1gyO4F3d+S3+yH49zV7iR4czDUnn9jrwhNJMYMJCw5we0M2r6yagvKaDq8hKWYwL37jdK6am8hf39vDV/+5ocMP7uq6Br67bDOxEaH8YsmMLpXdEyLCzMQo7r5wCmt+uJC/f2UOO46U8cMXt7htxsgqqGDjgWK+ODepV2q/nggNCmTqyCGkZ59Yo1dV7nstgwOFVdx61ngvlO5EFvSmQwcKqwDYkl3C7c9u6vNH6915e/sRKmrqyS05xv1vddxb4XDpMX70UjpTR0ay+vsL+eOXZnvcRt6eK+YkUNvQyGvph92u35NfzqrtedxwWnKXn9oMDBAmxbu/IdvWjVh3mtrYf335TNbtLeSSv65td7ak3721k70FlTxwVQpRg9u+Md2TRIRFM0Zy1wVTeD39MH9fk3XCNi9tyiFAXP/23pSSGMW23NIThht+fO0+nlp3gK+fOZZFM/r+RrE7FvSmQ9nFrqD/zrkTWZ1ZwI9f2dorN4w646VNuSRED2Lp6ck8ve4An+5rexjcxkblhy+kU9+o/Pmakzwad9xT00cNYXJ8ZJvNN39fk0VYcABL2+l14YlJ8ZFua/Rbc0sRcT1l6QkR4dpTRvP8N06joVG58m8f8+VH1vODF7bwp1W7eD4tm4/2HOX19EM8+dF+bjxtDGdO7PuBBr+xYByXzhrF/St3sjozv3l5Q6Py0sZczpoU12P3C7oqJSGa8pp69rWY1/fNrYf51YodXDRzBPdcONWLpTueBb3pUHZRFWHBAXz7CxO58wsTeT4thz+u2tXuPnsLKnptYuu8smrW7i7g8pMSuGvRZBKHDuLudobBfWb9AdbuOcqPL55Kcmzn+n13RES4cm4Cnx0sIavg+Julh0qO8ermXK45eTQx4SHdOs+UEZEUlNdQ1KpnyrbcMsbGhrfZR7sts5Oiee1b87liTiK1DY2s3X2Uv7y3m7teTOe6xz7hjn9/xri4cO72UliJCPdfmcLUEUO48z+fNf/bfrTnKEfKqrlqbteawXpSSlLTSJaudvqNB4r4zrLNzBk9lD9ePbtTN9x7W++PAGQGvINFVSQOHYyI8N1zJ5JfVs1f39vD8CFhXH/qmObtVJV1ewt55MMs3s8sIH5IKGt+eHaPd397dXMujer66j44JIjfXpHCVx7/hD+/u5sfLZpy3LZ7Cyr4zZs7WDg5jmvnje7RcjRZMjuB3765k1c+y+X7509uXv742n00Ktx8Zse9LjrSciiE08Z/Ps76ttxSThkX06VjxkaE8psrZja/r61v5EhpNTklVRwuqebk5Bi3PXn6yqCQQB65YS6LH/yIW57ZyCu3nc4LG3OIGhTMF6aeOFxEX5sQF8Gg4EC2ZJcyO2koNz/lGrXz0RtSvdLlsz1Wozcdyi46xminR4qI8MvLZvCFKcO599VtvLXtCHUNjfz3s1wu/starn3sE7bllnLNyUnkldXw4kbPHyjyhKrrq/tJo6ObR0ecPzGWq1MTeeSDrOPanOsaGvness2utukru9//uy3xQ8KYPzGOlzflNrfXllTV8p9PD7J41igSh3a/qWiK08Wy5TC/BeU1HCmrbrfHTWeEBAUwethgTh8fy5VzE3u0iaurEocO5qFr57DvaCW3//szVmYcYcls7/Sdby0oMIDpo4awbm8hNz35KSLCk0tP7va3t95gQe/Dnv3kQLeDVlXJLqoiaejnD3wEBQbw4LVzmJ0UzZ3PfcZZ96/mO8s2U1PfwG+vmMnaH53Db66YyeykaP6+Zm+P3rzNOFRGZl45V8w5vv/0jy+exrDwEO56Mb35fA+v3suWnFJ+ddnMLnVr7Iwr5ySQW3KMT5x7BU+vO0BVbQO3LhjXI8ePiwwlenAwO1vckN12yPMbsQPZaeOHce8l0/hgVwG19Y19PuRBe1ISo8nMK+dwaTWP3pDa402DPcWC3kftLajgZ69m8NiHJ/Za6IzSY3WU19Sf0Md8UEggj994MpPjIxkzbDBPLE1l1XcXcM280YQFByIi3HH2BHKKj7F88yGPzuXJkLovb8olJDCAS1NGHrc8alAwv7hsBtsPl/HIB1mk55Twl/d2c9nsUVzcatvecP60EUSEBvHyphyO1Tbwz4/3c86U4c3zvnaXiKvnTcsafYbz7WV6Qs+coz+74bQx3Dx/LOdOHX7c4G3eduq4GAIE/nzNbOaO8ay/vDdYG72P+s2KndQ3usYxb2zULt8Yyi5yPeLt7mGimPAQXvvW/Db3/cLU4UwZEcnD7+/h8pMS2i3DM+v289NXM3jgiyluR/kDV1PMq5tz+cLU4UQPPvHr8QXTR3Bxykj+/M5ulm3IJi4ilP/txf7fLQ0KCeSimSN4I/0w44dHUFRZyzcX9mwf6ikjInllUy6qioiwNbeU5GGD2x2Tx1eICD+5ZJq3i3GC86bF89lPz++z7qddZTV6H/TxnqO8syOP8XHh1NQ3cqSs6wNHHSxyda0c3cmnRsH1x3n72RPYW1DJWxltj1S4O6+cX76xg6AA4WfLM9qcZOODXQUUVtae0GzT0s8vnc7g0EAOFlXx+6tmETWo7/4Ar5iTSGVtAw+szGTumKGcnNy1m6RtmRQfSXlNPYdKXf8/t+WW+XyzTX8nIv0+5MGC3uc0NCq/fGMHCdGD+MnFrhpQR7MTtaepD31nhwdoctHMkYyLDeeh1Xvc9r2vqW/g289tJiI0iFduO4PgwADu/M9nbmdyenlTLjHhIe2ORxMXGcpjN6Tyf1+a3WuPk7dlXnIMiUMH0dCofHNBzz8R2XRDNvNIGcWVteSWHLOgNx6xoPcxL23KYfvhMn504ZTmwbC6E/QHi6oYOji40/20mwQGCN9YOJ6MQ2VuB//649u72H64jN9dmcLMxCh+d2UKW3NL+cOqzOO2K62qY9X2PBbPGnXCdHutpSbHcFkfzjjUJCBA+ObC8Zw7NZ5zpvR897+JzV0sK5pvxPan9mrTf1nQ+5Cq2np+vzKTk0ZHc2nKSEYMCSMsOKB7Nfqiqi4127R0+UkJJEQP4sFWtfqP9x7lkQ+zuPaU0Zw7zTWX5qIZI7j2lNH8Y00Wa3d/Pjb361sPUdvQyJXtNNv0B9edMobHbkztlYdlogYFMyoqjF155c2jJk738IlY498s6H3IP9ZkkV9ew08unoaIEBAgJA8L71bQ5xQfI7GbQR8cGMCtC8ax8UAx67Nc3Q9Lq+r4/vNbGDssnJ9cfPzTlz+9eBoThkfwvec3U1jh6onz8qZcJg6PYIYf9DBpz6QRkew8Uk5GbhlJMYPc3pQ2pjULeh9xpLSaf3ywl0tSRh7XzWtsbHiXJ5xoaFRyirtfowe4OjWJ2IjQ5rb6H/93KwXlNfzfNbMZHHJ8s9CgkED+cs1JlFTV8aOX0tl3tJKNB4q5cm6i10Yr7C8mx0eyN7+CzdklPfaglPF9FvQ+4oGVmTQqJwwBkBwbzsGiKuq78NBSXlk1dQ1KUg882RkWHMjXzxzL2j1Hue/17byefpjvnjeJlET344lPGzWEey6awjs78vnGMxsRgctme3e0wv5g8ohIahsa7Uas6RQLeh+wNaeUlzbl8NUzxp7QO2ZsbDj1jdrulGdtaepamRTT/jRonrru1DFEDQrmyY/2c3LyUL7RQc+Upacnc/bkODLzypk/IZYRUd4drbA/aBrzBnz/iVjTcyzofcCvV+wgJjyE284+MTjHOY9kd6WdPrsbfejdiQgN4lvnTCA2IpQ/Xj2bwA5uWIoID1w1i9PGDevxh48GqgnDI2j6Z5thN2KNh+zJ2AEuu6iKdVmF3H3hFLdPSCa3CPqzO3vs4mMECIzqYGLjzrj5zHEsPT2ZoEDP6hixEaH855ZTe+z8A11YcCDJseFU1zYwLCLU28UxA4QF/QD33k7XpAyLprufyWZYeAiRYUFdrtGPjBpEsIeh7ClPQ96497X5Y6lv8O7EL2ZgsaAf4N7Zkce4uPA2R80TEVfPmy5MApJdVNVj7fOm51x3ypiONzKmBataDWAVNfV8klXEuVPj291ubGw4WQWdD/qDPfCwlDHG+zwKehFZJCKZIrJHRO52s36piBSIyGbn5+YW60aLyNsiskNEtotIcs8V37+t3X2U2obGDh+3Tx4WzqHSY21OtedOdV0D+eU1PdK10hjjXR023YhIIPAQcB6QA2wQkeWqur3VpstU9Q43h3ga+JWqrhKRCKDnZqHwc+/uyGNIWFCH42CPiwtH1VVDb9k9rz053RzMzBjTf3hSo58H7FHVLFWtBZ4DlnhycBGZBgSp6ioAVa1Q1aoul9Y0a2xUVmfms3Dy8A5vlo7tQhfL9sahN8YMLJ4EfQKQ3eJ9jrOstStFJF1EXhSRppkjJgElIvKyiHwmIg843xCOIyK3iEiaiKQVFJw4wqE50ZacEo5W1Ho0SXJyV4K+uGcfljLGeE9P3Yx9DUhW1RRgFfCUszwIOBP4AXAyMA5Y2npnVX1EVVNVNTUuru2xxs3n3tuZT2CAtDs2e5MhYcHERoSwrxM3ZA8WVhEWHECc9dU2ZsDzJOhzgZZzuyU6y5qpaqGqNk34+Rgw13mdA2x2mn3qgf8Cc7pXZAPwzo585o4Z6vHohcnDwtnXiS6W2cVVJA0d7PeDiBnjCzwJ+g3ARBEZKyIhwDXA8pYbiEjL2ZcXAzta7BstIk3VznOA1jdxTScdKjnGjsNlnOtBs02TsbGdG674YNExa583xkd0GPROTfwOYCWuAH9eVTNE5D4RWexsdqeIZIjIFuBOnOYZVW3A1WzzrohsBQR4tOcvw7+86zwNe86U9vvPt5QcG05BeQ0VNfUdbquq5FgfemN8hkdPxqrqCmBFq2X3tnh9D3BPG/uuAlK6UUbTyns78kgeNpjxceeHyT0AABfKSURBVO6fhnWnaXCz/UcrOxz1sPRYHeU19SQOtRuxxvgCezJ2gKmqreejvYWcMyW+U+3nY+M873lzsIdHrTTGeJcF/QDz0Z5CausbO9U+DzAmxvOgtz70xvgWC/p+Zk9+OT94YUvzWPCtvbsjj8jQIFKTYzp13EEhgYyKCvNoWsHPJxyxoDfGF1jQ9zMPrMzkxY05XPrgWj7YdfzDY42Nyns78zlrUhwhQZ3/X5ccG06WJzX64ipiwkOICLXBTY3xBRb0/cj+o5W8vT2PK+ckEh8Zxo1PfspDq/fQ2Ogae3zboVLyy2s8ehrWHU+HK84uqiLJbsQa4zMs6PuRJz7aR3BAAD9aNJlXbj+dS1NG8cDKTG7910bKqut4d0c+AQILJ3c96Euq6iiurG13O9c49NZsY4yvsO/m/URJVS0vpOWwePYohg9xTYL952tmMzspml+v2MGSBz8CYM7oocSEe/Y0bGvNg5sVVjK0jWM0NCq5Jce4cOZIt+uNMQOP1ej7iWc/OcixugZuPnNs8zIR4avzx/Lvr59KRU09+45Wck4Xm22gxeBm7Yx5c6SsmroGta6VxvgQq9H3A7X1jTz18X7OnBjLlBFDTlg/b2wMb3xrPk+t28+XTx7d5fMkDR1MYIC028WyqbePTThijO+wGn0/8NqWQ+SX13DzmePa3Gb4kDB+eMGUNptcPBESFEDS0EHtDm7WHPQ2PLExPsOC3stUlUc/zGJyfCRnTYzt9fMlx4a323STXVRFgMCoaAt6Y3yFBb2XfbSnkJ1HyvnamWP7ZEjgpi6Wqup2fXbxMUZGDepw1ipjzMBhf81e9uiHWcRGhLJk9qg+Od/Y2HCqal0Tf7tz0EatNMbnWNB70a68ctbsKuDG08YQGnTCDIu9oqP5Y1196K3ZxhhfYkHvRY9/uI+w4AC+cuqYPjtn8rC2g766zlXTtx43xvgWC3ovKSiv4ZXPcvni3MRu9aTprFHRgwgJCnA7uFmOMyH46GEW9Mb4EutH7yVPfrSPusZGvnrG2I437kGBAULysMHNg5s1NCo7DpexYX8R7+5wzVyVaDV6Y3yKBb0XHCis5LG1+7g0ZRTj4iL6/PzJw8LZdLCYm578lLT9xZQ70wsmDh3ENScnMSPhxIe2jDEDlwV9H1NVfr48g+AA4X8umuqVMsxKiubt7XlkFx/j0tmjmJccw8ljY0iwvvPG+CQL+j62anseqzML+MnFUxkRFeaVMnxzwXhuOG0MkWHBXjm/MaZv2c3YPnSstoH/fW07k+IjuPH0ZK+VIyBALOSN8SNWo+9DD63eQ27JMZ675VR78tQY02csbfpIVkEFj3yQxeUnJXDquGHeLo4xxo9Y0PcBVeVnyzMIDQrgnoumeLs4xhg/Y0HfB97adoQPdx/le+dPYnikd27AGmP8lwV9L6uqree+17czdeQQru/DoQ6MMaaJBX0ve/C9PRwureYXS6YTZDdgjTFeYMnTi1SVZRuyuXDGCFKTY7xdHGOMn7Kg70V78isorKzl7Cldn9DbGGO6y6OgF5FFIpIpIntE5G4365eKSIGIbHZ+bm61foiI5IjIgz1VcG+ormvgH2v2cqy2waPt12cVAnDqWOtOaYzxng4fmBKRQOAh4DwgB9ggIstVdXurTZep6h1tHOYXwAfdKmk/8N7OfH7z5k6GhodwdWpSh9uvzypiVFSYTeRhjPEqT2r084A9qpqlqrXAc8AST08gInOBeODtrhWx/0jbXwzAmsyCDrdVVT7ZV8ip44b1yVywxhjTFk+CPgHIbvE+x1nW2pUiki4iL4pIEoCIBAB/AH7Q3glE5BYRSRORtIKCjkPUWzYedAX9h7sLqG9obHfbvQUVHK2otadgjTFe11M3Y18DklU1BVgFPOUsvw1Yoao57e2sqo+oaqqqpsbFxfVQkXpWdV0DGbmljIsNp6y6ns3ZJe1uvy6rCMCC3hjjdZ4EfS7QskE60VnWTFULVbXGefsYMNd5fRpwh4jsB34P3CAiv+1Wib0kPaeU+kbljnMmEBggvN9B8836rEJGWvu8MaYf8CToNwATRWSsiIQA1wDLW24gIiNbvF0M7ABQ1etUdbSqJuNqvnlaVU/otTMQbDzgarZZOHk4c0ZHs2ZX20GvqnySZe3zxpj+ocOgV9V64A5gJa4Af15VM0TkPhFZ7Gx2p4hkiMgW4E5gaW8V2Fs2HihmXGw4MeEhLJgUx9bcUgrKa9xu+3n7vD0kZYzxPo/a6FV1hapOUtXxqvorZ9m9qrrceX2Pqk5X1Vmqeraq7nRzjH+20/2yX1NVNh0sZs6YoYCrVg+um7LurLf2eWNMP2JPxnpgf2EVRZW1zHWCftrIIcRGhLTZTt/UPj86ZnBfFtMYY9yyoPdA2n5XDT3VCfqAAOGsSXF8sLuAhkY9bltVZX1WEaeMjbH2eWNMv2BB74FNB4sZEhbE+LiI5mULJsVRUlVHes7x3Sz3FlRytKLGmm2MMf2GBb0HNh5wtc8HBHxeQz9rYhwinNB80zy+jQW9MaafsKDvQOmxOnblVTB39NDjlg8ND2FW4ondLNdnFTJiSBhjhln7vDGmf7Cg78BnzrAHTTdiW1o4OY4tOSUUVdYCTePbFHHqOGufN8b0Hxb0Hdh0oJgAgVlJ0SesWzh5OKqfd7PMOlpJQXkNp1izjTGmH7Gg78DGg8VMHTmE8NATR3SemRDF0MHBzaNZWvu8MaY/sqBvR31DI5sPlrhttgEIbNHNsrHR1a0yfkgoydY+b4zpRyzo25GZV05lbUObQQ+ubpZHK2rJOFTGehvfxhjTD1nQt6NpILP2gv6sSa5hlZ/8aB8F5dZ/3hjT/1jQt2PjgWLih4SSEN32UMOxEaHMTIjilc2ukZtPGWsDmRlj+hcL+nZsPFDM3DFDO2yKWTg5DlUYHhnK2NjwPiqdMcZ4xoK+DXll1eQUH2PO6LabbZoscJpvrH3eGNMfWdC3YZMH7fNNZidFc960eK5KTeztYhljTKed2DncAK5mm5CgAKaPiupw26DAAB69IbUPSmWMMZ1nNfo2bDxYzKzEKEKC7J/IGDOwWYq5UV3XwLbcUuaOsR40xpiBz4Leja25pdQ1qEft88YY099Z0LvxiTNmzZzRJw5kZowxA40FvRurduQzKymaYRGh3i6KMcZ0mwV9K0dKq9mSXcL50+K9XRRjjOkRFvStrNqRB8AF0y3ojTG+wYK+lbczjjAuNvy4icCNMWYgs6BvofRYHev2FnLe9HgbysAY4zMs6Ft4PzOf+kbl/GkjvF0UY4zpMRb0LbydkUdsRCgnuZkf1hhjBioLekd1XQPvZ+Zz3rR4AgKs2cYY4zs8CnoRWSQimSKyR0TudrN+qYgUiMhm5+dmZ/lsEVknIhkiki4iX+rpC+gp6/YWUlnbwPnW28YY42M6HL1SRAKBh4DzgBxgg4gsV9XtrTZdpqp3tFpWBdygqrtFZBSwUURWqmpJTxS+J729/QgRoUGcPt6mAjTG+BZPavTzgD2qmqWqtcBzwBJPDq6qu1R1t/P6EJAPxHW1sL2loVFZtT2PhZPjCA0K9HZxjDGmR3kS9AlAdov3Oc6y1q50mmdeFJGk1itFZB4QAux1s+4WEUkTkbSCggIPi95zNmcXc7SilvOnW28bY4zv6ambsa8ByaqaAqwCnmq5UkRGAs8AN6lqY+udVfURVU1V1dS4uL6v8L+dkUdwoLBwcr/7smGMMd3mSdDnAi1r6InOsmaqWqiqNc7bx4C5TetEZAjwBvBjVV3fveL2PFVlZcYRThsfy5CwYG8XxxhjepwnQb8BmCgiY0UkBLgGWN5yA6fG3mQxsMNZHgK8Ajytqi/2TJF71p78CvYXVtkgZsYYn9VhrxtVrReRO4CVQCDwhKpmiMh9QJqqLgfuFJHFQD1QBCx1dr8aOAsYJiJNy5aq6uaevYyue3u7axCz8yzojTE+SlTV22U4TmpqqqalpfXZ+ZY8uBYR4b+3n9Fn5zTGmJ4mIhtVNdXdOr9+MvZw6TG25JTaQ1LGGJ/m10H/jtNsY4OYGWN8mV8H/ZpdBSQPG8yE4Tb2vDHGd/lt0Ksqm7NLmTNmqLeLYowxvcpvg/5waTVHK2qYlWhDEhtjfJvfBn16jmtctZTEKC+XxBhjepffBv2WnFKCAoSpI4d4uyjGGNOr/Dbo03NKmDIykrBgG63SGOPb/DLoGxuV9OxSUqx93hjjB/wy6PcVVlJeU88sa583xvgBvwz6z2/EWo3eGOP7/DLot2SXEhYcwER7UMoY4wf8MujTc0qYMSqKoEC/vHxjjJ/xu6Sra2gk41AZs5Ks2cYY4x/8Luh35ZVTU99oD0oZY/yG3wV9ek4pgA19YIzxG34Y9CVEDQpmzLDB3i6KMcb0Cb8L+i3ZpaQkRiEi3i6KMcb0Cb8K+uq6BjLzyq193hjjV/wq6DMOldHQqPaglDHGr/hV0Dc9EWs3Yo0x/sTPgr6U4ZGhjIgK83ZRjDGmz/hV0G/JKbFmG2OM3/GboC+rriOroNJGrDTG+B2/CfptzoNSKTb0gTHGz/hN0G9pCvoEq9EbY/yL3wR9ek4Jo2MGMzQ8xNtFMcaYPuVHQV9qD0oZY/ySR0EvIotEJFNE9ojI3W7WLxWRAhHZ7Pzc3GLdjSKy2/m5sScL76mC8hpyS45Z/3ljjF8K6mgDEQkEHgLOA3KADSKyXFW3t9p0mare0WrfGOBnQCqgwEZn3+IeKb2HPp860Gr0xhj/40mNfh6wR1WzVLUWeA5Y4uHxLwBWqWqRE+6rgEVdK2rXbckpJUBght2INcb4IU+CPgHIbvE+x1nW2pUiki4iL4pIUif37VXpOSVMGB5BeGiHX2CMMcbn9NTN2NeAZFVNwVVrf6ozO4vILSKSJiJpBQUFPVSkz23LLWNmgrXPG2P8kydBnwsktXif6CxrpqqFqlrjvH0MmOvpvs7+j6hqqqqmxsXFeVp2jxRV1nK0ooYpIyJ79LjGGDNQeBL0G4CJIjJWREKAa4DlLTcQkZEt3i4GdjivVwLni8hQERkKnO8s6zO78soBmBgf0ZenNcaYfqPDRmtVrReRO3AFdCDwhKpmiMh9QJqqLgfuFJHFQD1QBCx19i0SkV/g+rAAuE9Vi3rhOtq02wn6yVajN8b4KY/uTqrqCmBFq2X3tnh9D3BPG/s+ATzRjTJ2S2ZeOZFhQYwYYkMTG2P8k88/Gbsrr4JJ8ZE2R6wxxm/5dNCrKrvyypkUb802xhj/5dNBX1BRQ0lVHZPsRqwxxo/5dNDvOlIBwGSr0Rtj/JhvB31z10oLemOM//L5oI8JDyE2wsagN8b4L58P+onDI6zHjTHGr/ls0Ksqu/Mq7EEpY4zf89mgP1xaTXlNvbXPG2P8ns8GfWbT0AcW9MYYP+ezQd80xo31oTfG+DufDfrMIxUMjwwlerD1uDHG+DefDfrd+Tb0gTHGgI8GfWOjq8eNBb0xxvho0OcUH+NYXYO1zxtjDD4a9E09biZZH3pjjPHNoG8e42a41eiNMcZngz4hehCRYcHeLooxxnidjwZ9hbXPG2OMw+eCvr6hkb351uPGGGOa+FzQHyiqorah0YLeGGMcPhf0u440DX1gQW+MMeCLQZ9XgQhMsB43xhgD+GTQlzM6ZjCDQgK9XRRjjOkXfDLordnGGGM+51NBX1vfyL6jlda10hhjWvCpoN93tJL6RrUavTHGtOBTQd88xo0FvTHGNPOpoN+dV05ggDAuLtzbRTHGmH7Do6AXkUUikikie0Tk7na2u1JEVERSnffBIvKUiGwVkR0ick9PFdydzCPlJA8bTGiQ9bgxxpgmHQa9iAQCDwEXAtOAL4vINDfbRQLfBj5psfgqIFRVZwJzgVtFJLn7xXZvd34Fk21oYmOMOY4nNfp5wB5VzVLVWuA5YImb7X4B/A6obrFMgXARCQIGAbVAWfeK7F51XQP7CyuZONyC3hhjWvIk6BOA7Bbvc5xlzURkDpCkqm+02vdFoBI4DBwEfq+qRa1PICK3iEiaiKQVFBR0pvzNKmrquTRlFCcnx3Rpf2OM8VVB3T2AiAQAfwSWulk9D2gARgFDgQ9F5B1VzWq5kao+AjwCkJqaql0pR2xEKH/58kld2dUYY3yaJ0GfCyS1eJ/oLGsSCcwA3hcRgBHAchFZDFwLvKWqdUC+iHwEpALHBb0xxpje40nTzQZgooiMFZEQ4BpgedNKVS1V1VhVTVbVZGA9sFhV03A115wDICLhwKnAzh6+BmOMMe3oMOhVtR64A1gJ7ACeV9UMEbnPqbW35yEgQkQycH1gPKmq6d0ttDHGGM+JapeaxHtNamqqpqWlebsYxhgzoIjIRlVNdbfOp56MNcYYcyILemOM8XEW9MYY4+Ms6I0xxsf1u5uxIlIAHOhgs1jgaB8Upz/y12u36/Yvdt2dN0ZV49yt6HdB7wkRSWvr7rKv89drt+v2L3bdPcuabowxxsdZ0BtjjI8bqEH/iLcL4EX+eu123f7FrrsHDcg2emOMMZ4bqDV6Y4wxHrKgN8YYHzfggt7TicoHOhF5QkTyRWRbi2UxIrJKRHY7/x3qzTL2BhFJEpHVIrJdRDJE5NvOcp++dhEJE5FPRWSLc93/6ywfKyKfOL/vy5yhwn2OiASKyGci8rrz3l+ue7+IbBWRzSKS5izr8d/1ARX0nk5U7iP+CSxqtexu4F1VnQi867z3NfXA91V1Gq75C253/h/7+rXXAOeo6ixgNrBIRE7FNQ/zn1R1AlAMfM2LZexN38Y1DHoTf7lugLNVdXaL/vM9/rs+oIIezycqH/BU9QOg9fy6S4CnnNdPAZf1aaH6gKoeVtVNzutyXH/8Cfj4tatLhfM22PlRXBP3vOgs97nrBhCRROBi4DHnveAH192OHv9dH2hB3+FE5T4uXlUPO6+PAPHeLExvE5Fk4CTgE/zg2p3mi81APrAK2AuUOJP/gO/+vv8fcBfQ6Lwfhn9cN7g+zN8WkY0icouzrMd/17s9ObjxDlVVEfHZvrEiEgG8BHxHVcuc+YgB3712VW0AZotINPAKMMXLRep1InIJkK+qG0VkobfL4wXzVTVXRIYDq0TkuKlWe+p3faDV6DuaqNzX5YnISADnv/leLk+vEJFgXCH/rKq+7Cz2i2sHUNUSYDVwGhAtIk0VMl/8fT8DWCwi+3E1xZ4D/Bnfv24AVDXX+W8+rg/3efTC7/pAC/p2Jyr3A8uBG53XNwKverEsvcJpn30c2KGqf2yxyqevXUTinJo8IjIIOA/X/YnVwBedzXzuulX1HlVNVNVkXH/P76nqdfj4dQOISLiIRDa9Bs4HttELv+sD7slYEbkIV5teIPCEqv7Ky0XqFSLyH2AhrmFL84CfAf8FngdG4xrK+WpVbX3DdkATkfnAh8BWPm+z/R9c7fQ+e+0ikoLrxlsgrgrY86p6n4iMw1XTjQE+A76iqjXeK2nvcZpufqCql/jDdTvX+IrzNgj4t6r+SkSG0cO/6wMu6I0xxnTOQGu6McYY00kW9MYY4+Ms6I0xxsdZ0BtjjI+zoDfGGB9nQW9MDxKRhU0jMBrTX1jQG2OMj7OgN35JRL7ijP++WUT+4QwoViEif3LGg39XROKcbWeLyHoRSReRV5rGBxeRCSLyjjOG/CYRGe8cPkJEXhSRnSLyrLQcqMcYL7CgN35HRKYCXwLOUNXZQANwHRAOpKnqdGANrqeRAZ4GfqSqKbie2G1a/izwkDOG/OlA04iDJwHfwTVnwjhc47kY4zU2eqXxR18A5gIbnMr2IFwDRzUCy5xt/gW8LCJRQLSqrnGWPwW84IxRkqCqrwCoajWAc7xPVTXHeb8ZSAbW9v5lGeOeBb3xRwI8par3HLdQ5Kettuvq+CAtx2RpwP7OjJdZ043xR+8CX3TGAG+ao3MMrr+HphETrwXWqmopUCwiZzrLrwfWOLNf5YjIZc4xQkVkcJ9ehTEespqG8Tuqul1EfoJrZp8AoA64HagE5jnr8nG144NrqNi/O0GeBdzkLL8e+IeI3Occ46o+vAxjPGajVxrjEJEKVY3wdjmM6WnWdGOMMT7OavTGGOPjrEZvjDE+zoLeGGN8nAW9Mcb4OAt6Y4zxcRb0xhjj4/4fqsV9/LaNdqEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7MFYkGuwRbB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07aeee45-065c-49af-f2a6-33e2be28324b"
      },
      "source": [
        "#NNの保存ネットワーク\n",
        "\n",
        "\n",
        "distillation_net: torch.nn.Module = MyNet()\n",
        "    \n",
        "NN: torch.nn.Module = MyNet()\n",
        "    \n",
        "distillation_net2: torch.nn.Module = MyNet()\n",
        "    \n",
        "# 保存したモデルのパラメータを読み込む\n",
        "param2 = torch.load('weight_distillationNN_gc.pth')\n",
        "param3 = torch.load('weight_NN_gc.pth')\n",
        "param4 = torch.load('weight_distillationNN2_gc.pth')\n",
        "\n",
        "\n",
        "# 保存したモデルにパラメータを当てはめる\n",
        "distillation_net.load_state_dict(param2)\n",
        "NN.load_state_dict(param3)\n",
        "distillation_net2.load_state_dict(param4)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx-04Tocwx4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10451e4d-d4f9-4935-b9e7-950cbd3e8752"
      },
      "source": [
        "print(Tnet)\n",
        "print(param)\n",
        "print(distillation_net)\n",
        "print(param2)\n",
        "print(NN)\n",
        "print(param3)\n",
        "print(distillation_net2)\n",
        "print(param4)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyCNN3(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1600, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n",
            "OrderedDict([('conv1.weight', tensor([[[[-0.1687, -0.1699, -0.0443],\n",
            "          [ 0.0337,  0.1241, -0.0337],\n",
            "          [ 0.0716, -0.1144,  0.0994]],\n",
            "\n",
            "         [[ 0.1514, -0.0106,  0.0916],\n",
            "          [ 0.1079, -0.1364,  0.1300],\n",
            "          [-0.2173, -0.3131, -0.3231]],\n",
            "\n",
            "         [[ 0.0888,  0.2423,  0.0313],\n",
            "          [ 0.1031,  0.0491,  0.2293],\n",
            "          [-0.0977, -0.0407, -0.0783]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1972,  0.2018,  0.1519],\n",
            "          [ 0.1243, -0.2673, -0.1259],\n",
            "          [ 0.0866, -0.1371, -0.2320]],\n",
            "\n",
            "         [[ 0.1045, -0.2505, -0.1331],\n",
            "          [-0.0561, -0.2682,  0.1233],\n",
            "          [-0.0252,  0.1284, -0.1227]],\n",
            "\n",
            "         [[-0.1001,  0.0141, -0.0426],\n",
            "          [ 0.0627, -0.1829, -0.1173],\n",
            "          [ 0.1807, -0.1850, -0.0510]]],\n",
            "\n",
            "\n",
            "        [[[-0.3710, -0.0927,  0.0381],\n",
            "          [-0.3109, -0.0333,  0.0981],\n",
            "          [-0.0244,  0.0308, -0.0703]],\n",
            "\n",
            "         [[-0.2719,  0.2028,  0.1639],\n",
            "          [-0.0865,  0.1676,  0.3127],\n",
            "          [ 0.2266,  0.2675,  0.2463]],\n",
            "\n",
            "         [[-0.3533, -0.1799, -0.0010],\n",
            "          [ 0.0358,  0.0839,  0.2879],\n",
            "          [-0.2506, -0.0115, -0.1930]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1553,  0.0302,  0.2422],\n",
            "          [ 0.1636, -0.1692,  0.2452],\n",
            "          [-0.0745, -0.0502,  0.1898]],\n",
            "\n",
            "         [[ 0.0222, -0.1624, -0.0706],\n",
            "          [-0.2239, -0.2018,  0.0969],\n",
            "          [-0.2578, -0.2663,  0.2144]],\n",
            "\n",
            "         [[-0.0182, -0.1917, -0.0073],\n",
            "          [-0.2691, -0.0398, -0.0254],\n",
            "          [ 0.0479, -0.0645, -0.0478]]],\n",
            "\n",
            "\n",
            "        [[[-0.0603, -0.0997,  0.0483],\n",
            "          [-0.0496,  0.1115,  0.0328],\n",
            "          [ 0.0608,  0.1302,  0.1296]],\n",
            "\n",
            "         [[ 0.0978,  0.0425, -0.1835],\n",
            "          [-0.0491, -0.0062,  0.0059],\n",
            "          [ 0.1444,  0.0769, -0.1757]],\n",
            "\n",
            "         [[ 0.1239,  0.0979,  0.0543],\n",
            "          [ 0.2510,  0.2187,  0.2069],\n",
            "          [ 0.0973, -0.0248, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0833,  0.1569,  0.0837],\n",
            "          [ 0.2038, -0.1542,  0.0496],\n",
            "          [ 0.2251, -0.0062, -0.0156]],\n",
            "\n",
            "         [[ 0.1380,  0.0624,  0.0726],\n",
            "          [ 0.1249,  0.0757, -0.0308],\n",
            "          [ 0.1435,  0.1144,  0.0863]],\n",
            "\n",
            "         [[ 0.0959,  0.1910,  0.2194],\n",
            "          [ 0.1350, -0.1177,  0.0484],\n",
            "          [ 0.1743, -0.0420, -0.0817]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0123, -0.0515,  0.0497],\n",
            "          [-0.0838,  0.1747, -0.1987],\n",
            "          [-0.0675,  0.0206, -0.1370]],\n",
            "\n",
            "         [[ 0.0158,  0.1723, -0.0848],\n",
            "          [-0.0196, -0.1518, -0.0986],\n",
            "          [-0.0480, -0.1472,  0.0076]],\n",
            "\n",
            "         [[ 0.0571,  0.1016, -0.0683],\n",
            "          [ 0.0287,  0.2160, -0.0398],\n",
            "          [-0.0497,  0.1690, -0.0764]]],\n",
            "\n",
            "\n",
            "        [[[-0.1802, -0.1225, -0.3408],\n",
            "          [-0.1027, -0.2110, -0.0739],\n",
            "          [ 0.3178,  0.4022,  0.3375]],\n",
            "\n",
            "         [[ 0.0338,  0.1452,  0.1620],\n",
            "          [-0.0634,  0.1189, -0.1171],\n",
            "          [-0.1520, -0.0769,  0.1298]],\n",
            "\n",
            "         [[ 0.2073,  0.2453,  0.0580],\n",
            "          [ 0.1462, -0.1475, -0.1209],\n",
            "          [ 0.0192, -0.2357, -0.3413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0395, -0.0786,  0.0379],\n",
            "          [-0.0416,  0.0366,  0.0557],\n",
            "          [ 0.2106, -0.1755,  0.1157]],\n",
            "\n",
            "         [[ 0.1536,  0.0214,  0.1081],\n",
            "          [ 0.2761,  0.2622,  0.1333],\n",
            "          [ 0.2213,  0.1101,  0.1346]],\n",
            "\n",
            "         [[-0.0704, -0.2090,  0.0492],\n",
            "          [-0.0349, -0.2728, -0.2432],\n",
            "          [-0.2882, -0.1627, -0.3268]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0912,  0.0695,  0.0938],\n",
            "          [ 0.0020,  0.0184, -0.0121],\n",
            "          [-0.1785, -0.2746, -0.2221]],\n",
            "\n",
            "         [[-0.2092, -0.0438, -0.2086],\n",
            "          [-0.1637,  0.0124, -0.0790],\n",
            "          [ 0.0722,  0.1098, -0.1506]],\n",
            "\n",
            "         [[ 0.1524,  0.1519,  0.0027],\n",
            "          [ 0.2291,  0.3117,  0.0609],\n",
            "          [ 0.2672, -0.0010,  0.1309]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1138,  0.1980,  0.0239],\n",
            "          [ 0.2669,  0.1793,  0.0539],\n",
            "          [ 0.2820,  0.2905,  0.1676]],\n",
            "\n",
            "         [[-0.1108, -0.1498, -0.1144],\n",
            "          [-0.2550, -0.2458, -0.2852],\n",
            "          [ 0.0044, -0.2272, -0.2177]],\n",
            "\n",
            "         [[ 0.2158,  0.0744,  0.0249],\n",
            "          [ 0.0140, -0.1154, -0.2145],\n",
            "          [ 0.1372,  0.0486, -0.2580]]],\n",
            "\n",
            "\n",
            "        [[[-0.0360,  0.1211, -0.0137],\n",
            "          [ 0.1150, -0.0007,  0.1339],\n",
            "          [-0.1656,  0.1380,  0.1207]],\n",
            "\n",
            "         [[-0.1988,  0.0272, -0.1375],\n",
            "          [-0.0806,  0.0974,  0.2433],\n",
            "          [-0.0557,  0.1985,  0.2324]],\n",
            "\n",
            "         [[-0.3064, -0.2697, -0.2387],\n",
            "          [-0.1387,  0.0167,  0.1968],\n",
            "          [-0.1229,  0.1228, -0.1284]]],\n",
            "\n",
            "\n",
            "        [[[-0.0377, -0.1728,  0.0735],\n",
            "          [-0.1263, -0.0741, -0.0919],\n",
            "          [-0.1487, -0.0883, -0.1512]],\n",
            "\n",
            "         [[-0.0177,  0.0576,  0.1986],\n",
            "          [ 0.0448, -0.0083, -0.1946],\n",
            "          [-0.2162,  0.0452,  0.1512]],\n",
            "\n",
            "         [[ 0.2618,  0.2376,  0.1923],\n",
            "          [-0.1117,  0.2215,  0.0111],\n",
            "          [ 0.0422,  0.2195,  0.2406]]],\n",
            "\n",
            "\n",
            "        [[[-0.2276, -0.1632,  0.1294],\n",
            "          [-0.2558, -0.0966,  0.1408],\n",
            "          [ 0.0015, -0.0506, -0.0399]],\n",
            "\n",
            "         [[-0.0080, -0.0666, -0.0799],\n",
            "          [-0.2522,  0.1411,  0.0401],\n",
            "          [ 0.1677,  0.2401,  0.1445]],\n",
            "\n",
            "         [[-0.1230,  0.1411,  0.0712],\n",
            "          [-0.1687,  0.0081, -0.0562],\n",
            "          [-0.0911,  0.0046,  0.0662]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2484,  0.1116,  0.1148],\n",
            "          [ 0.1416,  0.2088,  0.0621],\n",
            "          [-0.2196, -0.0169, -0.1840]],\n",
            "\n",
            "         [[-0.0075, -0.0269, -0.1751],\n",
            "          [-0.1700,  0.0770, -0.1157],\n",
            "          [ 0.1827, -0.1048, -0.0247]],\n",
            "\n",
            "         [[-0.2883, -0.0134,  0.0912],\n",
            "          [-0.0756, -0.1194,  0.1999],\n",
            "          [ 0.1326,  0.0097,  0.2066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0758,  0.0730, -0.0628],\n",
            "          [ 0.0176,  0.0014,  0.0326],\n",
            "          [ 0.1015,  0.0155, -0.1424]],\n",
            "\n",
            "         [[-0.0689,  0.0805, -0.0778],\n",
            "          [-0.0121,  0.0220,  0.1815],\n",
            "          [-0.1301,  0.2033,  0.1276]],\n",
            "\n",
            "         [[ 0.0387, -0.0795,  0.0927],\n",
            "          [ 0.0808,  0.1365, -0.0866],\n",
            "          [-0.1084,  0.1955,  0.0246]]],\n",
            "\n",
            "\n",
            "        [[[-0.0673, -0.2721, -0.0759],\n",
            "          [ 0.1715, -0.0810,  0.0319],\n",
            "          [ 0.0087, -0.1947,  0.1634]],\n",
            "\n",
            "         [[-0.0889,  0.0074,  0.0922],\n",
            "          [ 0.3109, -0.0187, -0.1434],\n",
            "          [-0.0437,  0.1713,  0.1166]],\n",
            "\n",
            "         [[ 0.0275, -0.0859,  0.0918],\n",
            "          [ 0.0129, -0.0297, -0.1985],\n",
            "          [ 0.0869, -0.1729,  0.1069]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0453, -0.2017,  0.3913],\n",
            "          [-0.1513, -0.0201,  0.0875],\n",
            "          [-0.2461,  0.1516,  0.2052]],\n",
            "\n",
            "         [[-0.1408, -0.1726,  0.1170],\n",
            "          [-0.3783,  0.0342,  0.3453],\n",
            "          [-0.1771,  0.1845,  0.0033]],\n",
            "\n",
            "         [[-0.2918, -0.1673,  0.3039],\n",
            "          [-0.2272,  0.0857,  0.0423],\n",
            "          [-0.0902,  0.1570,  0.1017]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0881, -0.0037,  0.1357],\n",
            "          [-0.1048, -0.1403,  0.0117],\n",
            "          [-0.1056,  0.0094,  0.1411]],\n",
            "\n",
            "         [[ 0.1169,  0.0627,  0.1461],\n",
            "          [ 0.1705, -0.0079,  0.1106],\n",
            "          [-0.0680,  0.1974,  0.0083]],\n",
            "\n",
            "         [[-0.0569,  0.1688, -0.0960],\n",
            "          [ 0.2129,  0.1639,  0.1676],\n",
            "          [ 0.0119,  0.1658, -0.1469]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1798, -0.0927,  0.0079],\n",
            "          [ 0.0704,  0.0725,  0.0435],\n",
            "          [ 0.0202, -0.2313, -0.0939]],\n",
            "\n",
            "         [[ 0.0827, -0.2561,  0.0420],\n",
            "          [-0.0986, -0.3370, -0.1520],\n",
            "          [ 0.1823, -0.1257,  0.0031]],\n",
            "\n",
            "         [[ 0.1965, -0.1850,  0.0056],\n",
            "          [ 0.0363,  0.0144, -0.0378],\n",
            "          [ 0.0585,  0.0087, -0.0900]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0936,  0.3400,  0.2225],\n",
            "          [ 0.0501, -0.1769,  0.1368],\n",
            "          [-0.1097, -0.1875, -0.2945]],\n",
            "\n",
            "         [[ 0.2150,  0.2538,  0.0749],\n",
            "          [-0.0329, -0.1415, -0.0798],\n",
            "          [-0.2477, -0.2555, -0.1695]],\n",
            "\n",
            "         [[ 0.1557,  0.1226,  0.0890],\n",
            "          [ 0.0404,  0.0834, -0.1654],\n",
            "          [-0.0017, -0.1121,  0.0679]]],\n",
            "\n",
            "\n",
            "        [[[-0.3639, -0.1160, -0.1185],\n",
            "          [-0.0546, -0.3486,  0.0087],\n",
            "          [-0.3763, -0.1296, -0.2460]],\n",
            "\n",
            "         [[-0.0009,  0.1270,  0.0678],\n",
            "          [ 0.3054,  0.2966, -0.0788],\n",
            "          [-0.0900,  0.1141, -0.2111]],\n",
            "\n",
            "         [[ 0.2099,  0.2429, -0.3282],\n",
            "          [ 0.3366,  0.3727,  0.2209],\n",
            "          [ 0.2256,  0.0436,  0.0063]]],\n",
            "\n",
            "\n",
            "        [[[-0.1971, -0.2703, -0.3641],\n",
            "          [ 0.2347, -0.0187,  0.1730],\n",
            "          [ 0.1160,  0.2193,  0.0995]],\n",
            "\n",
            "         [[-0.2414, -0.1943, -0.2743],\n",
            "          [-0.1360, -0.0269,  0.1170],\n",
            "          [ 0.2221,  0.1182,  0.2105]],\n",
            "\n",
            "         [[-0.2449, -0.1086, -0.0354],\n",
            "          [ 0.0022,  0.1904,  0.1270],\n",
            "          [ 0.2588,  0.0946, -0.0995]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1318, -0.0571, -0.1317],\n",
            "          [ 0.1344,  0.1802,  0.2044],\n",
            "          [ 0.2125, -0.0019,  0.1665]],\n",
            "\n",
            "         [[-0.1630,  0.2057,  0.1096],\n",
            "          [-0.0408, -0.0636, -0.1646],\n",
            "          [-0.2580, -0.0697, -0.0304]],\n",
            "\n",
            "         [[ 0.2871,  0.0459,  0.2077],\n",
            "          [ 0.2065,  0.1705, -0.2312],\n",
            "          [-0.1005,  0.1509, -0.2661]]],\n",
            "\n",
            "\n",
            "        [[[-0.2941, -0.3979,  0.0217],\n",
            "          [ 0.2801, -0.0414, -0.0363],\n",
            "          [ 0.4266,  0.0803,  0.0376]],\n",
            "\n",
            "         [[-0.0188, -0.2720, -0.1020],\n",
            "          [ 0.1428,  0.1821, -0.1245],\n",
            "          [ 0.3533, -0.1681, -0.0588]],\n",
            "\n",
            "         [[ 0.0332, -0.0603, -0.0968],\n",
            "          [ 0.3326, -0.0912,  0.1560],\n",
            "          [ 0.1547, -0.1371, -0.2957]]],\n",
            "\n",
            "\n",
            "        [[[-0.0245, -0.0085, -0.0631],\n",
            "          [ 0.0935, -0.1548,  0.2370],\n",
            "          [-0.1925,  0.0240,  0.2389]],\n",
            "\n",
            "         [[ 0.0378, -0.2800,  0.1688],\n",
            "          [-0.0580,  0.0597,  0.2166],\n",
            "          [-0.0244, -0.0927,  0.1836]],\n",
            "\n",
            "         [[-0.1631, -0.0182,  0.0994],\n",
            "          [-0.0321, -0.0355,  0.2135],\n",
            "          [-0.1608, -0.2388,  0.0026]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3650, -0.0521, -0.2941],\n",
            "          [ 0.3459,  0.0706, -0.3230],\n",
            "          [-0.0947,  0.1936, -0.1272]],\n",
            "\n",
            "         [[ 0.1231, -0.0185, -0.2731],\n",
            "          [ 0.3125, -0.1807, -0.1858],\n",
            "          [ 0.2306,  0.0753, -0.1684]],\n",
            "\n",
            "         [[ 0.0752, -0.1068, -0.0837],\n",
            "          [ 0.2848,  0.1469, -0.3429],\n",
            "          [-0.0549,  0.1214, -0.0341]]],\n",
            "\n",
            "\n",
            "        [[[-0.1719,  0.2783, -0.1045],\n",
            "          [-0.0431,  0.3633,  0.2550],\n",
            "          [ 0.2925,  0.1644,  0.3013]],\n",
            "\n",
            "         [[ 0.1239, -0.0022,  0.0440],\n",
            "          [-0.0479, -0.0511, -0.2251],\n",
            "          [ 0.2164, -0.1982,  0.1886]],\n",
            "\n",
            "         [[-0.0511,  0.0064, -0.2944],\n",
            "          [-0.1528, -0.3373, -0.1655],\n",
            "          [-0.1431, -0.1562, -0.1363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0153,  0.0689, -0.0167],\n",
            "          [-0.2392, -0.3520, -0.2261],\n",
            "          [-0.2395, -0.1699, -0.1024]],\n",
            "\n",
            "         [[ 0.3874,  0.3867,  0.2640],\n",
            "          [ 0.0205, -0.1717,  0.0822],\n",
            "          [-0.1459,  0.1556,  0.1283]],\n",
            "\n",
            "         [[ 0.1928,  0.0830,  0.1029],\n",
            "          [-0.1274, -0.0548, -0.1059],\n",
            "          [ 0.1528, -0.0542,  0.1178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3221,  0.4039, -0.2374],\n",
            "          [ 0.2324,  0.0868, -0.2404],\n",
            "          [ 0.0447, -0.2005, -0.3043]],\n",
            "\n",
            "         [[ 0.2096,  0.3054, -0.1720],\n",
            "          [ 0.3233,  0.0837, -0.3843],\n",
            "          [ 0.2079,  0.0792,  0.0419]],\n",
            "\n",
            "         [[ 0.1421, -0.1432, -0.3634],\n",
            "          [ 0.0567,  0.0656, -0.3671],\n",
            "          [-0.0449, -0.0359, -0.1677]]],\n",
            "\n",
            "\n",
            "        [[[-0.1164,  0.0824,  0.2759],\n",
            "          [ 0.0717, -0.1368,  0.1851],\n",
            "          [-0.1785,  0.0551, -0.2627]],\n",
            "\n",
            "         [[ 0.0468,  0.1526,  0.2329],\n",
            "          [-0.1216, -0.1473, -0.0586],\n",
            "          [ 0.1897, -0.1889, -0.1273]],\n",
            "\n",
            "         [[ 0.0738,  0.0133, -0.0718],\n",
            "          [-0.0337,  0.1221, -0.1479],\n",
            "          [ 0.1537, -0.1731,  0.1354]]],\n",
            "\n",
            "\n",
            "        [[[-0.1583, -0.0894, -0.1420],\n",
            "          [-0.3200,  0.0483,  0.1076],\n",
            "          [-0.1942,  0.1898,  0.1679]],\n",
            "\n",
            "         [[-0.1944, -0.2670, -0.0908],\n",
            "          [-0.3251, -0.0478,  0.0145],\n",
            "          [ 0.0060,  0.0308,  0.3620]],\n",
            "\n",
            "         [[ 0.0707, -0.3309,  0.0185],\n",
            "          [-0.0624, -0.0994,  0.0152],\n",
            "          [-0.0213,  0.2460,  0.1678]]]], device='cuda:0')), ('conv1.bias', tensor([ 0.2544, -0.0730,  0.3770, -0.0704,  0.1279, -0.0479, -0.1292,  0.0142,\n",
            "         0.0619,  0.3849, -0.1484,  0.1930,  0.0498, -0.1157,  0.0927, -0.1509,\n",
            "         0.0825,  0.0159,  0.3120, -0.1247, -0.0657,  0.2188, -0.0661,  0.6053,\n",
            "         0.4509,  0.1842,  0.0094, -0.0929,  0.3044,  0.4366, -0.0183,  0.1170],\n",
            "       device='cuda:0')), ('conv2.weight', tensor([[[[ 0.0014,  0.0314,  0.0216],\n",
            "          [ 0.0034, -0.0117,  0.0509],\n",
            "          [ 0.0055, -0.0185,  0.0233]],\n",
            "\n",
            "         [[-0.0783, -0.0933, -0.0538],\n",
            "          [ 0.0095, -0.0197, -0.0617],\n",
            "          [-0.0059, -0.0040, -0.0345]],\n",
            "\n",
            "         [[ 0.0231,  0.0776, -0.0231],\n",
            "          [ 0.0094, -0.0248,  0.0166],\n",
            "          [-0.0314,  0.0567,  0.0014]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0196,  0.0355,  0.0400],\n",
            "          [ 0.0044, -0.0247,  0.1165],\n",
            "          [-0.0028,  0.0401,  0.0968]],\n",
            "\n",
            "         [[-0.0627,  0.0044, -0.0398],\n",
            "          [-0.0025, -0.0743, -0.0375],\n",
            "          [-0.0664, -0.0341,  0.0139]],\n",
            "\n",
            "         [[-0.0167, -0.0201, -0.0739],\n",
            "          [-0.0219,  0.0461,  0.0333],\n",
            "          [-0.0531,  0.0289, -0.0187]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0532, -0.0485, -0.0104],\n",
            "          [ 0.0168, -0.0085, -0.0232],\n",
            "          [-0.0898, -0.0964, -0.0272]],\n",
            "\n",
            "         [[ 0.0007, -0.0635, -0.0243],\n",
            "          [-0.0224, -0.0245,  0.0812],\n",
            "          [ 0.0612,  0.0991,  0.0779]],\n",
            "\n",
            "         [[ 0.0200,  0.0265,  0.0538],\n",
            "          [-0.0307, -0.0929, -0.0493],\n",
            "          [ 0.0357, -0.0395, -0.0424]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0550, -0.0943, -0.0386],\n",
            "          [ 0.0314,  0.0093, -0.0180],\n",
            "          [-0.0380,  0.0030,  0.0567]],\n",
            "\n",
            "         [[-0.0781, -0.0828, -0.0138],\n",
            "          [ 0.1099,  0.0214,  0.0783],\n",
            "          [ 0.0051,  0.0862, -0.0111]],\n",
            "\n",
            "         [[-0.0661,  0.0064, -0.0221],\n",
            "          [-0.0832, -0.0603, -0.0325],\n",
            "          [ 0.1382,  0.1028,  0.0385]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0280,  0.0888,  0.0013],\n",
            "          [-0.0234,  0.0298,  0.0223],\n",
            "          [ 0.0224, -0.0525, -0.0258]],\n",
            "\n",
            "         [[ 0.0389,  0.1015, -0.0200],\n",
            "          [ 0.0947, -0.0054, -0.0313],\n",
            "          [-0.0037,  0.0129, -0.1018]],\n",
            "\n",
            "         [[-0.0309, -0.0705, -0.1001],\n",
            "          [-0.1812, -0.0562,  0.0192],\n",
            "          [-0.0434,  0.0243, -0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0014,  0.1154,  0.0038],\n",
            "          [ 0.1249,  0.0003, -0.1355],\n",
            "          [-0.0269, -0.0818, -0.1669]],\n",
            "\n",
            "         [[ 0.0587, -0.0560,  0.0358],\n",
            "          [ 0.0472, -0.0353,  0.0455],\n",
            "          [-0.0205, -0.0286,  0.0005]],\n",
            "\n",
            "         [[-0.1593, -0.0706,  0.0446],\n",
            "          [-0.0396,  0.0056,  0.1429],\n",
            "          [ 0.0454,  0.1228, -0.0150]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0573, -0.0124,  0.0634],\n",
            "          [ 0.0027,  0.0362, -0.0544],\n",
            "          [ 0.0561,  0.0697,  0.0167]],\n",
            "\n",
            "         [[-0.0010, -0.0065,  0.0624],\n",
            "          [-0.0283,  0.0581,  0.0426],\n",
            "          [-0.0361, -0.0343, -0.0229]],\n",
            "\n",
            "         [[-0.0597, -0.0097, -0.0738],\n",
            "          [ 0.0250,  0.0209,  0.0358],\n",
            "          [ 0.0140, -0.0068,  0.0091]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0171, -0.0674, -0.0133],\n",
            "          [-0.0385, -0.0668, -0.0733],\n",
            "          [-0.0049, -0.0551, -0.0355]],\n",
            "\n",
            "         [[-0.0027, -0.0018,  0.0044],\n",
            "          [-0.0279,  0.0509,  0.0513],\n",
            "          [-0.0120,  0.0464,  0.0712]],\n",
            "\n",
            "         [[-0.0392, -0.0186, -0.0090],\n",
            "          [ 0.0935,  0.0844, -0.0103],\n",
            "          [ 0.0160, -0.0510,  0.0352]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0650,  0.0424, -0.0387],\n",
            "          [ 0.0631, -0.0174,  0.0459],\n",
            "          [ 0.0084,  0.0589,  0.0181]],\n",
            "\n",
            "         [[ 0.0507,  0.0470,  0.0842],\n",
            "          [-0.0244,  0.0457,  0.0115],\n",
            "          [-0.0348, -0.0344,  0.0206]],\n",
            "\n",
            "         [[ 0.0107,  0.0050,  0.0167],\n",
            "          [-0.0696, -0.0629, -0.0046],\n",
            "          [ 0.0213, -0.0331, -0.0526]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0147,  0.0376, -0.0169],\n",
            "          [-0.0393,  0.0135, -0.0117],\n",
            "          [ 0.0073,  0.0046, -0.0343]],\n",
            "\n",
            "         [[-0.0529, -0.0389, -0.0473],\n",
            "          [ 0.0444,  0.0481,  0.0508],\n",
            "          [ 0.0169,  0.0370,  0.0022]],\n",
            "\n",
            "         [[ 0.0542,  0.0272,  0.0257],\n",
            "          [-0.0164, -0.0161, -0.0038],\n",
            "          [ 0.0023,  0.0486,  0.0704]]],\n",
            "\n",
            "\n",
            "        [[[-0.0196,  0.0176, -0.0390],\n",
            "          [-0.0283, -0.0278,  0.0224],\n",
            "          [-0.0633,  0.0004, -0.0369]],\n",
            "\n",
            "         [[-0.0525,  0.0249, -0.0750],\n",
            "          [-0.1230,  0.0449, -0.0322],\n",
            "          [-0.0086, -0.0385, -0.0071]],\n",
            "\n",
            "         [[ 0.0662, -0.1187,  0.0509],\n",
            "          [ 0.0136, -0.0772,  0.0595],\n",
            "          [ 0.0679, -0.1558,  0.0462]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0383,  0.0992, -0.1084],\n",
            "          [-0.0677,  0.0826, -0.1335],\n",
            "          [-0.0171,  0.1297, -0.1616]],\n",
            "\n",
            "         [[-0.0364, -0.0466, -0.0192],\n",
            "          [-0.0555,  0.0278, -0.0412],\n",
            "          [ 0.0144, -0.0443,  0.0120]],\n",
            "\n",
            "         [[ 0.0225, -0.0488,  0.0934],\n",
            "          [ 0.0468, -0.0386,  0.0081],\n",
            "          [-0.0116, -0.0659, -0.0380]]]], device='cuda:0')), ('conv2.bias', tensor([ 0.1564, -0.0845, -0.0079,  0.1406, -0.0668,  0.0068, -0.0839, -0.0357,\n",
            "         0.0974,  0.0638, -0.0164, -0.0829,  0.0209,  0.0584,  0.0743,  0.0612,\n",
            "         0.1393,  0.0496,  0.0876,  0.1347,  0.0588,  0.1662,  0.0077,  0.0394,\n",
            "         0.0397,  0.0618, -0.1605,  0.1658,  0.0437, -0.0508, -0.0272,  0.1338],\n",
            "       device='cuda:0')), ('conv3.weight', tensor([[[[-0.0102, -0.0314, -0.0324],\n",
            "          [-0.0468, -0.0774, -0.0433],\n",
            "          [-0.0609, -0.0714, -0.0468]],\n",
            "\n",
            "         [[-0.0261,  0.0652,  0.0633],\n",
            "          [-0.0587,  0.0530, -0.0489],\n",
            "          [-0.0369, -0.0119, -0.0327]],\n",
            "\n",
            "         [[-0.0416, -0.0117,  0.0082],\n",
            "          [-0.0385,  0.0316,  0.0882],\n",
            "          [ 0.0069, -0.0048,  0.0493]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0254,  0.0211, -0.0360],\n",
            "          [-0.0190, -0.0367, -0.0071],\n",
            "          [-0.0124, -0.0504, -0.0358]],\n",
            "\n",
            "         [[ 0.0287, -0.0099,  0.0032],\n",
            "          [-0.0065,  0.0024,  0.0394],\n",
            "          [ 0.0341,  0.0444, -0.0144]],\n",
            "\n",
            "         [[ 0.0583,  0.0435,  0.0074],\n",
            "          [ 0.0394,  0.0161, -0.0435],\n",
            "          [-0.0184,  0.0355,  0.0061]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0319, -0.0195,  0.0603],\n",
            "          [ 0.0555,  0.0487, -0.0167],\n",
            "          [ 0.0829,  0.0146, -0.0264]],\n",
            "\n",
            "         [[-0.0789, -0.0681,  0.0312],\n",
            "          [-0.0832,  0.0050,  0.0455],\n",
            "          [-0.1189, -0.1049, -0.0521]],\n",
            "\n",
            "         [[-0.0461,  0.0447,  0.0172],\n",
            "          [-0.0148, -0.0238, -0.0198],\n",
            "          [-0.0109, -0.0886, -0.0631]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0242, -0.0685, -0.0616],\n",
            "          [-0.0757,  0.0008,  0.0238],\n",
            "          [-0.0402,  0.0309,  0.0365]],\n",
            "\n",
            "         [[-0.0269,  0.0003,  0.0098],\n",
            "          [-0.0459, -0.0606,  0.0082],\n",
            "          [-0.0834, -0.0115,  0.0061]],\n",
            "\n",
            "         [[ 0.0327,  0.0465,  0.0613],\n",
            "          [ 0.1270,  0.0891,  0.0244],\n",
            "          [ 0.1436,  0.1318,  0.0866]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0262, -0.0370,  0.0652],\n",
            "          [-0.0069, -0.0368, -0.0157],\n",
            "          [ 0.0378, -0.0374,  0.0125]],\n",
            "\n",
            "         [[-0.0227,  0.0207, -0.0036],\n",
            "          [-0.0766, -0.0026, -0.0541],\n",
            "          [-0.0436,  0.0159,  0.0289]],\n",
            "\n",
            "         [[ 0.0904,  0.0664,  0.0521],\n",
            "          [ 0.0124,  0.0323,  0.0341],\n",
            "          [ 0.0255,  0.0576,  0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0497,  0.0309, -0.0104],\n",
            "          [ 0.0499, -0.0095, -0.0094],\n",
            "          [-0.0145, -0.0441, -0.0400]],\n",
            "\n",
            "         [[ 0.0285,  0.0517,  0.0534],\n",
            "          [ 0.0430, -0.0332,  0.0299],\n",
            "          [-0.0166, -0.0487,  0.0498]],\n",
            "\n",
            "         [[ 0.0143,  0.0045,  0.0372],\n",
            "          [ 0.0145, -0.0016, -0.0068],\n",
            "          [-0.0303,  0.0320, -0.0503]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0265,  0.0326,  0.0342],\n",
            "          [-0.0051, -0.0394, -0.0432],\n",
            "          [ 0.0400,  0.0216,  0.0529]],\n",
            "\n",
            "         [[-0.0605, -0.0315,  0.0286],\n",
            "          [ 0.0551, -0.0317,  0.0416],\n",
            "          [-0.0106,  0.0006,  0.0553]],\n",
            "\n",
            "         [[-0.0547,  0.0401, -0.0221],\n",
            "          [ 0.0347, -0.0232,  0.0446],\n",
            "          [-0.0319, -0.0290, -0.0497]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0036, -0.0341, -0.0148],\n",
            "          [ 0.0655,  0.0425,  0.0482],\n",
            "          [ 0.0641,  0.0079,  0.0345]],\n",
            "\n",
            "         [[-0.0402,  0.0194,  0.0052],\n",
            "          [ 0.0505,  0.0216, -0.0514],\n",
            "          [-0.0006, -0.0456, -0.0515]],\n",
            "\n",
            "         [[ 0.0323,  0.0156,  0.0260],\n",
            "          [ 0.0502,  0.0237, -0.0103],\n",
            "          [ 0.0334,  0.0320, -0.0249]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0230,  0.0443,  0.0098],\n",
            "          [ 0.0202,  0.0276, -0.0164],\n",
            "          [ 0.0698, -0.0417, -0.0677]],\n",
            "\n",
            "         [[-0.0500, -0.0128, -0.0256],\n",
            "          [ 0.0367,  0.0080,  0.0182],\n",
            "          [-0.0093,  0.0067, -0.0371]],\n",
            "\n",
            "         [[ 0.0087, -0.0071, -0.0042],\n",
            "          [-0.0347,  0.0417,  0.0985],\n",
            "          [ 0.0046, -0.0309,  0.0298]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0284,  0.0665, -0.0069],\n",
            "          [-0.0350, -0.0365, -0.0279],\n",
            "          [-0.0551, -0.0389,  0.0209]],\n",
            "\n",
            "         [[ 0.0008,  0.0329, -0.0435],\n",
            "          [ 0.0168, -0.0223,  0.0249],\n",
            "          [ 0.0147,  0.0029,  0.0039]],\n",
            "\n",
            "         [[ 0.0073, -0.0954,  0.0057],\n",
            "          [-0.0439, -0.0799, -0.0960],\n",
            "          [-0.0921, -0.0866, -0.0778]]],\n",
            "\n",
            "\n",
            "        [[[-0.0348, -0.0377, -0.0391],\n",
            "          [ 0.0833,  0.0803, -0.0091],\n",
            "          [ 0.0860, -0.0035,  0.0416]],\n",
            "\n",
            "         [[-0.0329,  0.0200, -0.0377],\n",
            "          [ 0.0455, -0.0366,  0.0012],\n",
            "          [ 0.0484, -0.0412,  0.0575]],\n",
            "\n",
            "         [[ 0.1100,  0.0251,  0.0365],\n",
            "          [ 0.0793,  0.0550,  0.0909],\n",
            "          [-0.0015,  0.0035,  0.0672]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0862,  0.0453,  0.0525],\n",
            "          [ 0.0480,  0.1036,  0.0589],\n",
            "          [ 0.0713,  0.0696,  0.0961]],\n",
            "\n",
            "         [[-0.0167, -0.0404,  0.0060],\n",
            "          [-0.0412, -0.0344, -0.0656],\n",
            "          [-0.0173, -0.0302, -0.0405]],\n",
            "\n",
            "         [[-0.0656, -0.0317, -0.0153],\n",
            "          [ 0.0067, -0.0241, -0.0254],\n",
            "          [-0.0221, -0.0717, -0.0739]]]], device='cuda:0')), ('conv3.bias', tensor([ 0.1619,  0.2294,  0.1769,  0.1374, -0.0831,  0.0617, -0.0544, -0.0384,\n",
            "        -0.0348, -0.0474, -0.0678,  0.1594, -0.0595,  0.2737,  0.0144, -0.0520,\n",
            "        -0.2140, -0.0283,  0.0642,  0.0969, -0.0105,  0.1449, -0.1491,  0.2241,\n",
            "        -0.0338,  0.0159, -0.1683, -0.0093, -0.0327,  0.1549, -0.0956,  0.0457,\n",
            "         0.2325, -0.0261, -0.1456,  0.4664,  0.5524,  0.1640,  0.0630, -0.0234,\n",
            "        -0.0318,  0.3210, -0.1960, -0.0127,  0.3607,  0.0866,  0.0892, -0.0262,\n",
            "        -0.0307,  0.1760,  0.0574,  0.1621, -0.0168,  0.1654,  0.1733,  0.0682,\n",
            "        -0.0783,  0.0241,  0.1508,  0.2837, -0.0625,  0.1465,  0.2319, -0.0859],\n",
            "       device='cuda:0')), ('conv4.weight', tensor([[[[-1.7901e-02, -1.1724e-02,  4.4346e-02],\n",
            "          [ 1.5255e-02, -4.1251e-03, -1.4560e-02],\n",
            "          [-2.2641e-02,  4.1322e-02,  2.1226e-02]],\n",
            "\n",
            "         [[-5.0197e-02,  2.4124e-02, -2.1402e-02],\n",
            "          [-1.5654e-02,  1.4623e-02,  2.3613e-02],\n",
            "          [-5.1812e-02, -1.6770e-03,  1.5350e-02]],\n",
            "\n",
            "         [[ 1.3046e-02,  3.5004e-03, -3.7958e-02],\n",
            "          [ 3.1453e-03, -6.0299e-03,  2.9113e-02],\n",
            "          [-1.2389e-02,  5.9494e-03,  4.1182e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4008e-02, -2.5156e-02, -2.6150e-02],\n",
            "          [ 4.0315e-02, -1.8788e-02, -2.2328e-02],\n",
            "          [ 1.4713e-02,  1.3054e-02, -3.4931e-02]],\n",
            "\n",
            "         [[ 9.0609e-03, -4.0388e-02, -1.0549e-02],\n",
            "          [-4.4932e-02, -2.3960e-02,  4.8658e-03],\n",
            "          [ 1.3351e-02, -2.3602e-02,  7.0660e-02]],\n",
            "\n",
            "         [[ 2.4517e-02,  4.7283e-03,  1.4813e-02],\n",
            "          [-4.2130e-02, -4.0275e-02, -1.6745e-02],\n",
            "          [-4.3604e-02, -4.8247e-02, -5.4649e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.0125e-03,  2.4052e-02,  2.8959e-02],\n",
            "          [-1.1448e-02,  6.3736e-03,  3.3237e-02],\n",
            "          [-1.3642e-02, -1.2650e-02, -9.8914e-03]],\n",
            "\n",
            "         [[ 5.8966e-02,  3.7048e-02,  4.8805e-02],\n",
            "          [ 3.9934e-02,  6.8252e-03,  4.5116e-02],\n",
            "          [ 5.1943e-02,  9.1099e-03,  2.4520e-02]],\n",
            "\n",
            "         [[ 1.7169e-02,  2.3133e-02,  4.9864e-02],\n",
            "          [ 3.2291e-02,  1.9767e-02,  4.3827e-02],\n",
            "          [-1.0283e-03,  4.0025e-02,  2.1595e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8244e-02,  1.5179e-02, -1.9296e-02],\n",
            "          [ 4.3084e-02,  2.9277e-02,  2.7096e-02],\n",
            "          [-2.4655e-02,  7.4807e-04,  1.7529e-02]],\n",
            "\n",
            "         [[ 4.3466e-03,  5.0961e-02,  1.9005e-02],\n",
            "          [ 4.0878e-02,  2.8433e-02, -1.2581e-02],\n",
            "          [ 1.2619e-02,  3.8128e-02,  3.8271e-02]],\n",
            "\n",
            "         [[ 4.8671e-03, -3.6262e-02,  2.5591e-02],\n",
            "          [-1.9402e-02,  1.8135e-02,  4.2954e-02],\n",
            "          [-3.7442e-02, -1.1142e-02, -2.2406e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.0193e-03,  2.6611e-02, -2.6306e-02],\n",
            "          [ 1.1555e-02, -2.7801e-03, -2.9245e-02],\n",
            "          [ 5.3017e-02, -1.7987e-02,  1.1943e-02]],\n",
            "\n",
            "         [[-3.1615e-02, -2.0290e-02,  2.0617e-02],\n",
            "          [-4.3296e-02,  1.3095e-02, -2.2647e-02],\n",
            "          [-4.7684e-02,  2.9604e-02, -1.3126e-02]],\n",
            "\n",
            "         [[ 7.9172e-02,  6.0166e-03,  4.5969e-02],\n",
            "          [ 6.7371e-02,  5.4002e-02, -1.3318e-02],\n",
            "          [ 7.0876e-02,  1.4320e-03,  2.9766e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1726e-02,  2.4630e-03,  5.5661e-02],\n",
            "          [-6.1219e-03,  2.0793e-02,  4.9001e-02],\n",
            "          [-2.6797e-02, -6.6939e-03,  4.4228e-02]],\n",
            "\n",
            "         [[-3.4602e-03, -1.3461e-02,  8.0743e-03],\n",
            "          [-1.5254e-02, -5.5195e-02,  2.3810e-02],\n",
            "          [-5.9015e-02, -3.8322e-02, -2.2027e-02]],\n",
            "\n",
            "         [[-6.8976e-02,  1.0267e-02, -3.5111e-03],\n",
            "          [-3.9802e-02, -2.7424e-02,  4.4760e-02],\n",
            "          [-1.0971e-01, -2.2892e-03, -3.4555e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 4.2094e-02, -2.2977e-02,  3.6723e-02],\n",
            "          [-2.0575e-02, -1.3020e-02,  4.5388e-02],\n",
            "          [ 1.8514e-03,  2.0150e-02,  1.2616e-02]],\n",
            "\n",
            "         [[ 1.7299e-02,  2.7146e-02,  1.6584e-02],\n",
            "          [-2.7413e-02,  6.5253e-03,  1.8903e-03],\n",
            "          [-1.6962e-02, -4.6584e-02,  5.1575e-03]],\n",
            "\n",
            "         [[-1.6479e-02,  1.4932e-02,  6.4438e-02],\n",
            "          [ 1.6657e-03,  2.8155e-02, -7.7925e-03],\n",
            "          [ 1.9596e-02,  3.8568e-02,  9.9051e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7070e-02,  5.6998e-03,  1.1207e-02],\n",
            "          [-2.0630e-02, -1.0201e-02,  2.7979e-02],\n",
            "          [ 1.3224e-02, -4.7497e-03,  5.3244e-03]],\n",
            "\n",
            "         [[ 5.2667e-02,  6.5728e-02,  3.5802e-02],\n",
            "          [ 1.0211e-02,  4.2092e-02,  5.2607e-02],\n",
            "          [ 4.5026e-02,  4.1310e-02,  4.2344e-02]],\n",
            "\n",
            "         [[-3.8582e-02, -3.9212e-02, -8.6595e-03],\n",
            "          [-4.9492e-03, -4.4917e-02, -2.0211e-02],\n",
            "          [ 3.3210e-02,  1.6529e-03,  6.1972e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1478e-02,  1.0831e-02, -1.1440e-03],\n",
            "          [ 6.2888e-02,  4.6565e-02, -4.6532e-03],\n",
            "          [-1.5099e-02,  3.2995e-02,  3.9024e-02]],\n",
            "\n",
            "         [[-1.6894e-02, -5.0667e-02, -2.4537e-02],\n",
            "          [ 2.0828e-02, -6.0974e-02, -5.8362e-02],\n",
            "          [ 2.5107e-04, -7.1218e-02, -1.0020e-01]],\n",
            "\n",
            "         [[-7.2316e-03, -1.1408e-02, -2.6451e-03],\n",
            "          [ 1.9495e-02, -2.3456e-02, -3.8769e-03],\n",
            "          [-1.6942e-02, -1.6399e-02,  1.7425e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7035e-02, -3.1016e-02,  2.1796e-02],\n",
            "          [ 2.2749e-02,  3.9112e-02, -2.3586e-02],\n",
            "          [-3.7569e-02, -9.9192e-03, -4.8170e-02]],\n",
            "\n",
            "         [[ 4.7776e-02,  2.5663e-02,  6.1775e-02],\n",
            "          [ 3.7004e-02,  6.5668e-03,  3.5010e-02],\n",
            "          [ 2.8961e-02,  5.1505e-02,  3.5185e-02]],\n",
            "\n",
            "         [[ 7.4838e-03, -1.3840e-02, -6.0882e-02],\n",
            "          [-9.7301e-03, -1.1037e-02,  1.7027e-02],\n",
            "          [-2.9216e-02, -7.3997e-02, -2.4658e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3486e-03, -3.3117e-02,  3.3211e-02],\n",
            "          [ 3.6109e-02, -1.7419e-02,  3.0478e-02],\n",
            "          [-4.6824e-03,  4.1723e-02,  1.1240e-02]],\n",
            "\n",
            "         [[-3.5577e-02,  2.4054e-02,  5.2683e-02],\n",
            "          [-4.6361e-02, -2.8038e-02,  7.6932e-02],\n",
            "          [-3.8964e-02,  1.3202e-02, -1.6895e-02]],\n",
            "\n",
            "         [[-2.3286e-03,  1.8012e-02,  4.9058e-02],\n",
            "          [ 7.2208e-03,  2.2465e-02,  2.1700e-02],\n",
            "          [ 1.3760e-02, -4.5274e-04,  1.9402e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8973e-02, -1.3038e-02,  3.6479e-02],\n",
            "          [-1.7029e-02, -7.4277e-03, -1.9560e-02],\n",
            "          [-3.1115e-02, -1.4310e-02, -2.9693e-02]],\n",
            "\n",
            "         [[ 3.9185e-02, -4.5371e-02, -2.6910e-02],\n",
            "          [ 1.0804e-02, -5.9352e-02, -1.2278e-02],\n",
            "          [-7.0264e-05, -1.4198e-02,  3.9084e-03]],\n",
            "\n",
            "         [[-1.6683e-02,  7.5345e-03,  5.1489e-02],\n",
            "          [-3.0312e-02,  1.3660e-02,  1.9649e-02],\n",
            "          [-6.0514e-02,  1.6292e-02,  2.5869e-02]]]], device='cuda:0')), ('conv4.bias', tensor([-0.1022,  0.1128,  0.1171,  0.2050,  0.2385,  0.1252,  0.0453,  0.2124,\n",
            "         0.0110, -0.0456,  0.0118,  0.1950,  0.2503,  0.0560,  0.0678, -0.1477,\n",
            "         0.0196, -0.0715,  0.0904, -0.0776,  0.1288, -0.0258, -0.0047,  0.0771,\n",
            "        -0.0626,  0.1152,  0.0176, -0.0258,  0.0397,  0.0658, -0.0098, -0.0491,\n",
            "         0.1534,  0.0215, -0.1242,  0.0382,  0.1945,  0.0725, -0.0106, -0.0711,\n",
            "         0.0089,  0.0059,  0.0586,  0.0406, -0.0267, -0.0443, -0.1162,  0.1997,\n",
            "         0.0243,  0.0671,  0.1139,  0.1642,  0.0011, -0.0199, -0.0212,  0.0118,\n",
            "        -0.0148,  0.1798, -0.0722, -0.0344, -0.0159,  0.0973,  0.1314, -0.0363],\n",
            "       device='cuda:0')), ('fc1.weight', tensor([[-0.0054,  0.0070, -0.0140,  ..., -0.0211,  0.0076, -0.0293],\n",
            "        [ 0.0160, -0.0275,  0.0166,  ...,  0.0148, -0.0227, -0.0104],\n",
            "        [ 0.0153, -0.0079, -0.0060,  ...,  0.0141, -0.0132, -0.0027],\n",
            "        ...,\n",
            "        [-0.0139,  0.0154, -0.0021,  ..., -0.0057,  0.0012, -0.0164],\n",
            "        [-0.0188,  0.0016,  0.0204,  ...,  0.0039,  0.0140,  0.0049],\n",
            "        [ 0.0071,  0.0135,  0.0105,  ...,  0.0206, -0.0191, -0.0011]],\n",
            "       device='cuda:0')), ('fc1.bias', tensor([-4.1406e-03,  4.0458e-02,  2.9784e-03,  3.2465e-02,  7.7885e-02,\n",
            "        -1.0299e-03,  1.9883e-03, -2.3456e-02, -2.5890e-02,  1.3044e-02,\n",
            "        -1.8065e-02,  4.6820e-02,  1.1483e-02,  1.0026e-01, -5.2559e-02,\n",
            "         3.7408e-02,  4.6497e-02,  4.6399e-03,  1.9828e-03,  3.0381e-02,\n",
            "         3.1103e-02,  6.5048e-02, -4.9771e-03,  5.0816e-02,  1.0718e-04,\n",
            "        -1.2159e-04,  3.5336e-03,  9.4960e-03,  1.8169e-02, -3.6447e-02,\n",
            "         1.6377e-02, -9.9641e-03, -2.9759e-02,  1.1980e-02, -3.5200e-03,\n",
            "         5.8529e-03,  4.4864e-02, -1.0119e-03,  2.0135e-03,  4.1484e-02,\n",
            "         1.5140e-02, -8.6653e-05,  3.3905e-02, -3.1427e-03,  4.0908e-02,\n",
            "         7.3960e-03, -7.0659e-03,  4.3581e-03,  2.4762e-02, -8.3995e-03,\n",
            "        -2.4106e-02, -4.5591e-02,  7.1304e-02,  2.6056e-02,  5.7524e-03,\n",
            "        -4.0239e-02, -2.5338e-02,  4.9801e-03, -2.1850e-02,  5.0297e-03,\n",
            "         4.0542e-02,  2.7281e-02, -9.0750e-04,  3.4816e-02, -8.0487e-03,\n",
            "         2.7125e-02,  1.3845e-02,  4.4293e-02, -3.1915e-02,  1.2457e-02,\n",
            "         1.4063e-02,  5.4973e-02,  3.9962e-02,  3.9688e-02, -9.1640e-03,\n",
            "        -2.9009e-03,  2.8726e-02, -4.9438e-03,  4.9640e-02, -1.7078e-02,\n",
            "         4.3356e-02,  2.5850e-02,  1.2124e-02,  6.8119e-02, -1.2813e-02,\n",
            "        -4.1904e-03,  6.3980e-03,  2.4784e-02,  4.8609e-02,  9.0820e-02,\n",
            "         2.8864e-02,  2.4026e-02,  8.3428e-02, -1.9734e-02, -1.1888e-02,\n",
            "        -1.3818e-02, -2.4926e-02,  1.7850e-02,  6.4454e-02,  3.2637e-03,\n",
            "        -3.0573e-02,  3.0888e-02,  4.2222e-02,  1.3894e-02,  2.0889e-02,\n",
            "        -2.7594e-02,  1.6032e-02,  3.7615e-02, -2.2098e-03,  4.9905e-03,\n",
            "         6.3971e-03, -3.6272e-02, -5.9943e-03,  4.3436e-02, -1.5733e-02,\n",
            "        -3.7799e-03,  5.6570e-04,  6.8307e-02, -2.8358e-02,  5.5075e-02,\n",
            "         1.2623e-02,  5.6970e-02, -2.5096e-02,  8.7057e-03, -2.8901e-02,\n",
            "        -3.1103e-02, -5.2263e-02,  1.9983e-02, -1.0975e-02, -2.6283e-02,\n",
            "         4.7769e-02,  2.6479e-02,  6.6309e-02, -2.8937e-02, -2.1400e-02,\n",
            "         3.2327e-02, -1.1432e-02,  7.3946e-03,  3.9509e-02,  5.3527e-02,\n",
            "        -7.4017e-03,  3.4616e-02, -2.0741e-02,  5.8846e-02,  6.4438e-02,\n",
            "         2.5136e-02,  2.7392e-02,  8.7325e-02,  4.4996e-02,  2.9944e-02,\n",
            "        -2.5882e-02, -2.3286e-02,  6.3485e-02,  3.6801e-02, -6.6705e-03,\n",
            "         2.2999e-02, -3.0128e-02, -2.4739e-03,  3.2378e-02, -4.4685e-03,\n",
            "         3.1685e-02,  5.4333e-02, -1.4742e-02, -1.9907e-02, -1.0517e-02,\n",
            "         1.0245e-02,  4.6187e-02,  4.8781e-02,  2.8648e-02,  1.2674e-03,\n",
            "        -4.3105e-02,  4.0281e-02,  1.4465e-02,  1.6948e-02,  2.8439e-02,\n",
            "         2.4832e-02,  3.1384e-02,  8.7496e-03, -1.3545e-02,  1.1298e-02,\n",
            "         1.3169e-02,  4.3092e-02, -1.6470e-02, -4.5295e-03,  1.6704e-02,\n",
            "         4.8142e-02, -2.4024e-02, -2.0118e-02, -3.2839e-02, -1.9058e-02,\n",
            "         7.8349e-02,  1.4894e-02,  1.2979e-02,  9.5435e-03,  2.4628e-02,\n",
            "         7.0410e-02,  3.2488e-02, -4.2236e-03, -1.2156e-02,  4.5384e-02,\n",
            "         4.3884e-02,  2.5341e-02,  1.1711e-02, -3.5497e-02, -8.7112e-05,\n",
            "        -5.1212e-03,  7.7427e-03,  6.9164e-02,  3.7994e-02,  5.6159e-02,\n",
            "         1.3870e-02,  5.5487e-02, -1.5757e-02, -5.8690e-03, -1.3076e-02,\n",
            "         4.8854e-02,  1.8591e-02,  3.8814e-02,  6.1554e-02,  5.5231e-02,\n",
            "         1.1746e-02, -2.2814e-02, -7.7591e-03, -3.2996e-02, -1.7689e-02,\n",
            "         7.0716e-02, -1.1954e-02,  7.2913e-02,  2.8722e-02,  5.2444e-03,\n",
            "         8.5845e-02, -6.3234e-03,  3.6347e-02, -2.0821e-02, -1.8453e-02,\n",
            "         7.9764e-02,  3.3963e-02,  1.8233e-02,  1.1142e-02,  1.8638e-02,\n",
            "        -4.3684e-02, -1.1383e-02,  7.2674e-02,  1.8420e-02,  9.8451e-03,\n",
            "        -8.6904e-03,  5.9517e-02,  5.7267e-03,  5.0667e-02,  4.7312e-02,\n",
            "        -4.6293e-02, -6.0789e-02, -9.7616e-03,  3.7970e-02,  1.8580e-02,\n",
            "        -5.6208e-03,  5.7993e-02, -2.0094e-02, -1.7603e-02, -3.7432e-02,\n",
            "         2.4370e-02,  1.1445e-02,  1.5283e-02,  1.7720e-02,  6.2207e-02,\n",
            "         6.7260e-03,  1.1596e-02,  3.5173e-02, -2.5775e-02, -1.3319e-02,\n",
            "         6.6180e-02,  6.2930e-02,  2.1506e-02, -3.4411e-02,  1.7228e-02,\n",
            "         1.8955e-02,  9.9428e-03, -1.2808e-02,  3.5962e-02,  2.8287e-03,\n",
            "         3.6726e-02,  7.0180e-02,  1.8739e-02,  4.0844e-02, -3.4019e-02,\n",
            "         6.1455e-03,  7.9865e-02, -6.3494e-03, -5.9519e-03,  3.9354e-02,\n",
            "         3.1657e-02, -1.2398e-02,  8.1862e-02,  1.3662e-02,  9.4609e-02,\n",
            "         1.0864e-02,  2.6464e-02,  5.5863e-02, -1.9547e-02,  2.0460e-02,\n",
            "        -3.9520e-02,  2.3476e-02,  2.3091e-02,  6.9306e-02, -1.7541e-02,\n",
            "        -1.4370e-02,  6.0797e-02,  2.8107e-04,  2.5402e-02,  1.3446e-03,\n",
            "         2.0928e-02, -5.1933e-03,  2.4059e-02,  7.6702e-03,  1.9006e-02,\n",
            "         8.7827e-02, -5.1082e-02,  6.7427e-03, -1.0924e-02,  1.2314e-02,\n",
            "         6.6908e-02,  1.8233e-02, -1.1541e-02, -1.2721e-02,  1.8676e-02,\n",
            "         3.3341e-02,  6.0511e-02, -4.6858e-03, -3.7988e-02,  3.0577e-02,\n",
            "        -1.4791e-02,  1.2804e-02,  6.1543e-05,  2.3264e-02,  1.0860e-02,\n",
            "         1.9641e-02, -5.0924e-03, -1.1778e-02,  2.2879e-02,  6.0276e-02,\n",
            "         1.4204e-02,  6.5680e-04,  2.0080e-02,  3.2559e-02, -1.7455e-02,\n",
            "         1.0429e-02, -2.4984e-02, -2.1096e-02,  1.6693e-02,  7.8131e-02,\n",
            "        -6.1394e-04,  1.8229e-03,  1.3316e-02,  7.8082e-02,  2.2294e-02,\n",
            "         2.6997e-02,  5.2818e-02,  8.2542e-02, -1.7403e-02,  2.5024e-02,\n",
            "         3.1929e-02,  1.0975e-02,  1.7128e-03, -2.7877e-02, -4.4890e-02,\n",
            "         1.7868e-02,  1.5163e-02, -2.0367e-02, -1.6880e-02,  7.9541e-02,\n",
            "         9.1145e-03,  3.1259e-02, -5.5822e-03,  4.2358e-02, -9.4144e-03,\n",
            "        -1.1074e-02,  2.4673e-02,  3.3357e-02, -3.9698e-02,  4.1679e-02,\n",
            "         6.1904e-02,  1.2927e-02, -1.1503e-02, -4.9067e-03, -4.8910e-03,\n",
            "         4.3538e-03,  2.4406e-02,  3.7657e-02, -5.8421e-04,  2.5064e-02,\n",
            "         4.0708e-02,  9.3240e-02,  2.0668e-02, -2.9034e-03,  5.6075e-02,\n",
            "        -2.0593e-03,  3.4783e-02,  3.4270e-02,  2.5036e-02, -9.1439e-03,\n",
            "        -1.4936e-02,  1.4418e-02,  9.0933e-03,  7.6644e-02,  1.1357e-02,\n",
            "         2.2233e-02,  5.0376e-02,  2.4242e-05,  2.9693e-02, -6.9411e-03,\n",
            "         6.4741e-02, -1.0110e-02,  3.0717e-02,  3.7921e-02,  1.7405e-02,\n",
            "         3.7227e-02,  1.8164e-02, -1.4113e-02, -7.4658e-03, -1.6178e-02,\n",
            "         9.2746e-02,  9.9392e-02,  4.9265e-02,  5.7494e-02, -2.7018e-02,\n",
            "         5.0898e-02,  1.2242e-02,  8.7179e-03,  5.1484e-02,  4.3419e-02,\n",
            "        -1.4885e-03,  3.3538e-02, -4.8300e-02,  5.5605e-03,  1.4090e-02,\n",
            "        -1.3970e-02,  2.1837e-02,  4.3967e-02,  3.3656e-02,  9.1367e-02,\n",
            "         5.9650e-02,  8.0974e-03,  4.7109e-03,  2.3499e-02, -3.9192e-02,\n",
            "        -1.5319e-02, -9.1498e-03,  3.9584e-02,  2.6318e-02,  2.5155e-03,\n",
            "         6.2588e-02,  7.8772e-03,  5.7446e-02,  9.4348e-03,  4.2798e-02,\n",
            "         1.0234e-02,  3.4888e-02, -1.7082e-03,  5.3149e-03,  1.5842e-02,\n",
            "        -1.0503e-02,  3.9685e-02,  5.4703e-03,  1.9567e-02,  2.5374e-02,\n",
            "         5.5587e-02,  3.2280e-03, -1.8813e-02,  1.3997e-02, -1.1883e-02,\n",
            "        -2.2535e-02, -2.4530e-02, -5.1643e-03,  5.9776e-02,  3.3305e-02,\n",
            "         2.4917e-03,  1.7301e-02,  2.2455e-02, -1.6758e-02,  2.0824e-02,\n",
            "        -2.2234e-02,  3.2823e-02,  1.8331e-02,  4.9612e-02, -4.1713e-02,\n",
            "        -1.2463e-02,  5.7619e-02,  2.0677e-02,  3.4076e-02, -1.3788e-02,\n",
            "        -5.7603e-03, -2.8229e-03,  1.2743e-02,  4.8579e-03,  6.6493e-02,\n",
            "        -2.0261e-02,  3.0167e-02,  2.2765e-02,  5.0790e-03,  2.1781e-02,\n",
            "         5.0815e-02, -3.0118e-05,  3.0381e-02, -1.1653e-02,  4.4991e-03,\n",
            "        -2.6027e-02, -5.1489e-03,  3.5127e-02, -4.4329e-03, -2.4131e-02,\n",
            "        -3.1812e-03,  3.7140e-02], device='cuda:0')), ('fc2.weight', tensor([[-0.0316, -0.1178, -0.0707,  ...,  0.0476,  0.0590,  0.0428],\n",
            "        [ 0.0110,  0.0061, -0.0233,  ...,  0.0375, -0.0225, -0.1500],\n",
            "        [ 0.0514, -0.0465,  0.0533,  ..., -0.0579,  0.0446,  0.0869],\n",
            "        ...,\n",
            "        [ 0.0854,  0.0337,  0.0210,  ...,  0.0681, -0.0928,  0.0035],\n",
            "        [-0.1315,  0.1147, -0.0748,  ..., -0.0919, -0.0097,  0.0558],\n",
            "        [ 0.0244, -0.0908,  0.1392,  ...,  0.0143, -0.0223, -0.1175]],\n",
            "       device='cuda:0')), ('fc2.bias', tensor([-0.1503, -0.2097, -0.1321,  0.1708,  0.3564, -0.1722,  0.4310, -0.4648,\n",
            "         0.4167, -0.2613], device='cuda:0'))])\n",
            "MyNet(\n",
            "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n",
            "OrderedDict([('fc1.weight', tensor([[ 0.1048,  0.1090,  0.0759,  ...,  0.1110,  0.0408,  0.0724],\n",
            "        [ 0.0856,  0.1340,  0.1090,  ..., -0.0063, -0.0061, -0.0180],\n",
            "        [ 0.0121,  0.0187, -0.0006,  ...,  0.0205,  0.0533,  0.0294],\n",
            "        ...,\n",
            "        [ 0.0446,  0.0092,  0.0798,  ..., -0.0230,  0.0264,  0.0436],\n",
            "        [-0.0335, -0.0041,  0.0972,  ..., -0.0264, -0.0684, -0.0845],\n",
            "        [ 0.0650, -0.0934, -0.1019,  ..., -0.0339, -0.0698, -0.0469]],\n",
            "       device='cuda:0')), ('fc1.bias', tensor([-1.2556, -1.3071, -0.5352,  ..., -1.3310, -1.2173, -1.0617],\n",
            "       device='cuda:0')), ('fc2.weight', tensor([[-0.0038,  0.0103, -0.0601,  ..., -0.0139, -0.0219, -0.0235],\n",
            "        [ 0.0177, -0.0106,  0.0173,  ...,  0.0174,  0.0433, -0.0051],\n",
            "        [-0.0354,  0.0047, -0.0031,  ...,  0.0203, -0.0105, -0.0210],\n",
            "        ...,\n",
            "        [-0.0184, -0.0063,  0.0140,  ..., -0.0388, -0.0107, -0.0047],\n",
            "        [ 0.0021,  0.0273, -0.0343,  ...,  0.0367, -0.0040,  0.0024],\n",
            "        [-0.0209,  0.0317,  0.0208,  ...,  0.0183,  0.0183,  0.0031]],\n",
            "       device='cuda:0')), ('fc2.bias', tensor([ 0.0733, -0.9829,  0.7638,  0.3156,  0.8186,  0.0100,  0.3502, -0.2479,\n",
            "        -0.1159, -0.7787], device='cuda:0'))])\n",
            "MyNet(\n",
            "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n",
            "OrderedDict([('fc1.weight', tensor([[ 0.1821,  0.1179,  0.0877,  ...,  0.0763, -0.1139, -0.1946],\n",
            "        [ 0.0888,  0.1488,  0.1033,  ..., -0.0506, -0.1565, -0.2907],\n",
            "        [ 0.1720,  0.1568,  0.0757,  ...,  0.0917,  0.1227,  0.1357],\n",
            "        ...,\n",
            "        [ 0.2184,  0.2224,  0.1360,  ..., -0.0146,  0.0887,  0.0735],\n",
            "        [ 0.1545,  0.1761,  0.1599,  ..., -0.1788, -0.0904, -0.0043],\n",
            "        [ 0.0089,  0.0049, -0.0388,  ...,  0.0380, -0.0959, -0.1041]],\n",
            "       device='cuda:0')), ('fc1.bias', tensor([-0.9593,  0.1096, -1.5642,  ..., -1.7116, -1.1653, -1.2398],\n",
            "       device='cuda:0')), ('fc2.weight', tensor([[ 0.1052,  0.1089, -0.0032,  ...,  0.0329, -0.0148,  0.0299],\n",
            "        [-0.0348,  0.0071,  0.0881,  ..., -0.0344, -0.0422,  0.2281],\n",
            "        [ 0.0207,  0.0832,  0.0021,  ..., -0.0640,  0.0307, -0.1212],\n",
            "        ...,\n",
            "        [-0.1787, -0.0242,  0.0662,  ...,  0.0839,  0.1675, -0.0434],\n",
            "        [ 0.0166, -0.1625,  0.0538,  ...,  0.0689, -0.0375, -0.0706],\n",
            "        [ 0.0367, -0.1720,  0.0362,  ...,  0.2489, -0.0211, -0.1326]],\n",
            "       device='cuda:0')), ('fc2.bias', tensor([-0.0182, -1.0393,  0.6338, -0.2050,  0.8908, -0.3150,  0.4571, -0.5384,\n",
            "         0.5270, -0.8619], device='cuda:0'))])\n",
            "MyNet(\n",
            "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n",
            "OrderedDict([('fc1.weight', tensor([[ 0.0501,  0.0697,  0.0615,  ...,  0.0387,  0.0976,  0.0844],\n",
            "        [ 0.0967,  0.1151,  0.0099,  ..., -0.0898, -0.1231, -0.1917],\n",
            "        [ 0.0708,  0.1011,  0.0509,  ...,  0.0496,  0.0313, -0.0335],\n",
            "        ...,\n",
            "        [-0.0168, -0.1208, -0.0515,  ..., -0.0855, -0.1364, -0.1673],\n",
            "        [ 0.0777,  0.2107,  0.2325,  ..., -0.0539, -0.0098, -0.0529],\n",
            "        [-0.0818, -0.1080,  0.0342,  ...,  0.0585,  0.1051,  0.0617]],\n",
            "       device='cuda:0')), ('fc1.bias', tensor([-4.9297, -2.0619, -4.9268,  ..., -2.8873, -2.7062, -1.5931],\n",
            "       device='cuda:0')), ('fc2.weight', tensor([[-1.5332e-02, -2.8029e-02,  5.2333e-03,  ..., -2.4263e-03,\n",
            "         -2.1192e-02,  2.6467e-02],\n",
            "        [-7.3781e-04,  2.4349e-02, -1.6772e-03,  ...,  6.1239e-02,\n",
            "         -1.0216e-02, -8.8789e-05],\n",
            "        [ 1.5220e-02, -2.4167e-02,  3.6045e-03,  ..., -2.0423e-02,\n",
            "          2.2249e-02,  2.5179e-02],\n",
            "        ...,\n",
            "        [-1.2071e-02, -1.7204e-02, -4.8667e-03,  ..., -3.3811e-02,\n",
            "         -3.3082e-02, -1.4479e-02],\n",
            "        [ 1.0377e-02, -2.1769e-02, -1.7507e-03,  ..., -2.1989e-02,\n",
            "         -1.2822e-02,  1.4963e-02],\n",
            "        [ 6.0790e-03, -8.4575e-03,  6.7843e-03,  ...,  1.9793e-02,\n",
            "          4.5100e-02,  1.1295e-02]], device='cuda:0')), ('fc2.bias', tensor([ 0.2604, -1.4145,  0.9069,  0.3645,  0.9822, -0.0383,  0.4377, -0.3044,\n",
            "        -0.0647, -1.0064], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMF4w8VWhtAA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11e0e3c0-e50e-47c4-d993-88d117a93fd8"
      },
      "source": [
        "# ====== 保存 =======\n",
        "# torch.save(net.state_dict(), 'teacher_model_weight.pth')\n",
        "#to(device)から戻した感じかな。\n",
        "\n",
        "Tnet: MyCNN3 = MyCNN3()\n",
        "    \n",
        "# 保存したモデルのパラメータを読み込む\n",
        "param = torch.load('teacher_model_weight.pth')\n",
        "\n",
        "# 保存したモデルにパラメータを当てはめる\n",
        "Tnet.load_state_dict(param)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1eztiUaxbTP",
        "colab_type": "text"
      },
      "source": [
        "**モデル検証**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCeEzmDXxhfc",
        "colab_type": "text"
      },
      "source": [
        "教師モデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQnUPJcEwx--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9cfb0523-2d92-4c47-f9af-bc84b1e96d1d"
      },
      "source": [
        "import time\n",
        "loader = load_cifar10()\n",
        "t1 = time.time()\n",
        "\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in loader['test']:\n",
        "        outputs = Tnet(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = float(correct / 10000)\n",
        "print(acc)\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "0.6854\n",
            "経過時間：8.915922164916992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anVKxzJMxkt8",
        "colab_type": "text"
      },
      "source": [
        "通常NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WclmgWJYwyBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "02060322-6336-4988-ba4f-0ebb0ce37eb7"
      },
      "source": [
        "import time\n",
        "loader = load_cifar10()\n",
        "t1 = time.time()\n",
        "\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in loader['test']:\n",
        "        data = images.view(-1, 32 * 32 * 3)\n",
        "        outputs = NN(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = float(correct / 10000)\n",
        "print(acc)\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "0.5251\n",
            "経過時間：3.074653148651123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO8Qyrrtxo6n",
        "colab_type": "text"
      },
      "source": [
        "蒸留モデル1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8h_XVBdwyFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "6f70e2bd-1608-4647-d06d-89483745c92b"
      },
      "source": [
        "import time\n",
        "loader = load_cifar10()\n",
        "t1 = time.time()\n",
        "\n",
        "\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in loader['test']:\n",
        "        data = images.view(-1, 32 * 32 * 3)\n",
        "        outputs = distillation_net(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = float(correct / 10000)\n",
        "print(acc)\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "0.5603\n",
            "経過時間：3.0584280490875244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t-WJkeRxtfU",
        "colab_type": "text"
      },
      "source": [
        "蒸留モデル2(hard+soft)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztw6wHgrU5YG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4dd0f17f-98ca-4d99-9a80-ca1422ccc945"
      },
      "source": [
        "import time\n",
        "loader = load_cifar10()\n",
        "t1 = time.time()\n",
        "\n",
        "\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in loader['test']:\n",
        "        data = images.view(-1, 32 * 32 * 3)\n",
        "        outputs = distillation_net2(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = float(correct / 10000)\n",
        "print(acc)\n",
        "\n",
        "\n",
        "t2 = time.time()\n",
        "elapsed_time = t2-t1\n",
        "print(f\"経過時間：{elapsed_time}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "0.5747\n",
            "経過時間：3.061567783355713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGMmhAamU5yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}